{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a424fa5",
   "metadata": {
    "id": "8-o5Wfg9YtAB",
    "papermill": {
     "duration": 0.005437,
     "end_time": "2024-12-14T02:18:34.734715",
     "exception": false,
     "start_time": "2024-12-14T02:18:34.729278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load sub\n",
    "\n",
    "The videos are in the order of Experiment_id, so not in the order of presentation. This means the first video is the same for each participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eaaf2f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:18:34.746205Z",
     "iopub.status.busy": "2024-12-14T02:18:34.745887Z",
     "iopub.status.idle": "2024-12-14T02:18:52.790414Z",
     "shell.execute_reply": "2024-12-14T02:18:52.789497Z"
    },
    "id": "vXChgENjXQLH",
    "papermill": {
     "duration": 18.053235,
     "end_time": "2024-12-14T02:18:52.792610",
     "exception": false,
     "start_time": "2024-12-14T02:18:34.739375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mrmr-selection in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.8)\n",
      "Requirement already satisfied: category-encoders in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (2.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (3.1.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (1.4.2)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (1.15.1)\n",
      "Requirement already satisfied: polars>=0.12.5 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mrmr-selection) (1.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.3->mrmr-selection) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.3->mrmr-selection) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.3->mrmr-selection) (2024.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from category-encoders->mrmr-selection) (1.0.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from category-encoders->mrmr-selection) (0.14.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->mrmr-selection) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->mrmr-selection) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->mrmr-selection) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.3->mrmr-selection) (1.17.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels>=0.9.0->category-encoders->mrmr-selection) (24.2)\n",
      "Requirement already satisfied: ordpy in c:\\users\\ferri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.1.5)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import gc  # Garbage collector\n",
    "\n",
    "!pip install mrmr-selection\n",
    "!pip install ordpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b633346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:18:52.804599Z",
     "iopub.status.busy": "2024-12-14T02:18:52.804335Z",
     "iopub.status.idle": "2024-12-14T02:19:19.650699Z",
     "shell.execute_reply": "2024-12-14T02:19:19.649733Z"
    },
    "papermill": {
     "duration": 26.854463,
     "end_time": "2024-12-14T02:19:19.652606",
     "exception": false,
     "start_time": "2024-12-14T02:18:52.798143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 40, 8064)\n",
      "(1280, 4)\n"
     ]
    }
   ],
   "source": [
    "participants = 32\n",
    "subjects = {'data': [], 'labels': []}\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "\n",
    "# Read and collect data\n",
    "for i in range(1, participants + 1):\n",
    "    file_name = prefix_path + f\"data_preprocessed_python\\\\s{'0' if i < 10 else ''}{i}.dat\"\n",
    "    with open(file_name, 'rb') as file:\n",
    "        subject = pickle.load(file, encoding='latin1')\n",
    "        for key in subjects:\n",
    "            subjects[key].append(subject[key])\n",
    "\n",
    "        del subject\n",
    "\n",
    "# Merge data and reshape\n",
    "for key in subjects:\n",
    "    subjects[key] = np.concatenate(subjects[key], axis=0)\n",
    "\n",
    "print(subjects['data'].shape)\n",
    "print(subjects['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7e3345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:19.664575Z",
     "iopub.status.busy": "2024-12-14T02:19:19.664028Z",
     "iopub.status.idle": "2024-12-14T02:19:19.670727Z",
     "shell.execute_reply": "2024-12-14T02:19:19.669937Z"
    },
    "papermill": {
     "duration": 0.014383,
     "end_time": "2024-12-14T02:19:19.672409",
     "exception": false,
     "start_time": "2024-12-14T02:19:19.658026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.float64(0.0), np.float64(1.0)}\n",
      "{np.float64(0.0), np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "# Use 2 classifiers valence and arousal\n",
    "subjects['labels'] = subjects['labels'][:, :2]\n",
    "\n",
    "# Use threshold 5 to assign binary label to each classifier\n",
    "subjects['labels'][:, 0] = (subjects['labels'][:, 0] >= 5).astype(int)\n",
    "subjects['labels'][:, 1] = (subjects['labels'][:, 1] >= 5).astype(int)\n",
    "\n",
    "print(set(subjects['labels'][:, 0]))\n",
    "print(set(subjects['labels'][:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96081c1",
   "metadata": {
    "papermill": {
     "duration": 0.005,
     "end_time": "2024-12-14T02:19:19.682532",
     "exception": false,
     "start_time": "2024-12-14T02:19:19.677532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split Train Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c47127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:19.693561Z",
     "iopub.status.busy": "2024-12-14T02:19:19.693342Z",
     "iopub.status.idle": "2024-12-14T02:19:21.756931Z",
     "shell.execute_reply": "2024-12-14T02:19:21.756102Z"
    },
    "papermill": {
     "duration": 2.070958,
     "end_time": "2024-12-14T02:19:21.758539",
     "exception": false,
     "start_time": "2024-12-14T02:19:19.687581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 40, 8064) (256, 40, 8064) (1024, 2) (256, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    subjects['data'], subjects['labels'], test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "del subjects\n",
    "gc.collect()  # Free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f95fd",
   "metadata": {
    "papermill": {
     "duration": 0.005846,
     "end_time": "2024-12-14T02:19:21.769933",
     "exception": false,
     "start_time": "2024-12-14T02:19:21.764087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665ba0c",
   "metadata": {
    "papermill": {
     "duration": 0.00644,
     "end_time": "2024-12-14T02:19:21.784501",
     "exception": false,
     "start_time": "2024-12-14T02:19:21.778061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c385adc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:21.796792Z",
     "iopub.status.busy": "2024-12-14T02:19:21.795935Z",
     "iopub.status.idle": "2024-12-14T02:19:21.873590Z",
     "shell.execute_reply": "2024-12-14T02:19:21.872726Z"
    },
    "papermill": {
     "duration": 0.0855,
     "end_time": "2024-12-14T02:19:21.875322",
     "exception": false,
     "start_time": "2024-12-14T02:19:21.789822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wavelet transform\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sampling frequency:\n",
    "fs = 128\n",
    "\n",
    "# Select scales and wavelets\n",
    "scales = np.arange(1, 129)  # Example: 129 scale values\n",
    "wavelet = 'morl'\n",
    "\n",
    "def CWT_for_sample(data):\n",
    "    cwt_output = []\n",
    "    # Calculate CWT for each sample and each channel\n",
    "    for i in tqdm(range(data.shape[0])):  # 1024 samples\n",
    "        cwt_channels = []\n",
    "        for j in range(data.shape[1]):  # 40 channels\n",
    "            coeffs, freqs = pywt.cwt(data[i, j], scales, wavelet) # coeffs are of the form (len(scales), 8064)\n",
    "            energy_scales = np.sum(np.abs(coeffs)**2, axis=1)  # (len(scales),)\n",
    "            cwt_channels.append(energy_scales)\n",
    "        cwt_output.append(cwt_channels)\n",
    "    \n",
    "    # Convert output to numpy array\n",
    "    cwt_output = np.array(cwt_output)  # Size: (1024, 40, len(scales))\n",
    "\n",
    "    return cwt_output\n",
    "    \n",
    "# cwt_train = CWT_for_sample(X_train) # Size: (1024, 40, len(scales))\n",
    "# cwt_test = CWT_for_sample(X_test) # Size: (256, 40, len(scales))\n",
    "\n",
    "# print(cwt_train.shape, cwt_test.shape)\n",
    "\n",
    "# # Save file name\n",
    "# prefix_output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "# filename = \"cwt_data.pkl\"\n",
    "\n",
    "# # Save data\n",
    "# with open(prefix_output_path +filename, 'wb') as file:\n",
    "#     pickle.dump({'train': cwt_train, 'test': cwt_test}, file)\n",
    "\n",
    "# print(f\"Data has been saved to file {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c8f6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:21.894280Z",
     "iopub.status.busy": "2024-12-14T02:19:21.893393Z",
     "iopub.status.idle": "2024-12-14T02:19:22.386639Z",
     "shell.execute_reply": "2024-12-14T02:19:22.385524Z"
    },
    "papermill": {
     "duration": 0.505542,
     "end_time": "2024-12-14T02:19:22.388501",
     "exception": false,
     "start_time": "2024-12-14T02:19:21.882959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size cwt_train: (1024, 40, 128)\n",
      "Size cwt_test: (256, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"cwt_data.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Data retrieval\n",
    "cwt_train_loaded = data['train']\n",
    "cwt_test_loaded = data['test']\n",
    "\n",
    "print(\"Size cwt_train:\", cwt_train_loaded.shape)\n",
    "print(\"Size cwt_test:\", cwt_test_loaded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ef55a",
   "metadata": {
    "papermill": {
     "duration": 0.00529,
     "end_time": "2024-12-14T02:19:22.399337",
     "exception": false,
     "start_time": "2024-12-14T02:19:22.394047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Nonlinear Feature Analyses: Permutation Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd705ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:22.411187Z",
     "iopub.status.busy": "2024-12-14T02:19:22.410904Z",
     "iopub.status.idle": "2024-12-14T02:19:22.418960Z",
     "shell.execute_reply": "2024-12-14T02:19:22.418178Z"
    },
    "papermill": {
     "duration": 0.015777,
     "end_time": "2024-12-14T02:19:22.420542",
     "exception": false,
     "start_time": "2024-12-14T02:19:22.404765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ordpy\n",
    "\n",
    "def split_array(arr, num_epochs):\n",
    "    \n",
    "    len_arr = len(arr)\n",
    "    len_epochs = round(len_arr / num_epochs)\n",
    "    \n",
    "    splits_arr = [arr[i * len_epochs: len_arr if i + 1 == num_epochs else (i + 1) * len_epochs] for i in range(num_epochs)]\n",
    "\n",
    "    return splits_arr\n",
    "\n",
    "def permutation_entropy_eeg(data, num_epochs=8):\n",
    "    B, C, T = data.shape\n",
    "    pe = np.zeros((B, C, num_epochs))\n",
    "    \n",
    "    for b in tqdm(range(B)):\n",
    "        for c in range(C):\n",
    "            splits_arr = split_array(data[b, c], num_epochs)\n",
    "            for i in range(num_epochs):\n",
    "                pe[b, c, i] = ordpy.permutation_entropy(splits_arr[i])\n",
    "\n",
    "    return pe\n",
    "\n",
    "# pe_train = permutation_entropy_eeg(X_train)#1024x40\n",
    "# pe_test = permutation_entropy_eeg(X_test)#256x40\n",
    "\n",
    "# # Save file name\n",
    "# prefix_output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "# filename = \"pe_data.pkl\"\n",
    "\n",
    "# # Save data\n",
    "# with open(prefix_output_path + filename, 'wb') as file:\n",
    "#    pickle.dump({'train': pe_train, 'test': pe_test}, file)\n",
    "\n",
    "# print(f\"Data has been saved to file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff9e1aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:22.432770Z",
     "iopub.status.busy": "2024-12-14T02:19:22.432140Z",
     "iopub.status.idle": "2024-12-14T02:19:22.481085Z",
     "shell.execute_reply": "2024-12-14T02:19:22.480130Z"
    },
    "papermill": {
     "duration": 0.056838,
     "end_time": "2024-12-14T02:19:22.482775",
     "exception": false,
     "start_time": "2024-12-14T02:19:22.425937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size pe_train: (1024, 40, 8)\n",
      "Size pe_test: (256, 40, 8)\n"
     ]
    }
   ],
   "source": [
    "# # Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"pe_data.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Data retrieval\n",
    "pe_train_loaded = data['train']\n",
    "pe_test_loaded = data['test']\n",
    "\n",
    "print(\"Size pe_train:\", pe_train_loaded.shape)\n",
    "print(\"Size pe_test:\", pe_test_loaded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b50eb9",
   "metadata": {
    "papermill": {
     "duration": 0.005191,
     "end_time": "2024-12-14T02:19:22.493569",
     "exception": false,
     "start_time": "2024-12-14T02:19:22.488378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09b5501a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:22.505170Z",
     "iopub.status.busy": "2024-12-14T02:19:22.504942Z",
     "iopub.status.idle": "2024-12-14T02:19:22.599980Z",
     "shell.execute_reply": "2024-12-14T02:19:22.599349Z"
    },
    "papermill": {
     "duration": 0.10266,
     "end_time": "2024-12-14T02:19:22.601614",
     "exception": false,
     "start_time": "2024-12-14T02:19:22.498954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to file C:\\Users\\ferri\\Downloads\\PoliTO\\Tesi\\DSs\\Emotion-Stress\\deap-dataset\\pca_data_train_test_rnn.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "DEVICE = 'cpu' \n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, rnn_type=\"LSTM\", device=DEVICE):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        # Choose the RNN type (LSTM or GRU)\n",
    "        if rnn_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        elif rnn_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN type. Use 'LSTM' or 'GRU'.\")\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, feature_extraction=False):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # Reshape if necessary\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.view(batch_size, seq_len, self.input_size)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device) if isinstance(self.rnn, nn.LSTM) else None\n",
    "\n",
    "        # Pass through the RNN\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0)) if isinstance(self.rnn, nn.LSTM) else self.rnn(x, h0)\n",
    "\n",
    "        if feature_extraction:\n",
    "            return out\n",
    "\n",
    "        # Take the last hidden state\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Output layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, outs_channels, output_size, length_signal, device=DEVICE):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = [in_channels] + outs_channels\n",
    "        self.model = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, device=device),\n",
    "                nn.BatchNorm1d(out_channels, device=device),\n",
    "                nn.ReLU()\n",
    "            ) for in_channels, out_channels in zip(channels[:-1], channels[1:]) ]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(outs_channels[-1] * length_signal, output_size, device=device) \n",
    "\n",
    "    def forward(self, x, feature_extraction=False):\n",
    "        x = self.model(x)\n",
    "\n",
    "        if feature_extraction:\n",
    "            # If we want feature extraction, return features before the fully connected layer\n",
    "            return x\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def pca_data(data, k):\n",
    "    # Reshape the data into (n_samples, n_features) to prepare for PCA\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    data_reshaped = data.reshape(n_samples * n_channels, n_features)\n",
    "    \n",
    "    # Data Normalization\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_reshaped)\n",
    "    \n",
    "    # Apply PCA to reduce dimensionality\n",
    "    pca = PCA(n_components=k)\n",
    "    data_pca = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    # Reshape back to (n_samples, n_channels, k)\n",
    "    data_pca_reshaped = data_pca.reshape(n_samples, n_channels, k)\n",
    "    \n",
    "    return data_pca_reshaped\n",
    "\n",
    "\n",
    "def feature_extraction_with_rnn_cnn(X, y, model_type=\"CNN\", k=128):\n",
    "    \"\"\"\n",
    "    Extract features from the RNN or CNN model and return the extracted features.\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): The input data (n_samples, n_channels, n_features).\n",
    "        y (numpy.ndarray): The labels (n_samples, num_classes).\n",
    "        model_type (str): The model to use for feature extraction, either \"RNN\" or \"CNN\".\n",
    "        k (int): Number of principal components to keep after PCA.\n",
    "\n",
    "    Returns:\n",
    "        extracted_features (numpy.ndarray): The extracted features from the model.\n",
    "    \"\"\"\n",
    "    # Apply PCA\n",
    "    pca_data_transformed = pca_data(X, k=k)\n",
    "\n",
    "    # Convert to tensor\n",
    "    pca_data_tensor = torch.Tensor(pca_data_transformed).to(DEVICE)\n",
    "    \n",
    "    # Reshape the data to have 1 channel instead of 40\n",
    "    pca_data_tensor = pca_data_tensor.reshape(pca_data_tensor.shape[0], 1, pca_data_tensor.shape[1] * pca_data_tensor.shape[2])\n",
    "\n",
    "    # Choose model\n",
    "    if model_type == \"CNN\":\n",
    "        model = CNNModel(in_channels=1, outs_channels=[32, 64], output_size=10, length_signal=k, device=DEVICE)\n",
    "    elif model_type == \"RNN\":\n",
    "        model = RNNModel(input_size=5120, hidden_size=128, num_layers=2, output_size=10, device=DEVICE)\n",
    "    else:\n",
    "        raise ValueError(\"Model type must be either 'RNN' or 'CNN'.\")\n",
    "\n",
    "    # Extract features using the model\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        extracted_features = model(pca_data_tensor, feature_extraction=True)  # Extract features\n",
    "\n",
    "    return extracted_features\n",
    "\n",
    "\n",
    "# Assuming you have X_train, y_train, X_test, and y_test already loaded\n",
    "\n",
    "# Select model type based on input\n",
    "model_type = \"RNN\" \n",
    "\n",
    "# Feature extraction for train and test sets\n",
    "if model_type == \"CNN\":\n",
    "    features_train = feature_extraction_with_rnn_cnn(X_train, y_train, model_type=\"CNN\", k=128)\n",
    "    features_test = feature_extraction_with_rnn_cnn(X_test, y_test, model_type=\"CNN\", k=128)\n",
    "elif model_type == \"RNN\":\n",
    "    features_train = feature_extraction_with_rnn_cnn(X_train, y_train, model_type=\"RNN\", k=128)\n",
    "    features_test = feature_extraction_with_rnn_cnn(X_test, y_test, model_type=\"RNN\", k=128)\n",
    "\n",
    "# Save the extracted features to a pickle file\n",
    "output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = f\"pca_data_train_test_{model_type.lower()}.pkl\"  # File name will include model type\n",
    "\n",
    "with open(output_path + filename, 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'train': features_train,\n",
    "        'test': features_test\n",
    "    }, file)\n",
    "\n",
    "print(f\"Data has been saved to file {output_path + filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7829a243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:22.613557Z",
     "iopub.status.busy": "2024-12-14T02:19:22.613328Z",
     "iopub.status.idle": "2024-12-14T02:19:23.096634Z",
     "shell.execute_reply": "2024-12-14T02:19:23.095590Z"
    },
    "papermill": {
     "duration": 0.49133,
     "end_time": "2024-12-14T02:19:23.098554",
     "exception": false,
     "start_time": "2024-12-14T02:19:22.607224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size pca_train: torch.Size([1024, 1, 128])\n",
      "Size pca_test: torch.Size([256, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "if model_type == \"CNN\":\n",
    "    filename = \"pca_data_train_test_cnn.pkl\"\n",
    "elif model_type == \"RNN\":\n",
    "    filename = \"pca_data_train_test_rnn.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "# print(data)\n",
    "\n",
    "# Data retrieval\n",
    "pca_train_loaded = data['train']\n",
    "pca_test_loaded = data['test']\n",
    "\n",
    "print(\"Size pca_train:\", pca_train_loaded.shape)\n",
    "print(\"Size pca_test:\", pca_test_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cd3a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:23.111006Z",
     "iopub.status.busy": "2024-12-14T02:19:23.110733Z",
     "iopub.status.idle": "2024-12-14T02:19:24.538505Z",
     "shell.execute_reply": "2024-12-14T02:19:24.537851Z"
    },
    "papermill": {
     "duration": 1.436435,
     "end_time": "2024-12-14T02:19:24.540756",
     "exception": false,
     "start_time": "2024-12-14T02:19:23.104321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:13<00:00,  4.57it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 38.16it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 39.56it/s]\n",
      "100%|██████████| 64/64 [00:13<00:00,  4.68it/s]\n",
      "100%|██████████| 64/64 [00:13<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to file feature_selections.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "import pandas as pd\n",
    "\n",
    "def feature_selector(num_features, X, y, classif_obj): # keep last dimension\n",
    "    flatted_X = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "    flatted_X = pd.DataFrame(flatted_X)\n",
    "\n",
    "    flatted_y_new = y\n",
    "    if len(y.shape) == 2:\n",
    "        y_new = np.repeat(y[:, np.newaxis, :], X.shape[1], axis=1)\n",
    "        flatted_y_new = y_new.reshape(-1, y_new.shape[-1])\n",
    "        \n",
    "    flatted_y_new = flatted_y_new[:,classif_obj]\n",
    "\n",
    "    selected_features = mrmr_classif(X=flatted_X, y=flatted_y_new, K=num_features)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "f = feature_selector(64, cwt_train_loaded, y_train, 0)\n",
    "feature_selections = {\n",
    "    'PCA': {\n",
    "        'Valence': feature_selector(64, pca_train_loaded, y_train, 0), #1024x40x8064\n",
    "        'Arousal': feature_selector(64, pca_train_loaded, y_train, 1) #1024x40x8064\n",
    "    },\n",
    "    'WT': {\n",
    "        'Valence': feature_selector(64, cwt_train_loaded, y_train, 0), #1024x40x128\n",
    "        'Arousal': feature_selector(64, cwt_train_loaded, y_train, 1) #1024x40x128\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save file name\n",
    "prefix_output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"feature_selections.pkl\"\n",
    "\n",
    "# Save data\n",
    "with open(prefix_output_path + filename, 'wb') as file:\n",
    "    pickle.dump(feature_selections, file)\n",
    "\n",
    "print(f\"Data has been saved to file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73794484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:24.553390Z",
     "iopub.status.busy": "2024-12-14T02:19:24.553020Z",
     "iopub.status.idle": "2024-12-14T02:19:24.569787Z",
     "shell.execute_reply": "2024-12-14T02:19:24.568889Z"
    },
    "papermill": {
     "duration": 0.024719,
     "end_time": "2024-12-14T02:19:24.571368",
     "exception": false,
     "start_time": "2024-12-14T02:19:24.546649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PCA': {'Valence': [np.int64(117), np.int64(67), np.int64(42), np.int64(4), np.int64(44), np.int64(111), np.int64(81), np.int64(119), np.int64(99), np.int64(14), np.int64(54), np.int64(110), np.int64(45), np.int64(87), np.int64(48), np.int64(38), np.int64(40), np.int64(66), np.int64(98), np.int64(76), np.int64(70), np.int64(94), np.int64(2), np.int64(118), np.int64(28), np.int64(9), np.int64(121), np.int64(24), np.int64(125), np.int64(47), np.int64(23), np.int64(51), np.int64(95), np.int64(61), np.int64(30), np.int64(75), np.int64(101), np.int64(39), np.int64(29), np.int64(52), np.int64(22), np.int64(68), np.int64(57), np.int64(79), np.int64(7), np.int64(90), np.int64(6), np.int64(59), np.int64(127), np.int64(37), np.int64(97), np.int64(25), np.int64(73), np.int64(77), np.int64(85), np.int64(0), np.int64(36), np.int64(93), np.int64(113), np.int64(108), np.int64(62), np.int64(104), np.int64(5), np.int64(17)], 'Arousal': [np.int64(76), np.int64(1), np.int64(15), np.int64(123), np.int64(13), np.int64(19), np.int64(26), np.int64(85), np.int64(77), np.int64(69), np.int64(91), np.int64(7), np.int64(46), np.int64(38), np.int64(112), np.int64(125), np.int64(14), np.int64(3), np.int64(83), np.int64(5), np.int64(54), np.int64(62), np.int64(101), np.int64(47), np.int64(42), np.int64(48), np.int64(0), np.int64(102), np.int64(99), np.int64(116), np.int64(109), np.int64(11), np.int64(104), np.int64(71), np.int64(89), np.int64(16), np.int64(105), np.int64(8), np.int64(124), np.int64(67), np.int64(108), np.int64(30), np.int64(12), np.int64(53), np.int64(120), np.int64(28), np.int64(82), np.int64(68), np.int64(44), np.int64(126), np.int64(110), np.int64(43), np.int64(37), np.int64(107), np.int64(41), np.int64(23), np.int64(34), np.int64(24), np.int64(121), np.int64(31), np.int64(74), np.int64(81), np.int64(88), np.int64(59)]}, 'WT': {'Valence': [np.int64(58), np.int64(59), np.int64(57), np.int64(60), np.int64(56), np.int64(61), np.int64(55), np.int64(62), np.int64(54), np.int64(63), np.int64(64), np.int64(53), np.int64(65), np.int64(66), np.int64(52), np.int64(67), np.int64(68), np.int64(51), np.int64(69), np.int64(70), np.int64(71), np.int64(50), np.int64(72), np.int64(73), np.int64(32), np.int64(31), np.int64(49), np.int64(74), np.int64(33), np.int64(30), np.int64(75), np.int64(34), np.int64(76), np.int64(29), np.int64(35), np.int64(48), np.int64(77), np.int64(36), np.int64(28), np.int64(78), np.int64(37), np.int64(79), np.int64(27), np.int64(47), np.int64(38), np.int64(80), np.int64(81), np.int64(39), np.int64(26), np.int64(46), np.int64(82), np.int64(25), np.int64(40), np.int64(83), np.int64(24), np.int64(41), np.int64(45), np.int64(23), np.int64(84), np.int64(42), np.int64(22), np.int64(44), np.int64(43), np.int64(85)], 'Arousal': [np.int64(30), np.int64(58), np.int64(29), np.int64(31), np.int64(28), np.int64(59), np.int64(60), np.int64(57), np.int64(32), np.int64(61), np.int64(56), np.int64(27), np.int64(62), np.int64(63), np.int64(55), np.int64(33), np.int64(64), np.int64(54), np.int64(65), np.int64(66), np.int64(53), np.int64(26), np.int64(67), np.int64(34), np.int64(52), np.int64(68), np.int64(69), np.int64(51), np.int64(35), np.int64(70), np.int64(71), np.int64(25), np.int64(50), np.int64(72), np.int64(36), np.int64(73), np.int64(18), np.int64(49), np.int64(74), np.int64(37), np.int64(75), np.int64(24), np.int64(19), np.int64(76), np.int64(48), np.int64(17), np.int64(77), np.int64(38), np.int64(20), np.int64(78), np.int64(23), np.int64(21), np.int64(79), np.int64(47), np.int64(22), np.int64(39), np.int64(80), np.int64(46), np.int64(81), np.int64(40), np.int64(16), np.int64(82), np.int64(45), np.int64(83)]}}\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"feature_selections.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    feature_selection_loaded = pickle.load(file)\n",
    "\n",
    "print(feature_selection_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33322c24",
   "metadata": {
    "papermill": {
     "duration": 0.005405,
     "end_time": "2024-12-14T02:19:24.582361",
     "exception": false,
     "start_time": "2024-12-14T02:19:24.576956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b2179d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:24.594349Z",
     "iopub.status.busy": "2024-12-14T02:19:24.594092Z",
     "iopub.status.idle": "2024-12-14T02:19:24.802569Z",
     "shell.execute_reply": "2024-12-14T02:19:24.801686Z"
    },
    "papermill": {
     "duration": 0.216712,
     "end_time": "2024-12-14T02:19:24.804618",
     "exception": false,
     "start_time": "2024-12-14T02:19:24.587906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregated_data = [\n",
    "    ['WT', 'YES', 'VALENCE', {'TRAIN': (cwt_train_loaded[:, :, feature_selection_loaded['WT']['Valence']], y_train), \n",
    "                              'TEST': (cwt_test_loaded[:, :, feature_selection_loaded['WT']['Valence']], y_test)}],\n",
    "    ['WT', 'YES', 'AROUSAL', {'TRAIN': (cwt_train_loaded[:, :, feature_selection_loaded['WT']['Arousal']], y_train),\n",
    "                              'TEST': (cwt_test_loaded[:, :, feature_selection_loaded['WT']['Arousal']], y_test)}],\n",
    "\n",
    "    ['WT', 'NO', '*', {'TRAIN': (cwt_train_loaded, y_train), \n",
    "                       'TEST': (cwt_test_loaded, y_test)}],\n",
    "\n",
    "    ['PE', 'NO', '*', {'TRAIN': (pe_train_loaded, y_train), \n",
    "                       'TEST': (pe_test_loaded, y_test)}],\n",
    "\n",
    "    ['NONE', 'YES', 'VALENCE', {'TRAIN': (pca_train_loaded[:, :, feature_selection_loaded['PCA']['Valence']], y_train), \n",
    "                                'TEST': (pca_test_loaded[:, :, feature_selection_loaded['PCA']['Valence']], y_test)}],\n",
    "    ['NONE', 'YES', 'AROUSAL', {'TRAIN': (pca_train_loaded[:, :, feature_selection_loaded['PCA']['Arousal']], y_train), \n",
    "                                'TEST': (pca_test_loaded[:, :, feature_selection_loaded['PCA']['Arousal']], y_test)}],\n",
    "\n",
    "    ['NONE', 'NO', '*', {'TRAIN': (pca_train_loaded, y_train), \n",
    "                         'TEST': (pca_test_loaded, y_test)}],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e60c4",
   "metadata": {
    "papermill": {
     "duration": 0.005819,
     "end_time": "2024-12-14T02:19:24.817106",
     "exception": false,
     "start_time": "2024-12-14T02:19:24.811287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054779f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:24.846513Z",
     "iopub.status.busy": "2024-12-14T02:19:24.846253Z",
     "iopub.status.idle": "2024-12-14T02:19:27.922385Z",
     "shell.execute_reply": "2024-12-14T02:19:27.921487Z"
    },
    "papermill": {
     "duration": 3.084379,
     "end_time": "2024-12-14T02:19:27.924447",
     "exception": false,
     "start_time": "2024-12-14T02:19:24.840068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def calculate_metric(metric, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the value of a metric based on the input metric name.\n",
    "\n",
    "    Args:\n",
    "        metric (str): Metric name, one of the ['Acc', 'Sens', 'Spec', 'Prec', 'F-measure'].\n",
    "        y_true (array-like): Actual label.\n",
    "        y_pred (array-like): Predictive label.\n",
    "\n",
    "    Returns:\n",
    "        float: Value of selected metric.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the metric is not in the supported list.\n",
    "    \"\"\"\n",
    "    metric = metric.lower()  # Convert metrics to lowercase for easier handling\n",
    "\n",
    "    if metric == 'acc':\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    elif metric == 'sens':  # Sensitivity (Recall)\n",
    "        return recall_score(y_true, y_pred, average='binary')\n",
    "    elif metric == 'spec':  # Specificity\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        return tn / (tn + fp) if (tn + fp) != 0 else 0.0\n",
    "    elif metric == 'prec':  # Precision\n",
    "        return precision_score(y_true, y_pred, average='binary')\n",
    "    elif metric == 'f-measure':  # F1-Score\n",
    "        return f1_score(y_true, y_pred, average='binary')\n",
    "    else:\n",
    "        raise ValueError(f\"Metric '{metric}' not supported. Please select one of the ['Acc', 'Sens', 'Spec', 'Prec', 'F-measure'].\")\n",
    "    \n",
    "\n",
    "def evaluate(model, name_model, classifi_obj, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the provided data.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model.\n",
    "        name_model: The type of model ('rnn', 'cnn', etc.)\n",
    "        classifi_obj: Whether it's a classification problem (True/False).\n",
    "        X: Input data.\n",
    "        y: True labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Metrics like accuracy, sensitivity, specificity, etc.\n",
    "    \"\"\"\n",
    "    if name_model == 'rnn' or name_model == 'cnn':\n",
    "        # Handle PyTorch models (RNN, CNN, etc.)\n",
    "        model.eval()  # Set model to evaluation mode if it's a PyTorch model\n",
    "\n",
    "        if classifi_obj:\n",
    "            X = X.permute(0, 2, 1)  # Assuming the model expects input (batch_size, seq_len, feature_dim)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X)  # PyTorch models are callable\n",
    "            y_pred = F.sigmoid(y_pred) >= 0.5  # For binary classification (change if necessary)\n",
    "            y_pred = y_pred.float().cpu().numpy()\n",
    "\n",
    "    else:\n",
    "        # Handle scikit-learn models (RandomForest, etc.)\n",
    "        # If the model is not a PyTorch model, reshape the input to 2D (n_samples, n_features)\n",
    "        n_samples, n_channels, n_features = X.shape\n",
    "        X_reshaped = X.reshape(n_samples, n_channels * n_features)  # Flatten the channels and features\n",
    "        \n",
    "        y_pred = model.predict(X_reshaped)  # Use the `predict` method for scikit-learn models\n",
    "        y_pred = y_pred.astype(float)  # Ensure the output is a float for metric calculations\n",
    "\n",
    "    # Convert y_true to a 1D array if it's multilabel-indicator\n",
    "    if len(y.shape) > 1 and y.shape[1] > 1:  # Check if y_true is multilabel (e.g., one-hot encoded)\n",
    "        y = np.argmax(y, axis=1)  # Convert to class labels\n",
    "\n",
    "    # Calculate metrics (accuracy, precision, etc.)\n",
    "    result = {\n",
    "        \"Acc\": calculate_metric(\"Acc\", y, y_pred),\n",
    "        \"Sens\": calculate_metric(\"Sens\", y, y_pred),\n",
    "        \"Spec\": calculate_metric(\"Spec\", y, y_pred),\n",
    "        \"Prec\": calculate_metric(\"Prec\", y, y_pred),\n",
    "        \"F-measure\": calculate_metric(\"F-measure\", y, y_pred),\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "169eec22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:27.937573Z",
     "iopub.status.busy": "2024-12-14T02:19:27.937191Z",
     "iopub.status.idle": "2024-12-14T02:19:27.955607Z",
     "shell.execute_reply": "2024-12-14T02:19:27.954818Z"
    },
    "papermill": {
     "duration": 0.026855,
     "end_time": "2024-12-14T02:19:27.957249",
     "exception": false,
     "start_time": "2024-12-14T02:19:27.930394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_config_train_ml_model(X_train, y_train, X_test, y_test, name_model):\n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'name_model': name_model.lower()\n",
    "    }\n",
    "\n",
    "def train_ml_model(model, classifi_obj, **kwargs):\n",
    "    name_model = kwargs.get('name_model').lower()\n",
    "    X_train = kwargs.get('X_train')\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    y = kwargs.get('y_train')[:, classifi_obj]\n",
    "    model.fit(X_train, y)\n",
    "\n",
    "def setup_config_train(X_train, y_train, X_test, y_test, name_model):\n",
    "    name_model = name_model.lower()\n",
    "    return setup_config_train_ml_model(X_train, y_train, X_test, y_test, name_model)\n",
    "\n",
    "def train_model(model, classifi_obj, **kwargs):\n",
    "    if kwargs.get('name_model').lower() in ['svm', 'rf', 'lr', 'knn', 'gb', 'xgboost', 'adaboost', 'dt']:\n",
    "\n",
    "        return train_ml_model(model, classifi_obj, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95e75362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:27.969415Z",
     "iopub.status.busy": "2024-12-14T02:19:27.969197Z",
     "iopub.status.idle": "2024-12-14T02:19:27.981569Z",
     "shell.execute_reply": "2024-12-14T02:19:27.980872Z"
    },
    "papermill": {
     "duration": 0.020523,
     "end_time": "2024-12-14T02:19:27.983154",
     "exception": false,
     "start_time": "2024-12-14T02:19:27.962631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "def get_model(**kwargs):\n",
    "    model = None\n",
    "    name_model = kwargs.get('name_model').lower()\n",
    "    \n",
    "    device = kwargs.get('device', DEVICE)\n",
    "    \n",
    "    if name_model == 'svm':\n",
    "        model = SVC(kernel='rbf')\n",
    "        \n",
    "    elif name_model == 'rf':\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_leaf=5, random_state=42)\n",
    "\n",
    "    elif name_model == 'lr':\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "    elif name_model == 'knn':\n",
    "        model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    elif name_model == 'dt':\n",
    "        model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Model {name_model} not recognized. Please choose from 'svm', 'rf', 'lr', 'knn', 'gb', 'xgboost', 'adaboost', 'dt'.\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cbba155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T02:19:28.011763Z",
     "iopub.status.busy": "2024-12-14T02:19:28.011485Z",
     "iopub.status.idle": "2024-12-14T02:21:05.570402Z",
     "shell.execute_reply": "2024-12-14T02:21:05.569408Z"
    },
    "papermill": {
     "duration": 97.566902,
     "end_time": "2024-12-14T02:21:05.572239",
     "exception": false,
     "start_time": "2024-12-14T02:19:28.005337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 1: ('rf', 'WT', 'YES', 'AROUSAL', 73.828125)\n",
      "experiment 2: ('rf', 'WT', 'YES', 'VALENCE', 78.90625)\n",
      "experiment 3: ('rf', 'WT', 'NO', 'AROUSAL', 74.21875)\n",
      "experiment 4: ('rf', 'WT', 'NO', 'VALENCE', 77.734375)\n",
      "experiment 5: ('rf', 'PE', 'NO', 'AROUSAL', 78.125)\n",
      "experiment 6: ('rf', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 7: ('rf', 'NONE', 'YES', 'AROUSAL', 78.515625)\n",
      "experiment 8: ('rf', 'NONE', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 9: ('rf', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 10: ('rf', 'NONE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 11: ('svm', 'WT', 'YES', 'AROUSAL', 77.734375)\n",
      "experiment 12: ('svm', 'WT', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 13: ('svm', 'WT', 'NO', 'AROUSAL', 77.734375)\n",
      "experiment 14: ('svm', 'WT', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 15: ('svm', 'PE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 16: ('svm', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 17: ('svm', 'NONE', 'YES', 'AROUSAL', 78.515625)\n",
      "experiment 18: ('svm', 'NONE', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 19: ('svm', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 20: ('svm', 'NONE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 21: ('lr', 'WT', 'YES', 'AROUSAL', 76.5625)\n",
      "experiment 22: ('lr', 'WT', 'YES', 'VALENCE', 78.125)\n",
      "experiment 23: ('lr', 'WT', 'NO', 'AROUSAL', 75.0)\n",
      "experiment 24: ('lr', 'WT', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 25: ('lr', 'PE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 26: ('lr', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 27: ('lr', 'NONE', 'YES', 'AROUSAL', 78.515625)\n",
      "experiment 28: ('lr', 'NONE', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 29: ('lr', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 30: ('lr', 'NONE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 31: ('knn', 'WT', 'YES', 'AROUSAL', 70.703125)\n",
      "experiment 32: ('knn', 'WT', 'YES', 'VALENCE', 69.140625)\n",
      "experiment 33: ('knn', 'WT', 'NO', 'AROUSAL', 70.3125)\n",
      "experiment 34: ('knn', 'WT', 'NO', 'VALENCE', 67.96875)\n",
      "experiment 35: ('knn', 'PE', 'NO', 'AROUSAL', 71.875)\n",
      "experiment 36: ('knn', 'PE', 'NO', 'VALENCE', 74.609375)\n",
      "experiment 37: ('knn', 'NONE', 'YES', 'AROUSAL', 76.953125)\n",
      "experiment 38: ('knn', 'NONE', 'YES', 'VALENCE', 76.953125)\n",
      "experiment 39: ('knn', 'NONE', 'NO', 'AROUSAL', 76.5625)\n",
      "experiment 40: ('knn', 'NONE', 'NO', 'VALENCE', 73.4375)\n",
      "experiment 41: ('dt', 'WT', 'YES', 'AROUSAL', 68.359375)\n",
      "experiment 42: ('dt', 'WT', 'YES', 'VALENCE', 68.75)\n",
      "experiment 43: ('dt', 'WT', 'NO', 'AROUSAL', 66.015625)\n",
      "experiment 44: ('dt', 'WT', 'NO', 'VALENCE', 67.578125)\n",
      "experiment 45: ('dt', 'PE', 'NO', 'AROUSAL', 67.578125)\n",
      "experiment 46: ('dt', 'PE', 'NO', 'VALENCE', 66.796875)\n",
      "experiment 47: ('dt', 'NONE', 'YES', 'AROUSAL', 68.75)\n",
      "experiment 48: ('dt', 'NONE', 'YES', 'VALENCE', 63.671875)\n",
      "experiment 49: ('dt', 'NONE', 'NO', 'AROUSAL', 70.3125)\n",
      "experiment 50: ('dt', 'NONE', 'NO', 'VALENCE', 67.578125)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "evaluates = []\n",
    "i = 0\n",
    "for name_model in ['rf', 'svm', 'lr', 'knn', 'dt']:\n",
    "    for experiment in aggregated_data:\n",
    "        data = experiment[-1]\n",
    "        classifi_objs = [0] if experiment[2] == 'VALENCE' else [1] if experiment[2] == 'AROUSAL' else [0,1]\n",
    "        (X_train_data, y_train_data), (X_test_data, y_test_data) = data['TRAIN'], data['TEST']\n",
    "        # print(X_test_data.shape, X_train_data.shape)\n",
    "        for classifi_obj in classifi_objs:\n",
    "            config = {\n",
    "                'length_signal': X_train_data.shape[-1],\n",
    "                'name_model': name_model\n",
    "            }\n",
    "            \n",
    "            model = get_model(**config)\n",
    "\n",
    "            # print(name_model)\n",
    "            config_train = setup_config_train(X_train_data, y_train_data, X_test_data, y_test_data, name_model)\n",
    "            train_model(model, classifi_obj, **config_train)\n",
    "\n",
    "            motion = 'VALENCE' if classifi_obj else 'AROUSAL'\n",
    "\n",
    "            models.append((*experiment[:2], motion, model))\n",
    "\n",
    "            info = (\n",
    "                name_model,\n",
    "                *experiment[:2], \n",
    "                motion,\n",
    "                evaluate(model, name_model, classifi_obj, X_test_data, y_test_data)['Acc']*100\n",
    "            )\n",
    "            i += 1\n",
    "            print(f'experiment {i}: {info}')\n",
    "            evaluates.append(info)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf198afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to file C:\\Users\\ferri\\Downloads\\PoliTO\\Tesi\\DSs\\Emotion-Stress\\deap-dataset\\pca_data_train_test_rnn.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "DEVICE = 'cpu' \n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, rnn_type=\"GRU\", device=DEVICE):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "\n",
    "        # Choose the RNN type (LSTM or GRU)\n",
    "        if rnn_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        elif rnn_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN type. Use 'LSTM' or 'GRU'.\")\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, feature_extraction=False):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # Reshape if necessary\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.view(batch_size, seq_len, self.input_size)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device) if isinstance(self.rnn, nn.LSTM) else None\n",
    "\n",
    "        # Pass through the RNN\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0)) if isinstance(self.rnn, nn.LSTM) else self.rnn(x, h0)\n",
    "\n",
    "        if feature_extraction:\n",
    "            return out\n",
    "\n",
    "        # Take the last hidden state\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Output layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, outs_channels, output_size, length_signal, device=DEVICE):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = [in_channels] + outs_channels\n",
    "        self.model = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, device=device),\n",
    "                nn.BatchNorm1d(out_channels, device=device),\n",
    "                nn.ReLU()\n",
    "            ) for in_channels, out_channels in zip(channels[:-1], channels[1:]) ]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(outs_channels[-1] * length_signal, output_size, device=device) \n",
    "\n",
    "    def forward(self, x, feature_extraction=False):\n",
    "        x = self.model(x)\n",
    "\n",
    "        if feature_extraction:\n",
    "            # If we want feature extraction, return features before the fully connected layer\n",
    "            return x\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def pca_data(data, k):\n",
    "    # Reshape the data into (n_samples, n_features) to prepare for PCA\n",
    "    n_samples, n_channels, n_features = data.shape\n",
    "    data_reshaped = data.reshape(n_samples * n_channels, n_features)\n",
    "    \n",
    "    # Data Normalization\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_reshaped)\n",
    "    \n",
    "    # Apply PCA to reduce dimensionality\n",
    "    pca = PCA(n_components=k)\n",
    "    data_pca = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    # Reshape back to (n_samples, n_channels, k)\n",
    "    data_pca_reshaped = data_pca.reshape(n_samples, n_channels, k)\n",
    "    \n",
    "    return data_pca_reshaped\n",
    "\n",
    "\n",
    "def feature_extraction_with_rnn_cnn(X, y, model_type=\"CNN\", k=128):\n",
    "    \"\"\"\n",
    "    Extract features from the RNN or CNN model and return the extracted features.\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): The input data (n_samples, n_channels, n_features).\n",
    "        y (numpy.ndarray): The labels (n_samples, num_classes).\n",
    "        model_type (str): The model to use for feature extraction, either \"RNN\" or \"CNN\".\n",
    "        k (int): Number of principal components to keep after PCA.\n",
    "\n",
    "    Returns:\n",
    "        extracted_features (numpy.ndarray): The extracted features from the model.\n",
    "    \"\"\"\n",
    "    # Apply PCA\n",
    "    pca_data_transformed = pca_data(X, k=k)\n",
    "\n",
    "    # Convert to tensor\n",
    "    pca_data_tensor = torch.Tensor(pca_data_transformed).to(DEVICE)\n",
    "    \n",
    "    # Reshape the data to have 1 channel instead of 40\n",
    "    pca_data_tensor = pca_data_tensor.reshape(pca_data_tensor.shape[0], 1, pca_data_tensor.shape[1] * pca_data_tensor.shape[2])\n",
    "\n",
    "    # Choose model\n",
    "    if model_type == \"CNN\":\n",
    "        model = CNNModel(in_channels=1, outs_channels=[32, 64], output_size=10, length_signal=k, device=DEVICE)\n",
    "    elif model_type == \"RNN\":\n",
    "        model = RNNModel(input_size=5120, hidden_size=128, num_layers=2, output_size=10, device=DEVICE)\n",
    "    else:\n",
    "        raise ValueError(\"Model type must be either 'RNN' or 'CNN'.\")\n",
    "\n",
    "    # Extract features using the model\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        extracted_features = model(pca_data_tensor, feature_extraction=True)  # Extract features\n",
    "\n",
    "    return extracted_features\n",
    "\n",
    "\n",
    "# Assuming you have X_train, y_train, X_test, and y_test already loaded\n",
    "\n",
    "# Select model type based on input\n",
    "model_type = \"RNN\" \n",
    "\n",
    "# Feature extraction for train and test sets\n",
    "if model_type == \"CNN\":\n",
    "    features_train = feature_extraction_with_rnn_cnn(X_train, y_train, model_type=\"CNN\", k=128)\n",
    "    features_test = feature_extraction_with_rnn_cnn(X_test, y_test, model_type=\"CNN\", k=128)\n",
    "elif model_type == \"RNN\":\n",
    "    features_train = feature_extraction_with_rnn_cnn(X_train, y_train, model_type=\"RNN\", k=128)\n",
    "    features_test = feature_extraction_with_rnn_cnn(X_test, y_test, model_type=\"RNN\", k=128)\n",
    "\n",
    "# Save the extracted features to a pickle file\n",
    "output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = f\"pca_data_train_test_{model_type.lower()}.pkl\"  # File name will include model type\n",
    "\n",
    "with open(output_path + filename, 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'train': features_train,\n",
    "        'test': features_test\n",
    "    }, file)\n",
    "\n",
    "print(f\"Data has been saved to file {output_path + filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6e3a299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size pca_train: torch.Size([1024, 1, 128])\n",
      "Size pca_test: torch.Size([256, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "if model_type == \"CNN\":\n",
    "    filename = \"pca_data_train_test_cnn.pkl\"\n",
    "elif model_type == \"RNN\":\n",
    "    filename = \"pca_data_train_test_rnn.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "# print(data)\n",
    "\n",
    "# Data retrieval\n",
    "pca_train_loaded = data['train']\n",
    "pca_test_loaded = data['test']\n",
    "\n",
    "print(\"Size pca_train:\", pca_train_loaded.shape)\n",
    "print(\"Size pca_test:\", pca_test_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "216ec19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:13<00:00,  4.61it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 34.44it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 38.44it/s]\n",
      "100%|██████████| 64/64 [00:13<00:00,  4.65it/s]\n",
      "100%|██████████| 64/64 [00:13<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to file feature_selections.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "import pandas as pd\n",
    "\n",
    "def feature_selector(num_features, X, y, classif_obj): # keep last dimension\n",
    "    flatted_X = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "    flatted_X = pd.DataFrame(flatted_X)\n",
    "\n",
    "    flatted_y_new = y\n",
    "    if len(y.shape) == 2:\n",
    "        y_new = np.repeat(y[:, np.newaxis, :], X.shape[1], axis=1)\n",
    "        flatted_y_new = y_new.reshape(-1, y_new.shape[-1])\n",
    "        \n",
    "    flatted_y_new = flatted_y_new[:,classif_obj]\n",
    "\n",
    "    selected_features = mrmr_classif(X=flatted_X, y=flatted_y_new, K=num_features)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "f = feature_selector(64, cwt_train_loaded, y_train, 0)\n",
    "feature_selections = {\n",
    "    'PCA': {\n",
    "        'Valence': feature_selector(64, pca_train_loaded, y_train, 0), #1024x40x8064\n",
    "        'Arousal': feature_selector(64, pca_train_loaded, y_train, 1) #1024x40x8064\n",
    "    },\n",
    "    'WT': {\n",
    "        'Valence': feature_selector(64, cwt_train_loaded, y_train, 0), #1024x40x128\n",
    "        'Arousal': feature_selector(64, cwt_train_loaded, y_train, 1) #1024x40x128\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save file name\n",
    "prefix_output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"feature_selections.pkl\"\n",
    "\n",
    "# Save data\n",
    "with open(prefix_output_path + filename, 'wb') as file:\n",
    "    pickle.dump(feature_selections, file)\n",
    "\n",
    "print(f\"Data has been saved to file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf57bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PCA': {'Valence': [np.int64(45), np.int64(124), np.int64(36), np.int64(17), np.int64(56), np.int64(79), np.int64(12), np.int64(32), np.int64(102), np.int64(26), np.int64(63), np.int64(66), np.int64(105), np.int64(58), np.int64(70), np.int64(127), np.int64(117), np.int64(59), np.int64(103), np.int64(89), np.int64(65), np.int64(106), np.int64(107), np.int64(72), np.int64(48), np.int64(86), np.int64(0), np.int64(51), np.int64(74), np.int64(55), np.int64(90), np.int64(119), np.int64(52), np.int64(10), np.int64(88), np.int64(97), np.int64(104), np.int64(29), np.int64(123), np.int64(2), np.int64(116), np.int64(101), np.int64(62), np.int64(64), np.int64(35), np.int64(5), np.int64(85), np.int64(38), np.int64(99), np.int64(31), np.int64(113), np.int64(19), np.int64(118), np.int64(120), np.int64(71), np.int64(11), np.int64(109), np.int64(1), np.int64(95), np.int64(28), np.int64(81), np.int64(100), np.int64(77), np.int64(40)], 'Arousal': [np.int64(32), np.int64(69), np.int64(34), np.int64(109), np.int64(45), np.int64(48), np.int64(36), np.int64(90), np.int64(125), np.int64(43), np.int64(124), np.int64(2), np.int64(17), np.int64(103), np.int64(111), np.int64(47), np.int64(118), np.int64(37), np.int64(117), np.int64(0), np.int64(83), np.int64(98), np.int64(97), np.int64(25), np.int64(19), np.int64(64), np.int64(33), np.int64(85), np.int64(55), np.int64(74), np.int64(11), np.int64(13), np.int64(58), np.int64(116), np.int64(38), np.int64(96), np.int64(77), np.int64(62), np.int64(63), np.int64(126), np.int64(44), np.int64(9), np.int64(113), np.int64(10), np.int64(105), np.int64(104), np.int64(16), np.int64(21), np.int64(101), np.int64(26), np.int64(94), np.int64(31), np.int64(57), np.int64(12), np.int64(8), np.int64(53), np.int64(14), np.int64(120), np.int64(82), np.int64(88), np.int64(46), np.int64(114), np.int64(123), np.int64(92)]}, 'WT': {'Valence': [np.int64(58), np.int64(59), np.int64(57), np.int64(60), np.int64(56), np.int64(61), np.int64(55), np.int64(62), np.int64(54), np.int64(63), np.int64(64), np.int64(53), np.int64(65), np.int64(66), np.int64(52), np.int64(67), np.int64(68), np.int64(51), np.int64(69), np.int64(70), np.int64(71), np.int64(50), np.int64(72), np.int64(73), np.int64(32), np.int64(31), np.int64(49), np.int64(74), np.int64(33), np.int64(30), np.int64(75), np.int64(34), np.int64(76), np.int64(29), np.int64(35), np.int64(48), np.int64(77), np.int64(36), np.int64(28), np.int64(78), np.int64(37), np.int64(79), np.int64(27), np.int64(47), np.int64(38), np.int64(80), np.int64(81), np.int64(39), np.int64(26), np.int64(46), np.int64(82), np.int64(25), np.int64(40), np.int64(83), np.int64(24), np.int64(41), np.int64(45), np.int64(23), np.int64(84), np.int64(42), np.int64(22), np.int64(44), np.int64(43), np.int64(85)], 'Arousal': [np.int64(30), np.int64(58), np.int64(29), np.int64(31), np.int64(28), np.int64(59), np.int64(60), np.int64(57), np.int64(32), np.int64(61), np.int64(56), np.int64(27), np.int64(62), np.int64(63), np.int64(55), np.int64(33), np.int64(64), np.int64(54), np.int64(65), np.int64(66), np.int64(53), np.int64(26), np.int64(67), np.int64(34), np.int64(52), np.int64(68), np.int64(69), np.int64(51), np.int64(35), np.int64(70), np.int64(71), np.int64(25), np.int64(50), np.int64(72), np.int64(36), np.int64(73), np.int64(18), np.int64(49), np.int64(74), np.int64(37), np.int64(75), np.int64(24), np.int64(19), np.int64(76), np.int64(48), np.int64(17), np.int64(77), np.int64(38), np.int64(20), np.int64(78), np.int64(23), np.int64(21), np.int64(79), np.int64(47), np.int64(22), np.int64(39), np.int64(80), np.int64(46), np.int64(81), np.int64(40), np.int64(16), np.int64(82), np.int64(45), np.int64(83)]}}\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"feature_selections.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    feature_selection_loaded = pickle.load(file)\n",
    "\n",
    "print(feature_selection_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cfeffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = [\n",
    "    ['WT', 'YES', 'VALENCE', {'TRAIN': (cwt_train_loaded[:, :, feature_selection_loaded['WT']['Valence']], y_train), \n",
    "                              'TEST': (cwt_test_loaded[:, :, feature_selection_loaded['WT']['Valence']], y_test)}],\n",
    "    ['WT', 'YES', 'AROUSAL', {'TRAIN': (cwt_train_loaded[:, :, feature_selection_loaded['WT']['Arousal']], y_train),\n",
    "                              'TEST': (cwt_test_loaded[:, :, feature_selection_loaded['WT']['Arousal']], y_test)}],\n",
    "\n",
    "    ['WT', 'NO', '*', {'TRAIN': (cwt_train_loaded, y_train), \n",
    "                       'TEST': (cwt_test_loaded, y_test)}],\n",
    "\n",
    "    ['PE', 'NO', '*', {'TRAIN': (pe_train_loaded, y_train), \n",
    "                       'TEST': (pe_test_loaded, y_test)}],\n",
    "\n",
    "    ['NONE', 'YES', 'VALENCE', {'TRAIN': (pca_train_loaded[:, :, feature_selection_loaded['PCA']['Valence']], y_train), \n",
    "                                'TEST': (pca_test_loaded[:, :, feature_selection_loaded['PCA']['Valence']], y_test)}],\n",
    "    ['NONE', 'YES', 'AROUSAL', {'TRAIN': (pca_train_loaded[:, :, feature_selection_loaded['PCA']['Arousal']], y_train), \n",
    "                                'TEST': (pca_test_loaded[:, :, feature_selection_loaded['PCA']['Arousal']], y_test)}],\n",
    "\n",
    "    ['NONE', 'NO', '*', {'TRAIN': (pca_train_loaded, y_train), \n",
    "                         'TEST': (pca_test_loaded, y_test)}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d512412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 1: ('rf', 'WT', 'YES', 'AROUSAL', 73.828125)\n",
      "experiment 2: ('rf', 'WT', 'YES', 'VALENCE', 78.90625)\n",
      "experiment 3: ('rf', 'WT', 'NO', 'AROUSAL', 74.21875)\n",
      "experiment 4: ('rf', 'WT', 'NO', 'VALENCE', 77.734375)\n",
      "experiment 5: ('rf', 'PE', 'NO', 'AROUSAL', 78.125)\n",
      "experiment 6: ('rf', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 7: ('rf', 'NONE', 'YES', 'AROUSAL', 78.515625)\n",
      "experiment 8: ('rf', 'NONE', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 9: ('rf', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 10: ('rf', 'NONE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 11: ('svm', 'WT', 'YES', 'AROUSAL', 77.734375)\n",
      "experiment 12: ('svm', 'WT', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 13: ('svm', 'WT', 'NO', 'AROUSAL', 77.734375)\n",
      "experiment 14: ('svm', 'WT', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 15: ('svm', 'PE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 16: ('svm', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 17: ('svm', 'NONE', 'YES', 'AROUSAL', 78.515625)\n",
      "experiment 18: ('svm', 'NONE', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 19: ('svm', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 20: ('svm', 'NONE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 21: ('lr', 'WT', 'YES', 'AROUSAL', 76.5625)\n",
      "experiment 22: ('lr', 'WT', 'YES', 'VALENCE', 78.125)\n",
      "experiment 23: ('lr', 'WT', 'NO', 'AROUSAL', 75.0)\n",
      "experiment 24: ('lr', 'WT', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 25: ('lr', 'PE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 26: ('lr', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 27: ('lr', 'NONE', 'YES', 'AROUSAL', 76.953125)\n",
      "experiment 28: ('lr', 'NONE', 'YES', 'VALENCE', 77.34375)\n",
      "experiment 29: ('lr', 'NONE', 'NO', 'AROUSAL', 74.21875)\n",
      "experiment 30: ('lr', 'NONE', 'NO', 'VALENCE', 78.125)\n",
      "experiment 31: ('knn', 'WT', 'YES', 'AROUSAL', 70.703125)\n",
      "experiment 32: ('knn', 'WT', 'YES', 'VALENCE', 69.140625)\n",
      "experiment 33: ('knn', 'WT', 'NO', 'AROUSAL', 70.3125)\n",
      "experiment 34: ('knn', 'WT', 'NO', 'VALENCE', 67.96875)\n",
      "experiment 35: ('knn', 'PE', 'NO', 'AROUSAL', 71.875)\n",
      "experiment 36: ('knn', 'PE', 'NO', 'VALENCE', 74.609375)\n",
      "experiment 37: ('knn', 'NONE', 'YES', 'AROUSAL', 76.953125)\n",
      "experiment 38: ('knn', 'NONE', 'YES', 'VALENCE', 75.78125)\n",
      "experiment 39: ('knn', 'NONE', 'NO', 'AROUSAL', 75.0)\n",
      "experiment 40: ('knn', 'NONE', 'NO', 'VALENCE', 75.390625)\n",
      "experiment 41: ('dt', 'WT', 'YES', 'AROUSAL', 68.359375)\n",
      "experiment 42: ('dt', 'WT', 'YES', 'VALENCE', 68.75)\n",
      "experiment 43: ('dt', 'WT', 'NO', 'AROUSAL', 66.015625)\n",
      "experiment 44: ('dt', 'WT', 'NO', 'VALENCE', 67.578125)\n",
      "experiment 45: ('dt', 'PE', 'NO', 'AROUSAL', 67.578125)\n",
      "experiment 46: ('dt', 'PE', 'NO', 'VALENCE', 66.796875)\n",
      "experiment 47: ('dt', 'NONE', 'YES', 'AROUSAL', 74.21875)\n",
      "experiment 48: ('dt', 'NONE', 'YES', 'VALENCE', 64.0625)\n",
      "experiment 49: ('dt', 'NONE', 'NO', 'AROUSAL', 75.78125)\n",
      "experiment 50: ('dt', 'NONE', 'NO', 'VALENCE', 64.453125)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "evaluates = []\n",
    "i = 0\n",
    "for name_model in ['rf', 'svm', 'lr', 'knn', 'dt']:\n",
    "    for experiment in aggregated_data:\n",
    "        data = experiment[-1]\n",
    "        classifi_objs = [0] if experiment[2] == 'VALENCE' else [1] if experiment[2] == 'AROUSAL' else [0,1]\n",
    "        (X_train_data, y_train_data), (X_test_data, y_test_data) = data['TRAIN'], data['TEST']\n",
    "        # print(X_test_data.shape, X_train_data.shape)\n",
    "        for classifi_obj in classifi_objs:\n",
    "            config = {\n",
    "                'length_signal': X_train_data.shape[-1],\n",
    "                'name_model': name_model\n",
    "            }\n",
    "            \n",
    "            model = get_model(**config)\n",
    "\n",
    "            # print(name_model)\n",
    "            config_train = setup_config_train(X_train_data, y_train_data, X_test_data, y_test_data, name_model)\n",
    "            train_model(model, classifi_obj, **config_train)\n",
    "\n",
    "            motion = 'VALENCE' if classifi_obj else 'AROUSAL'\n",
    "\n",
    "            models.append((*experiment[:2], motion, model))\n",
    "\n",
    "            info = (\n",
    "                name_model,\n",
    "                *experiment[:2], \n",
    "                motion,\n",
    "                evaluate(model, name_model, classifi_obj, X_test_data, y_test_data)['Acc']*100\n",
    "            )\n",
    "            i += 1\n",
    "            print(f'experiment {i}: {info}')\n",
    "            evaluates.append(info)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee449fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to file C:\\Users\\ferri\\Downloads\\PoliTO\\Tesi\\DSs\\Emotion-Stress\\deap-dataset\\pca_data_train_test_cnn.pkl\n"
     ]
    }
   ],
   "source": [
    "# Select model type based on input\n",
    "model_type = \"CNN\" \n",
    "\n",
    "# Feature extraction for train and test sets\n",
    "if model_type == \"CNN\":\n",
    "    features_train = feature_extraction_with_rnn_cnn(X_train, y_train, model_type=\"CNN\", k=128)\n",
    "    features_test = feature_extraction_with_rnn_cnn(X_test, y_test, model_type=\"CNN\", k=128)\n",
    "elif model_type == \"RNN\":\n",
    "    features_train = feature_extraction_with_rnn_cnn(X_train, y_train, model_type=\"RNN\", k=128)\n",
    "    features_test = feature_extraction_with_rnn_cnn(X_test, y_test, model_type=\"RNN\", k=128)\n",
    "\n",
    "# Save the extracted features to a pickle file\n",
    "output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = f\"pca_data_train_test_{model_type.lower()}.pkl\"  # File name will include model type\n",
    "\n",
    "with open(output_path + filename, 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'train': features_train,\n",
    "        'test': features_test\n",
    "    }, file)\n",
    "\n",
    "print(f\"Data has been saved to file {output_path + filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e204a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size pca_train: torch.Size([1024, 64, 5120])\n",
      "Size pca_test: torch.Size([256, 64, 5120])\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "if model_type == \"CNN\":\n",
    "    filename = \"pca_data_train_test_cnn.pkl\"\n",
    "elif model_type == \"RNN\":\n",
    "    filename = \"pca_data_train_test_rnn.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "# print(data)\n",
    "\n",
    "# Data retrieval\n",
    "pca_train_loaded = data['train']\n",
    "pca_test_loaded = data['test']\n",
    "\n",
    "print(\"Size pca_train:\", pca_train_loaded.shape)\n",
    "print(\"Size pca_test:\", pca_test_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a836fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:13<00:00,  4.59it/s]\n",
      "100%|██████████| 64/64 [02:45<00:00,  2.58s/it]\n",
      "100%|██████████| 64/64 [02:43<00:00,  2.56s/it]\n",
      "100%|██████████| 64/64 [00:13<00:00,  4.63it/s]\n",
      "100%|██████████| 64/64 [00:13<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to file feature_selections.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "import pandas as pd\n",
    "\n",
    "def feature_selector(num_features, X, y, classif_obj): # keep last dimension\n",
    "    flatted_X = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "    flatted_X = pd.DataFrame(flatted_X)\n",
    "\n",
    "    flatted_y_new = y\n",
    "    if len(y.shape) == 2:\n",
    "        y_new = np.repeat(y[:, np.newaxis, :], X.shape[1], axis=1)\n",
    "        flatted_y_new = y_new.reshape(-1, y_new.shape[-1])\n",
    "        \n",
    "    flatted_y_new = flatted_y_new[:,classif_obj]\n",
    "\n",
    "    selected_features = mrmr_classif(X=flatted_X, y=flatted_y_new, K=num_features)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "f = feature_selector(64, cwt_train_loaded, y_train, 0)\n",
    "feature_selections = {\n",
    "    'PCA': {\n",
    "        'Valence': feature_selector(64, pca_train_loaded, y_train, 0), #1024x40x8064\n",
    "        'Arousal': feature_selector(64, pca_train_loaded, y_train, 1) #1024x40x8064\n",
    "    },\n",
    "    'WT': {\n",
    "        'Valence': feature_selector(64, cwt_train_loaded, y_train, 0), #1024x40x128\n",
    "        'Arousal': feature_selector(64, cwt_train_loaded, y_train, 1) #1024x40x128\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save file name\n",
    "prefix_output_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"feature_selections.pkl\"\n",
    "\n",
    "# Save data\n",
    "with open(prefix_output_path + filename, 'wb') as file:\n",
    "    pickle.dump(feature_selections, file)\n",
    "\n",
    "print(f\"Data has been saved to file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e3186c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PCA': {'Valence': [np.int64(4867), np.int64(4606), np.int64(4892), np.int64(4890), np.int64(4894), np.int64(4893), np.int64(4895), np.int64(4868), np.int64(4896), np.int64(4891), np.int64(4869), np.int64(4903), np.int64(4889), np.int64(4884), np.int64(4756), np.int64(4899), np.int64(4883), np.int64(4898), np.int64(4878), np.int64(4902), np.int64(4871), np.int64(4879), np.int64(4901), np.int64(4870), np.int64(4945), np.int64(4877), np.int64(4897), np.int64(4900), np.int64(4876), np.int64(4748), np.int64(4872), np.int64(4880), np.int64(4881), np.int64(4882), np.int64(4887), np.int64(4994), np.int64(4885), np.int64(4752), np.int64(4904), np.int64(4886), np.int64(4888), np.int64(4607), np.int64(4866), np.int64(4875), np.int64(4749), np.int64(4947), np.int64(4873), np.int64(4757), np.int64(4874), np.int64(4944), np.int64(4758), np.int64(4995), np.int64(4822), np.int64(4913), np.int64(4823), np.int64(4948), np.int64(4768), np.int64(4911), np.int64(4750), np.int64(4912), np.int64(4781), np.int64(4755), np.int64(4608), np.int64(4915)], 'Arousal': [np.int64(4879), np.int64(4993), np.int64(4607), np.int64(4894), np.int64(4895), np.int64(4353), np.int64(4878), np.int64(4990), np.int64(4898), np.int64(4897), np.int64(4991), np.int64(4880), np.int64(4892), np.int64(4885), np.int64(4896), np.int64(4862), np.int64(4992), np.int64(4884), np.int64(4893), np.int64(4881), np.int64(4890), np.int64(4478), np.int64(4883), np.int64(4888), np.int64(4994), np.int64(4886), np.int64(4922), np.int64(4899), np.int64(4877), np.int64(4889), np.int64(4882), np.int64(4352), np.int64(4891), np.int64(4887), np.int64(4995), np.int64(4863), np.int64(4843), np.int64(4870), np.int64(4479), np.int64(4869), np.int64(4842), np.int64(4874), np.int64(4900), np.int64(4354), np.int64(4868), np.int64(4865), np.int64(4996), np.int64(4864), np.int64(4873), np.int64(4480), np.int64(4351), np.int64(4876), np.int64(4923), np.int64(4872), np.int64(4481), np.int64(4875), np.int64(4982), np.int64(4871), np.int64(4765), np.int64(4866), np.int64(4766), np.int64(4350), np.int64(4659), np.int64(4911)]}, 'WT': {'Valence': [np.int64(58), np.int64(59), np.int64(57), np.int64(60), np.int64(56), np.int64(61), np.int64(55), np.int64(62), np.int64(54), np.int64(63), np.int64(64), np.int64(53), np.int64(65), np.int64(66), np.int64(52), np.int64(67), np.int64(68), np.int64(51), np.int64(69), np.int64(70), np.int64(71), np.int64(50), np.int64(72), np.int64(73), np.int64(32), np.int64(31), np.int64(49), np.int64(74), np.int64(33), np.int64(30), np.int64(75), np.int64(34), np.int64(76), np.int64(29), np.int64(35), np.int64(48), np.int64(77), np.int64(36), np.int64(28), np.int64(78), np.int64(37), np.int64(79), np.int64(27), np.int64(47), np.int64(38), np.int64(80), np.int64(81), np.int64(39), np.int64(26), np.int64(46), np.int64(82), np.int64(25), np.int64(40), np.int64(83), np.int64(24), np.int64(41), np.int64(45), np.int64(23), np.int64(84), np.int64(42), np.int64(22), np.int64(44), np.int64(43), np.int64(85)], 'Arousal': [np.int64(30), np.int64(58), np.int64(29), np.int64(31), np.int64(28), np.int64(59), np.int64(60), np.int64(57), np.int64(32), np.int64(61), np.int64(56), np.int64(27), np.int64(62), np.int64(63), np.int64(55), np.int64(33), np.int64(64), np.int64(54), np.int64(65), np.int64(66), np.int64(53), np.int64(26), np.int64(67), np.int64(34), np.int64(52), np.int64(68), np.int64(69), np.int64(51), np.int64(35), np.int64(70), np.int64(71), np.int64(25), np.int64(50), np.int64(72), np.int64(36), np.int64(73), np.int64(18), np.int64(49), np.int64(74), np.int64(37), np.int64(75), np.int64(24), np.int64(19), np.int64(76), np.int64(48), np.int64(17), np.int64(77), np.int64(38), np.int64(20), np.int64(78), np.int64(23), np.int64(21), np.int64(79), np.int64(47), np.int64(22), np.int64(39), np.int64(80), np.int64(46), np.int64(81), np.int64(40), np.int64(16), np.int64(82), np.int64(45), np.int64(83)]}}\n"
     ]
    }
   ],
   "source": [
    "# Save file name\n",
    "prefix_path = 'C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\deap-dataset\\\\'\n",
    "filename = \"feature_selections.pkl\"\n",
    "\n",
    "# Read data again\n",
    "with open(prefix_path + filename, 'rb') as file:\n",
    "    feature_selection_loaded = pickle.load(file)\n",
    "\n",
    "print(feature_selection_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f53c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = [\n",
    "    ['WT', 'YES', 'VALENCE', {'TRAIN': (cwt_train_loaded[:, :, feature_selection_loaded['WT']['Valence']], y_train), \n",
    "                              'TEST': (cwt_test_loaded[:, :, feature_selection_loaded['WT']['Valence']], y_test)}],\n",
    "    ['WT', 'YES', 'AROUSAL', {'TRAIN': (cwt_train_loaded[:, :, feature_selection_loaded['WT']['Arousal']], y_train),\n",
    "                              'TEST': (cwt_test_loaded[:, :, feature_selection_loaded['WT']['Arousal']], y_test)}],\n",
    "\n",
    "    ['WT', 'NO', '*', {'TRAIN': (cwt_train_loaded, y_train), \n",
    "                       'TEST': (cwt_test_loaded, y_test)}],\n",
    "\n",
    "    ['PE', 'NO', '*', {'TRAIN': (pe_train_loaded, y_train), \n",
    "                       'TEST': (pe_test_loaded, y_test)}],\n",
    "\n",
    "    ['NONE', 'YES', 'VALENCE', {'TRAIN': (pca_train_loaded[:, :, feature_selection_loaded['PCA']['Valence']], y_train), \n",
    "                                'TEST': (pca_test_loaded[:, :, feature_selection_loaded['PCA']['Valence']], y_test)}],\n",
    "    ['NONE', 'YES', 'AROUSAL', {'TRAIN': (pca_train_loaded[:, :, feature_selection_loaded['PCA']['Arousal']], y_train), \n",
    "                                'TEST': (pca_test_loaded[:, :, feature_selection_loaded['PCA']['Arousal']], y_test)}],\n",
    "\n",
    "    ['NONE', 'NO', '*', {'TRAIN': (pca_train_loaded, y_train), \n",
    "                         'TEST': (pca_test_loaded, y_test)}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1f36ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 1: ('rf', 'WT', 'YES', 'AROUSAL', 73.828125)\n",
      "experiment 2: ('rf', 'WT', 'YES', 'VALENCE', 78.90625)\n",
      "experiment 3: ('rf', 'WT', 'NO', 'AROUSAL', 74.21875)\n",
      "experiment 4: ('rf', 'WT', 'NO', 'VALENCE', 77.734375)\n",
      "experiment 5: ('rf', 'PE', 'NO', 'AROUSAL', 78.125)\n",
      "experiment 6: ('rf', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 7: ('rf', 'NONE', 'YES', 'AROUSAL', 69.140625)\n",
      "experiment 8: ('rf', 'NONE', 'YES', 'VALENCE', 78.90625)\n",
      "experiment 9: ('rf', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 10: ('rf', 'NONE', 'NO', 'VALENCE', 22.65625)\n",
      "experiment 11: ('svm', 'WT', 'YES', 'AROUSAL', 77.734375)\n",
      "experiment 12: ('svm', 'WT', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 13: ('svm', 'WT', 'NO', 'AROUSAL', 77.734375)\n",
      "experiment 14: ('svm', 'WT', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 15: ('svm', 'PE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 16: ('svm', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 17: ('svm', 'NONE', 'YES', 'AROUSAL', 78.515625)\n",
      "experiment 18: ('svm', 'NONE', 'YES', 'VALENCE', 78.515625)\n",
      "experiment 19: ('svm', 'NONE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 20: ('svm', 'NONE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 21: ('lr', 'WT', 'YES', 'AROUSAL', 76.5625)\n",
      "experiment 22: ('lr', 'WT', 'YES', 'VALENCE', 78.125)\n",
      "experiment 23: ('lr', 'WT', 'NO', 'AROUSAL', 75.0)\n",
      "experiment 24: ('lr', 'WT', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 25: ('lr', 'PE', 'NO', 'AROUSAL', 78.515625)\n",
      "experiment 26: ('lr', 'PE', 'NO', 'VALENCE', 78.515625)\n",
      "experiment 27: ('lr', 'NONE', 'YES', 'AROUSAL', 77.34375)\n",
      "experiment 28: ('lr', 'NONE', 'YES', 'VALENCE', 56.640625)\n",
      "experiment 29: ('lr', 'NONE', 'NO', 'AROUSAL', 61.71875)\n",
      "experiment 30: ('lr', 'NONE', 'NO', 'VALENCE', 39.453125)\n",
      "experiment 31: ('knn', 'WT', 'YES', 'AROUSAL', 70.703125)\n",
      "experiment 32: ('knn', 'WT', 'YES', 'VALENCE', 69.140625)\n",
      "experiment 33: ('knn', 'WT', 'NO', 'AROUSAL', 70.3125)\n",
      "experiment 34: ('knn', 'WT', 'NO', 'VALENCE', 67.96875)\n",
      "experiment 35: ('knn', 'PE', 'NO', 'AROUSAL', 71.875)\n",
      "experiment 36: ('knn', 'PE', 'NO', 'VALENCE', 74.609375)\n",
      "experiment 37: ('knn', 'NONE', 'YES', 'AROUSAL', 72.65625)\n",
      "experiment 38: ('knn', 'NONE', 'YES', 'VALENCE', 67.578125)\n",
      "experiment 39: ('knn', 'NONE', 'NO', 'AROUSAL', 75.390625)\n",
      "experiment 40: ('knn', 'NONE', 'NO', 'VALENCE', 72.265625)\n",
      "experiment 41: ('dt', 'WT', 'YES', 'AROUSAL', 68.359375)\n",
      "experiment 42: ('dt', 'WT', 'YES', 'VALENCE', 68.75)\n",
      "experiment 43: ('dt', 'WT', 'NO', 'AROUSAL', 66.015625)\n",
      "experiment 44: ('dt', 'WT', 'NO', 'VALENCE', 67.578125)\n",
      "experiment 45: ('dt', 'PE', 'NO', 'AROUSAL', 67.578125)\n",
      "experiment 46: ('dt', 'PE', 'NO', 'VALENCE', 66.796875)\n",
      "experiment 47: ('dt', 'NONE', 'YES', 'AROUSAL', 44.53125)\n",
      "experiment 48: ('dt', 'NONE', 'YES', 'VALENCE', 35.15625)\n",
      "experiment 49: ('dt', 'NONE', 'NO', 'AROUSAL', 30.859375)\n",
      "experiment 50: ('dt', 'NONE', 'NO', 'VALENCE', 22.65625)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "evaluates = []\n",
    "i = 0\n",
    "for name_model in ['rf', 'svm', 'lr', 'knn', 'dt']:\n",
    "    for experiment in aggregated_data:\n",
    "        data = experiment[-1]\n",
    "        classifi_objs = [0] if experiment[2] == 'VALENCE' else [1] if experiment[2] == 'AROUSAL' else [0,1]\n",
    "        (X_train_data, y_train_data), (X_test_data, y_test_data) = data['TRAIN'], data['TEST']\n",
    "        # print(X_test_data.shape, X_train_data.shape)\n",
    "        for classifi_obj in classifi_objs:\n",
    "            config = {\n",
    "                'length_signal': X_train_data.shape[-1],\n",
    "                'name_model': name_model\n",
    "            }\n",
    "            \n",
    "            model = get_model(**config)\n",
    "\n",
    "            # print(name_model)\n",
    "            config_train = setup_config_train(X_train_data, y_train_data, X_test_data, y_test_data, name_model)\n",
    "            train_model(model, classifi_obj, **config_train)\n",
    "\n",
    "            motion = 'VALENCE' if classifi_obj else 'AROUSAL'\n",
    "\n",
    "            models.append((*experiment[:2], motion, model))\n",
    "\n",
    "            info = (\n",
    "                name_model,\n",
    "                *experiment[:2], \n",
    "                motion,\n",
    "                evaluate(model, name_model, classifi_obj, X_test_data, y_test_data)['Acc']*100\n",
    "            )\n",
    "            i += 1\n",
    "            print(f'experiment {i}: {info}')\n",
    "            evaluates.append(info)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5364e3",
   "metadata": {},
   "source": [
    "# **Summary of Best Scores and Configurations**\n",
    "\n",
    "## **Best Scores for Each Model:**\n",
    "\n",
    "| Model      | Classifier | Feature Set | Data Augmentation | Task   | Accuracy (%) |\n",
    "|------------|-----------|-------------|-------------------|--------|-------------|\n",
    "| **RNN LSTM** | SVM       | NONE        | YES               | AROUSAL | **78.5156** |\n",
    "| **RNN LSTM** | SVM       | NONE        | YES               | VALENCE | **78.5156** |\n",
    "| **RNN GRU**  | SVM       | NONE        | YES               | AROUSAL | **78.5156** |\n",
    "| **RNN GRU**  | SVM       | NONE        | YES               | VALENCE | **78.5156** |\n",
    "| **CNN**      | RF        | WT          | YES               | VALENCE | **78.9063** |\n",
    "\n",
    "---\n",
    "\n",
    "## **Best Configurations per Model Type:**\n",
    "\n",
    "### **RNN LSTM:**\n",
    "- **Best Score:** **78.5156%**\n",
    "- **Best Configuration:**  \n",
    "  - Classifier: **SVM**\n",
    "  - Feature Set: **NONE**\n",
    "  - Data Augmentation: **YES**\n",
    "  - Works best for both **Arousal and Valence**\n",
    "\n",
    "### **RNN GRU:**\n",
    "- **Best Score:** **78.5156%**\n",
    "- **Best Configuration:**  \n",
    "  - Classifier: **SVM**\n",
    "  - Feature Set: **NONE**\n",
    "  - Data Augmentation: **YES**\n",
    "  - Works best for both **Arousal and Valence**\n",
    "\n",
    "### **CNN:**\n",
    "- **Best Score:** **78.9063%** (Highest overall)\n",
    "- **Best Configuration:**  \n",
    "  - Classifier: **Random Forest (RF)**\n",
    "  - Feature Set: **WT**\n",
    "  - Data Augmentation: **YES**\n",
    "  - Works best for **Valence**\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways:**\n",
    "- **Best overall performance is achieved by CNN with RF classifier (78.9063% for Valence).**\n",
    "- **SVM performs best for RNN models, especially with no predefined feature set (NONE) and data augmentation (YES).**\n",
    "- **Data augmentation (\"YES\") appears to contribute to higher accuracy.**\n",
    "- **Feature Set \"NONE\" (no predefined features) seems to work well for RNN models.**\n",
    "- **Random Forest (RF) is the top performer for CNN.**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6241375,
     "sourceId": 10115927,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6257838,
     "sourceId": 10142875,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6260624,
     "sourceId": 10143051,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6268504,
     "sourceId": 10153382,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6281493,
     "sourceId": 10170850,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 154.627177,
   "end_time": "2024-12-14T02:21:07.015809",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-14T02:18:32.388632",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

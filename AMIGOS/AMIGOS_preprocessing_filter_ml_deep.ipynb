{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading Function ---\n",
    "def load_patient_preprocessed_data(patient_number):\n",
    "    base_dir = r\"C:\\Users\\ferri\\Downloads\\PoliTO\\Tesi\\DSs\\Emotion-Stress\\AMIGOS\"\n",
    "    file_path = os.path.join(\n",
    "        base_dir, \"Data preprocessed\",\n",
    "        f\"Data_Preprocessed_P{patient_number:02d}\",\n",
    "        f\"Data_Preprocessed_P{patient_number:02d}.mat\"\n",
    "    )\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Fixed target length for each trial signal\n",
    "TARGET_LENGTH = 1000\n",
    "\n",
    "# --- Preprocessing functions for CNN pipeline ---\n",
    "\n",
    "def process_trial_signals_together(trial_data, target_length=1000, fs=128):\n",
    "    signal_types = ['EEG', 'ECG', 'GSR']\n",
    "    processed_signals = []\n",
    "\n",
    "    for idx, signal_type in enumerate(signal_types):\n",
    "        raw_signal = np.array(trial_data[idx], dtype=float).squeeze()\n",
    "        filtered_signal = filter_signal(raw_signal, signal_type, fs)\n",
    "        \n",
    "        # resize or pad the signal\n",
    "        if len(filtered_signal) < target_length:\n",
    "            pad_width = target_length - len(filtered_signal)\n",
    "            filtered_signal = np.pad(filtered_signal, (0, pad_width), mode='constant')\n",
    "        else:\n",
    "            filtered_signal = filtered_signal[:target_length]\n",
    "        \n",
    "        processed_signals.append(filtered_signal)\n",
    "\n",
    "    # Combine signals into a single multi-channel array (shape: target_length x num_signals)\n",
    "    return np.vstack(processed_signals).T\n",
    "\n",
    "def discretize_label(label):\n",
    "    \"\"\"\n",
    "    Convert a continuous label [1, valence, arousal] into a descriptive class.\n",
    "    The first element is ignored.\n",
    "    \"\"\"\n",
    "    if label.size < 3:\n",
    "        return \"Unknown\"\n",
    "    valence = label[1]\n",
    "    arousal = label[2]\n",
    "    if valence < 0 and arousal < 0:\n",
    "        return \"Low valence, Low arousal\"\n",
    "    elif valence < 0 and arousal >= 0:\n",
    "        return \"Low valence, High arousal\"\n",
    "    elif valence >= 0 and arousal < 0:\n",
    "        return \"High valence, Low arousal\"\n",
    "    else:\n",
    "        return \"High valence, High arousal\"\n",
    "\n",
    "# --- Feature Extraction Functions ---\n",
    "def extract_features(signal):\n",
    "    # Flatten the signal and check if it's empty.\n",
    "    signal = signal.flatten()\n",
    "    if signal.size == 0:\n",
    "        return np.zeros(5)\n",
    "    features = {\n",
    "        \"mean\": np.mean(signal),\n",
    "        \"std\": np.std(signal),\n",
    "        \"max\": np.max(signal),\n",
    "        \"min\": np.min(signal),\n",
    "        \"median\": np.median(signal)\n",
    "    }\n",
    "    return np.array(list(features.values()))\n",
    "\n",
    "def build_patient_data(joined_data, label_array):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    n_trials = joined_data.shape[1]\n",
    "    for i in range(n_trials):\n",
    "        trial_data = joined_data[0, i]\n",
    "        trial_data = np.array(trial_data, dtype=float).squeeze()\n",
    "        features = extract_features(trial_data)\n",
    "        \n",
    "        lbl = np.array(label_array[0, i]).squeeze()\n",
    "        if lbl.size == 0:\n",
    "            print(f\"Warning: Trial {i} has empty label. Skipping trial.\")\n",
    "            continue\n",
    "        if lbl.ndim == 2:\n",
    "            lbl_processed = np.mean(lbl, axis=0)\n",
    "        elif lbl.ndim == 1:\n",
    "            lbl_processed = lbl\n",
    "        else:\n",
    "            lbl_processed = lbl.flatten()[0]\n",
    "        discrete_label = discretize_label(lbl_processed)\n",
    "        \n",
    "        X_list.append(features)\n",
    "        y_list.append(discrete_label)\n",
    "    if len(X_list) == 0:\n",
    "        return None, None\n",
    "    return np.vstack(X_list), np.array(y_list)\n",
    "\n",
    "def load_all_patients_data(num_patients=40):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for patient in range(1, num_patients+1):\n",
    "        print(f\"Loading patient {patient}\")\n",
    "        data = load_patient_preprocessed_data(patient)\n",
    "        joined_data = data['joined_data']\n",
    "        labels_array = data['labels_ext_annotation']\n",
    "        X_patient, y_patient = build_patient_data(joined_data, labels_array)\n",
    "        if X_patient is not None and y_patient is not None:\n",
    "            X_list.append(X_patient)\n",
    "            y_list.append(y_patient)\n",
    "    if len(X_list) == 0:\n",
    "        raise ValueError(\"No patient data loaded.\")\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.concatenate(y_list)\n",
    "    return X_all, y_all\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low')\n",
    "    return b, a\n",
    "\n",
    "def filter_signal(data, signal_type, fs=128):\n",
    "    nyquist = 0.5 * fs\n",
    "    if signal_type == 'EEG':\n",
    "        low, high = 1 / nyquist, 40 / nyquist\n",
    "        b, a = butter(4, [low, high], btype='band')\n",
    "    elif signal_type == 'ECG':\n",
    "        low, high = 0.5 / nyquist, 40 / nyquist\n",
    "        b, a = butter(4, [low, high], btype='band')\n",
    "    elif signal_type == 'GSR':\n",
    "        cutoff = 2 / nyquist\n",
    "        b, a = butter(4, cutoff, btype='low')\n",
    "    else:\n",
    "        raise ValueError(\"Unknown signal type.\")\n",
    "\n",
    "    padlen = 3 * max(len(a), len(b))\n",
    "    if len(data) <= padlen:\n",
    "        return data\n",
    "    else:\n",
    "        return filtfilt(b, a, data)\n",
    "\n",
    "def load_all_patients_raw_signal(num_patients=40, target_length=1000, fs=128):\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for patient in range(1, num_patients + 1):\n",
    "        data = load_patient_preprocessed_data(patient)\n",
    "        joined_data = data['joined_data']\n",
    "        labels_array = data['labels_ext_annotation']\n",
    "\n",
    "        for trial in range(joined_data.shape[1]):\n",
    "            trial_data = joined_data[0, trial]\n",
    "            lbl = np.array(labels_array[0, trial]).squeeze()\n",
    "\n",
    "            if lbl.size == 0:\n",
    "                print(f\"Skipping empty label trial {trial}\")\n",
    "                continue\n",
    "\n",
    "            if lbl.ndim == 2:\n",
    "                lbl_processed = np.mean(lbl, axis=0)\n",
    "            else:\n",
    "                lbl_processed = lbl.flatten()\n",
    "\n",
    "            discrete_label = discretize_label(lbl_processed)\n",
    "\n",
    "            processed_signal = process_trial_signals_together(trial_data, target_length, fs)\n",
    "\n",
    "            X_list.append(processed_signal)\n",
    "            y_list.append(discrete_label)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No data loaded!\")\n",
    "\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "def butter_highpass(cutoff, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='high')\n",
    "    return b, a\n",
    "\n",
    "def apply_filter(data, filter_type='bandpass', lowcut=None, highcut=None, cutoff=None, fs=128, order=4):\n",
    "    if filter_type == 'bandpass':\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    elif filter_type == 'lowpass':\n",
    "        b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    elif filter_type == 'highpass':\n",
    "        b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filter type. Choose 'bandpass', 'lowpass', or 'highpass'.\")\n",
    "\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading patient 1\n",
      "Loading patient 2\n",
      "Loading patient 3\n",
      "Loading patient 4\n",
      "Loading patient 5\n",
      "Loading patient 6\n",
      "Loading patient 7\n",
      "Loading patient 8\n",
      "Warning: Trial 0 has empty label. Skipping trial.\n",
      "Warning: Trial 1 has empty label. Skipping trial.\n",
      "Warning: Trial 2 has empty label. Skipping trial.\n",
      "Warning: Trial 3 has empty label. Skipping trial.\n",
      "Warning: Trial 4 has empty label. Skipping trial.\n",
      "Warning: Trial 5 has empty label. Skipping trial.\n",
      "Warning: Trial 6 has empty label. Skipping trial.\n",
      "Warning: Trial 7 has empty label. Skipping trial.\n",
      "Warning: Trial 8 has empty label. Skipping trial.\n",
      "Warning: Trial 9 has empty label. Skipping trial.\n",
      "Warning: Trial 10 has empty label. Skipping trial.\n",
      "Warning: Trial 11 has empty label. Skipping trial.\n",
      "Warning: Trial 12 has empty label. Skipping trial.\n",
      "Warning: Trial 13 has empty label. Skipping trial.\n",
      "Warning: Trial 14 has empty label. Skipping trial.\n",
      "Warning: Trial 15 has empty label. Skipping trial.\n",
      "Warning: Trial 16 has empty label. Skipping trial.\n",
      "Warning: Trial 17 has empty label. Skipping trial.\n",
      "Warning: Trial 18 has empty label. Skipping trial.\n",
      "Warning: Trial 19 has empty label. Skipping trial.\n",
      "Loading patient 9\n",
      "Loading patient 10\n",
      "Loading patient 11\n",
      "Loading patient 12\n",
      "Loading patient 13\n",
      "Loading patient 14\n",
      "Loading patient 15\n",
      "Loading patient 16\n",
      "Loading patient 17\n",
      "Loading patient 18\n",
      "Loading patient 19\n",
      "Loading patient 20\n",
      "Loading patient 21\n",
      "Loading patient 22\n",
      "Loading patient 23\n",
      "Loading patient 24\n",
      "Warning: Trial 0 has empty label. Skipping trial.\n",
      "Warning: Trial 1 has empty label. Skipping trial.\n",
      "Warning: Trial 2 has empty label. Skipping trial.\n",
      "Warning: Trial 3 has empty label. Skipping trial.\n",
      "Warning: Trial 4 has empty label. Skipping trial.\n",
      "Warning: Trial 5 has empty label. Skipping trial.\n",
      "Warning: Trial 6 has empty label. Skipping trial.\n",
      "Warning: Trial 7 has empty label. Skipping trial.\n",
      "Warning: Trial 8 has empty label. Skipping trial.\n",
      "Warning: Trial 9 has empty label. Skipping trial.\n",
      "Warning: Trial 10 has empty label. Skipping trial.\n",
      "Warning: Trial 11 has empty label. Skipping trial.\n",
      "Warning: Trial 12 has empty label. Skipping trial.\n",
      "Warning: Trial 13 has empty label. Skipping trial.\n",
      "Warning: Trial 14 has empty label. Skipping trial.\n",
      "Warning: Trial 15 has empty label. Skipping trial.\n",
      "Warning: Trial 16 has empty label. Skipping trial.\n",
      "Warning: Trial 17 has empty label. Skipping trial.\n",
      "Warning: Trial 18 has empty label. Skipping trial.\n",
      "Warning: Trial 19 has empty label. Skipping trial.\n",
      "Loading patient 25\n",
      "Loading patient 26\n",
      "Loading patient 27\n",
      "Loading patient 28\n",
      "Warning: Trial 0 has empty label. Skipping trial.\n",
      "Warning: Trial 1 has empty label. Skipping trial.\n",
      "Warning: Trial 2 has empty label. Skipping trial.\n",
      "Warning: Trial 3 has empty label. Skipping trial.\n",
      "Warning: Trial 4 has empty label. Skipping trial.\n",
      "Warning: Trial 5 has empty label. Skipping trial.\n",
      "Warning: Trial 6 has empty label. Skipping trial.\n",
      "Warning: Trial 7 has empty label. Skipping trial.\n",
      "Warning: Trial 8 has empty label. Skipping trial.\n",
      "Warning: Trial 9 has empty label. Skipping trial.\n",
      "Warning: Trial 10 has empty label. Skipping trial.\n",
      "Warning: Trial 11 has empty label. Skipping trial.\n",
      "Warning: Trial 12 has empty label. Skipping trial.\n",
      "Warning: Trial 13 has empty label. Skipping trial.\n",
      "Warning: Trial 14 has empty label. Skipping trial.\n",
      "Warning: Trial 15 has empty label. Skipping trial.\n",
      "Warning: Trial 16 has empty label. Skipping trial.\n",
      "Warning: Trial 17 has empty label. Skipping trial.\n",
      "Warning: Trial 18 has empty label. Skipping trial.\n",
      "Warning: Trial 19 has empty label. Skipping trial.\n",
      "Loading patient 29\n",
      "Loading patient 30\n",
      "Loading patient 31\n",
      "Loading patient 32\n",
      "Loading patient 33\n",
      "Loading patient 34\n",
      "Loading patient 35\n",
      "Loading patient 36\n",
      "Loading patient 37\n",
      "Loading patient 38\n",
      "Loading patient 39\n",
      "Loading patient 40\n"
     ]
    }
   ],
   "source": [
    "X_raw, y_desc = load_all_patients_data(num_patients=40)\n",
    "unique_labels = np.unique(y_desc)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int = np.array([label_to_int[label] for label in y_desc])\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "# Split once (used by all models)\n",
    "X_train, X_test, y_train, y_test, y_int_train, y_int_test = train_test_split(\n",
    "    X_raw, to_categorical(y_int), y_int, test_size=0.2, random_state=42, stratify=y_int\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# CNN feature extraction function\n",
    "def extract_cnn_features(X_train, y_train, X_test, num_classes):\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(16, kernel_size=5, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(32, kernel_size=5, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(64, kernel_size=5, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    features = Flatten(name='features')(x)\n",
    "    x = Dense(128, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
    "              callbacks=[early_stop], verbose=1)\n",
    "\n",
    "    extractor = Model(inputs=model.input, outputs=model.get_layer('features').output)\n",
    "    return extractor.predict(X_train), extractor.predict(X_test)\n",
    "\n",
    "# LSTM feature extraction function\n",
    "def extract_lstm_features(X_train, y_train, X_test, num_classes):\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = LSTM(64, return_sequences=True)(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    features = Dense(128, activation='relu', name='features')(x)\n",
    "    x = Dropout(0.5)(features)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "              callbacks=[early_stop], verbose=1)\n",
    "\n",
    "    extractor = Model(inputs=model.input, outputs=model.get_layer('features').output)\n",
    "    return extractor.predict(X_train), extractor.predict(X_test)\n",
    "\n",
    "# GRU feature extraction function\n",
    "def extract_gru_features(X_train, y_train, X_test, num_classes):\n",
    "    input_shape = X_train.shape[1:]\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = GRU(64, return_sequences=True)(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(64)(x)\n",
    "    features = Dense(128, activation='relu', name='features')(x)\n",
    "    x = Dropout(0.5)(features)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "              callbacks=[early_stop], verbose=1)\n",
    "\n",
    "    extractor = Model(inputs=model.input, outputs=model.get_layer('features').output)\n",
    "    return extractor.predict(X_train), extractor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_classifiers(X_tr, X_te, y_tr, y_te):\n",
    "    classifiers = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100)\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        pred = clf.predict(X_te)\n",
    "        acc = accuracy_score(y_te, pred)\n",
    "        print(f\"{clf_name}: Accuracy = {acc:.3f}\")\n",
    "        print(confusion_matrix(y_te, pred))\n",
    "        print(classification_report(y_te, pred))\n",
    "        try:\n",
    "            prob = clf.predict_proba(X_te)\n",
    "            auc = roc_auc_score(to_categorical(y_te), prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            print(\"AUC:\", auc)\n",
    "        except Exception as e:\n",
    "            print(\"AUC Error:\", e)\n",
    "            \n",
    "\n",
    "# --- Build CNN Model ---\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=5, activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Statistical Feature Extraction + ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.4447409467617899\n",
      "SVM: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.47144031329256836\n",
      "KNN: Accuracy = 0.561\n",
      "[[ 1  1  0 12]\n",
      " [ 1  2  0 27]\n",
      " [ 0  2  0  3]\n",
      " [ 7 12  0 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.07      0.09        14\n",
      "           1       0.12      0.07      0.09        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.66      0.81      0.72        99\n",
      "\n",
      "    accuracy                           0.56       148\n",
      "   macro avg       0.22      0.24      0.22       148\n",
      "weighted avg       0.47      0.56      0.51       148\n",
      "\n",
      "AUC: 0.506462413069285\n",
      "Decision Tree: Accuracy = 0.514\n",
      "[[ 0  1  0 13]\n",
      " [ 3  8  0 19]\n",
      " [ 1  1  0  3]\n",
      " [ 8 20  3 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.27      0.27      0.27        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.66      0.69      0.67        99\n",
      "\n",
      "    accuracy                           0.51       148\n",
      "   macro avg       0.23      0.24      0.23       148\n",
      "weighted avg       0.50      0.51      0.50       148\n",
      "\n",
      "AUC: 0.49463822460009804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy = 0.615\n",
      "[[ 0  0  0 14]\n",
      " [ 1  1  0 28]\n",
      " [ 0  0  0  5]\n",
      " [ 1  7  1 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.12      0.03      0.05        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.66      0.91      0.76        99\n",
      "\n",
      "    accuracy                           0.61       148\n",
      "   macro avg       0.20      0.24      0.20       148\n",
      "weighted avg       0.46      0.61      0.52       148\n",
      "\n",
      "AUC: 0.5669143802914266\n"
     ]
    }
   ],
   "source": [
    "# Correct feature extraction:\n",
    "X_train_stat = np.array([extract_features(signal) for signal in X_train])\n",
    "X_test_stat = np.array([extract_features(signal) for signal in X_test])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean').fit(X_train_stat)\n",
    "X_train_stat_imputed = imputer.transform(X_train_stat)\n",
    "X_test_stat_imputed = imputer.transform(X_test_stat)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler().fit(X_train_stat_imputed)\n",
    "X_train_stat_scaled = scaler.transform(X_train_stat_imputed)\n",
    "X_test_stat_scaled = scaler.transform(X_test_stat_imputed)\n",
    "\n",
    "# Train and evaluate classifiers\n",
    "train_evaluate_classifiers(X_train_stat_scaled, X_test_stat_scaled, y_int_train, y_int_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CNN Feature Extraction + ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "X_signal shape: (740, 1000, 3)\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.0899 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0945 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0840 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0930 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0963 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0619 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0739 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0587 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0885 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0731 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0898 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 0.095\n",
      "[[14  0  0  0]\n",
      " [30  0  0  0]\n",
      " [ 5  0  0  0]\n",
      " [99  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.09       148\n",
      "   macro avg       0.02      0.25      0.04       148\n",
      "weighted avg       0.01      0.09      0.02       148\n",
      "\n",
      "AUC: 0.5\n",
      "SVM: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess signals (EEG, ECG, GSR together)\n",
    "X_signal, y_signal_desc = load_all_patients_raw_signal(num_patients=40, target_length=TARGET_LENGTH)\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = np.unique(y_signal_desc)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int_signal = np.array([label_to_int[label] for label in y_signal_desc])\n",
    "y_cat_signal = to_categorical(y_int_signal)\n",
    "\n",
    "# Check shape for CNN/LSTM/GRU (samples, timesteps, channels)\n",
    "print(\"X_signal shape:\", X_signal.shape)  # should be (samples, target_length, 3)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test, y_int_train, y_int_test = train_test_split(\n",
    "    X_signal, y_cat_signal, y_int_signal,\n",
    "    test_size=0.2, random_state=42, stratify=y_int_signal\n",
    ")\n",
    "\n",
    "# Run CNN feature extraction + ML classifiers\n",
    "train_features, test_features = extract_cnn_features(X_train, y_train, X_test, len(unique_labels))\n",
    "train_evaluate_classifiers(train_features, test_features, y_int_train, y_int_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Feature Extraction + ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "X_signal shape: (740, 1000, 3)\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 324ms/step - accuracy: 0.5214 - loss: 1.3833 - val_accuracy: 0.6134 - val_loss: 1.3758\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 295ms/step - accuracy: 0.6642 - loss: 1.3713 - val_accuracy: 0.6134 - val_loss: 1.3655\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 295ms/step - accuracy: 0.7041 - loss: 1.3573 - val_accuracy: 0.6134 - val_loss: 1.3552\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.6975 - loss: 1.3452 - val_accuracy: 0.6134 - val_loss: 1.3453\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 283ms/step - accuracy: 0.7076 - loss: 1.3319 - val_accuracy: 0.6134 - val_loss: 1.3355\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.7082 - loss: 1.3193 - val_accuracy: 0.6134 - val_loss: 1.3260\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - accuracy: 0.6788 - loss: 1.3123 - val_accuracy: 0.6134 - val_loss: 1.3168\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - accuracy: 0.6992 - loss: 1.2984 - val_accuracy: 0.6134 - val_loss: 1.3077\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - accuracy: 0.7129 - loss: 1.2835 - val_accuracy: 0.6134 - val_loss: 1.2988\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - accuracy: 0.6947 - loss: 1.2764 - val_accuracy: 0.6134 - val_loss: 1.2902\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Logistic Regression: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "SVM: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "KNN: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "Decision Tree: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "Random Forest: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess signals (EEG, ECG, GSR together)\n",
    "X_signal, y_signal_desc = load_all_patients_raw_signal(num_patients=40, target_length=TARGET_LENGTH)\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = np.unique(y_signal_desc)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int_signal = np.array([label_to_int[label] for label in y_signal_desc])\n",
    "y_cat_signal = to_categorical(y_int_signal)\n",
    "\n",
    "# Verify shape for LSTM input (samples, timesteps, channels)\n",
    "print(\"X_signal shape:\", X_signal.shape)  # Should be (samples, TARGET_LENGTH, 3)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test, y_int_train, y_int_test = train_test_split(\n",
    "    X_signal, y_cat_signal, y_int_signal,\n",
    "    test_size=0.2, random_state=42, stratify=y_int_signal\n",
    ")\n",
    "\n",
    "# Run LSTM feature extraction + ML classifiers\n",
    "train_features, test_features = extract_lstm_features(X_train, y_train, X_test, len(unique_labels))\n",
    "train_evaluate_classifiers(train_features, test_features, y_int_train, y_int_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Feature Extraction + ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "X_signal shape: (740, 1000, 3)\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.5384 - loss: 1.3833 - val_accuracy: 0.6134 - val_loss: 1.3758\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 339ms/step - accuracy: 0.6788 - loss: 1.3708 - val_accuracy: 0.6134 - val_loss: 1.3653\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 352ms/step - accuracy: 0.7126 - loss: 1.3570 - val_accuracy: 0.6134 - val_loss: 1.3551\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.6815 - loss: 1.3468 - val_accuracy: 0.6134 - val_loss: 1.3454\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.6868 - loss: 1.3345 - val_accuracy: 0.6134 - val_loss: 1.3356\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - accuracy: 0.6737 - loss: 1.3239 - val_accuracy: 0.6134 - val_loss: 1.3261\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 0.6951 - loss: 1.3099 - val_accuracy: 0.6134 - val_loss: 1.3168\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 291ms/step - accuracy: 0.6970 - loss: 1.2983 - val_accuracy: 0.6134 - val_loss: 1.3078\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.7123 - loss: 1.2838 - val_accuracy: 0.6134 - val_loss: 1.2988\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.6930 - loss: 1.2779 - val_accuracy: 0.6134 - val_loss: 1.2903\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Logistic Regression: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "SVM: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "KNN: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "Decision Tree: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n",
      "Random Forest: Accuracy = 0.669\n",
      "[[ 0  0  0 14]\n",
      " [ 0  0  0 30]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.67      1.00      0.80        99\n",
      "\n",
      "    accuracy                           0.67       148\n",
      "   macro avg       0.17      0.25      0.20       148\n",
      "weighted avg       0.45      0.67      0.54       148\n",
      "\n",
      "AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess signals (EEG, ECG, GSR together)\n",
    "X_signal, y_signal_desc = load_all_patients_raw_signal(num_patients=40, target_length=TARGET_LENGTH)\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = np.unique(y_signal_desc)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int_signal = np.array([label_to_int[label] for label in y_signal_desc])\n",
    "y_cat_signal = to_categorical(y_int_signal)\n",
    "\n",
    "# Verify shape for GRU input (samples, timesteps, channels)\n",
    "print(\"X_signal shape:\", X_signal.shape)  # Should be (samples, TARGET_LENGTH, 3)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test, y_int_train, y_int_test = train_test_split(\n",
    "    X_signal, y_cat_signal, y_int_signal,\n",
    "    test_size=0.2, random_state=42, stratify=y_int_signal\n",
    ")\n",
    "\n",
    "# Run GRU feature extraction + ML classifiers\n",
    "train_features, test_features = extract_gru_features(X_train, y_train, X_test, len(unique_labels))\n",
    "train_evaluate_classifiers(train_features, test_features, y_int_train, y_int_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN/LSTM/GRU end-to-end model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "Skipping empty label trial 0\n",
      "Skipping empty label trial 1\n",
      "Skipping empty label trial 2\n",
      "Skipping empty label trial 3\n",
      "Skipping empty label trial 4\n",
      "Skipping empty label trial 5\n",
      "Skipping empty label trial 6\n",
      "Skipping empty label trial 7\n",
      "Skipping empty label trial 8\n",
      "Skipping empty label trial 9\n",
      "Skipping empty label trial 10\n",
      "Skipping empty label trial 11\n",
      "Skipping empty label trial 12\n",
      "Skipping empty label trial 13\n",
      "Skipping empty label trial 14\n",
      "Skipping empty label trial 15\n",
      "Skipping empty label trial 16\n",
      "Skipping empty label trial 17\n",
      "Skipping empty label trial 18\n",
      "Skipping empty label trial 19\n",
      "X_signal shape: (740, 1000, 3)\n",
      "\n",
      "--- CNN standalone ---\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0773 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0837 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0841 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0715 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1090 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0535 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0653 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0763 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0831 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0666 - loss: nan - val_accuracy: 0.1345 - val_loss: nan\n",
      "CNN evaluation (loss, accuracy): [nan, 0.09459459781646729]\n",
      "\n",
      "--- LSTM standalone ---\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.5300 - loss: 1.3833 - val_accuracy: 0.6134 - val_loss: 1.3758\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.7088 - loss: 1.3702 - val_accuracy: 0.6134 - val_loss: 1.3653\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - accuracy: 0.6672 - loss: 1.3596 - val_accuracy: 0.6134 - val_loss: 1.3553\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 280ms/step - accuracy: 0.6838 - loss: 1.3464 - val_accuracy: 0.6134 - val_loss: 1.3453\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 278ms/step - accuracy: 0.6919 - loss: 1.3336 - val_accuracy: 0.6134 - val_loss: 1.3356\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.6918 - loss: 1.3221 - val_accuracy: 0.6134 - val_loss: 1.3263\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - accuracy: 0.7042 - loss: 1.3094 - val_accuracy: 0.6134 - val_loss: 1.3170\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 281ms/step - accuracy: 0.6808 - loss: 1.3025 - val_accuracy: 0.6134 - val_loss: 1.3079\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 276ms/step - accuracy: 0.6926 - loss: 1.2883 - val_accuracy: 0.6134 - val_loss: 1.2990\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.6777 - loss: 1.2813 - val_accuracy: 0.6134 - val_loss: 1.2904\n",
      "LSTM evaluation (loss, accuracy): [1.2762278318405151, 0.6689189076423645]\n",
      "\n",
      "--- GRU standalone ---\n",
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.4754 - loss: 1.3833 - val_accuracy: 0.6134 - val_loss: 1.3758\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 291ms/step - accuracy: 0.6936 - loss: 1.3705 - val_accuracy: 0.6134 - val_loss: 1.3654\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 291ms/step - accuracy: 0.6970 - loss: 1.3580 - val_accuracy: 0.6134 - val_loss: 1.3553\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 291ms/step - accuracy: 0.7028 - loss: 1.3455 - val_accuracy: 0.6134 - val_loss: 1.3455\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 0.6799 - loss: 1.3354 - val_accuracy: 0.6134 - val_loss: 1.3358\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 295ms/step - accuracy: 0.6803 - loss: 1.3242 - val_accuracy: 0.6134 - val_loss: 1.3264\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.7057 - loss: 1.3091 - val_accuracy: 0.6134 - val_loss: 1.3171\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 290ms/step - accuracy: 0.6904 - loss: 1.3002 - val_accuracy: 0.6134 - val_loss: 1.3081\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 290ms/step - accuracy: 0.7004 - loss: 1.2873 - val_accuracy: 0.6134 - val_loss: 1.2992\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.6659 - loss: 1.2839 - val_accuracy: 0.6134 - val_loss: 1.2906\n",
      "GRU evaluation (loss, accuracy): [1.2765285968780518, 0.6689189076423645]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess signals (EEG, ECG, GSR together)\n",
    "X_signal, y_signal_desc = load_all_patients_raw_signal(num_patients=40, target_length=TARGET_LENGTH)\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = np.unique(y_signal_desc)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int_signal = np.array([label_to_int[label] for label in y_signal_desc])\n",
    "y_cat_signal = to_categorical(y_int_signal)\n",
    "\n",
    "# Verify final data shape for CNN/LSTM/GRU (samples, timesteps, channels=3)\n",
    "print(\"X_signal shape:\", X_signal.shape)  # expected (samples, TARGET_LENGTH, 3)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_signal, y_cat_signal, test_size=0.2, random_state=42, stratify=y_int_signal\n",
    ")\n",
    "\n",
    "# Consistent input shape across models\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# --- CNN standalone ---\n",
    "print(\"\\n--- CNN standalone ---\")\n",
    "cnn_model = create_cnn_model(input_shape, len(unique_labels))\n",
    "cnn_model.fit(\n",
    "    X_train, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "cnn_eval = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN evaluation (loss, accuracy):\", cnn_eval)\n",
    "\n",
    "# --- LSTM standalone ---\n",
    "print(\"\\n--- LSTM standalone ---\")\n",
    "lstm_model = create_lstm_model(input_shape, len(unique_labels))\n",
    "lstm_model.fit(\n",
    "    X_train, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "lstm_eval = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"LSTM evaluation (loss, accuracy):\", lstm_eval)\n",
    "\n",
    "# --- GRU standalone ---\n",
    "print(\"\\n--- GRU standalone ---\")\n",
    "gru_model = create_gru_model(input_shape, len(unique_labels))\n",
    "gru_model.fit(\n",
    "    X_train, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "gru_eval = gru_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"GRU evaluation (loss, accuracy):\", gru_eval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

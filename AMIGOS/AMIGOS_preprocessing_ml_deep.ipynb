{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import h5py\n",
    "import scipy.io\n",
    "import scipy.signal as sgl\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import neurokit2 as nk\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Data Loading Function ---\n",
    "def load_patient_preprocessed_data(patient_number):\n",
    "    base_dir = r\"C:\\Users\\ferri\\Downloads\\PoliTO\\Tesi\\DSs\\Emotion-Stress\\AMIGOS\"\n",
    "    file_path = os.path.join(\n",
    "        base_dir, \"Data preprocessed\",\n",
    "        f\"Data_Preprocessed_P{patient_number:02d}\",\n",
    "        f\"Data_Preprocessed_P{patient_number:02d}.mat\"\n",
    "    )\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    return data\n",
    "\n",
    "# --- Preprocessing functions for pipeline ---\n",
    "def process_trial_signal(signal, target_length=None, fs=512):\n",
    "    \"\"\"\n",
    "    Convert a trial's raw signal into a 2D array [channels, time].\n",
    "    If target_length is None, we keep the full length (then you'll pad later).\n",
    "    Preprocessing steps (downsampling, filtering, baseline removal) are applied.\n",
    "    \"\"\"\n",
    "    # Convert to float32.\n",
    "    signal = np.array(signal, dtype=np.float32)\n",
    "    \n",
    "    # Check if signal is empty.\n",
    "    if signal.size == 0:\n",
    "        return np.empty((0,0), dtype=np.float32)\n",
    "    \n",
    "    # If the signal is 1D, reshape to (1, length).\n",
    "    if signal.ndim == 1:\n",
    "        signal = signal[None, :]\n",
    "    \n",
    "    # Downsampling parameters.\n",
    "    N = 4\n",
    "    lowcut, highcut = 1.0, 45.0\n",
    "    desired_fs = 128\n",
    "    down_factor = fs // desired_fs\n",
    "    \n",
    "    # 1) Downsample each channel.\n",
    "    downsampled = []\n",
    "    for ch_data in signal:\n",
    "        # If a channel is empty, skip it.\n",
    "        if ch_data.size == 0:\n",
    "            continue\n",
    "        ch_data_down = ch_data[::down_factor]\n",
    "        downsampled.append(ch_data_down)\n",
    "        \n",
    "    # If no channels had data, return an empty array.\n",
    "    if not downsampled:\n",
    "        return np.empty((0,0), dtype=np.float32)\n",
    "        \n",
    "    # Stack downsampled channels.\n",
    "    signal = np.vstack([ch[None, :] for ch in downsampled])\n",
    "    \n",
    "    # 2) Bandpass filter design.\n",
    "    nyquist = 0.5 * desired_fs\n",
    "    b, a = sgl.butter(N=4, Wn=[lowcut/nyquist, highcut/nyquist], btype='band')\n",
    "    \n",
    "    # Calculate the minimum length required by filtfilt.\n",
    "    min_len = 3 * (max(len(a), len(b)) - 1)\n",
    "    \n",
    "    # Filter each channel; if too short, skip filtering.\n",
    "    filtered = []\n",
    "    for ch_data in signal:\n",
    "        if len(ch_data) < min_len:\n",
    "            ch_data_filt = ch_data  # Fallback: leave unfiltered.\n",
    "        else:\n",
    "            ch_data_filt = sgl.filtfilt(b, a, ch_data)\n",
    "        filtered.append(ch_data_filt)\n",
    "    signal = np.vstack([ch[None, :] for ch in filtered])\n",
    "    \n",
    "    # 3) Baseline removal (subtract mean from each channel).\n",
    "    baseline_removed = []\n",
    "    for ch_data in signal:\n",
    "        ch_data_bs = ch_data - np.mean(ch_data)\n",
    "        baseline_removed.append(ch_data_bs)\n",
    "    signal = np.vstack([ch[None, :] for ch in baseline_removed])\n",
    "    \n",
    "    # 4) Padding/Truncation if target_length is provided.\n",
    "    if target_length is not None:\n",
    "        processed = []\n",
    "        for ch_data in signal:\n",
    "            ch_len = len(ch_data)\n",
    "            if ch_len == 0:\n",
    "                proc = np.zeros(target_length, dtype=np.float32)\n",
    "            elif ch_len < target_length:\n",
    "                pad_width = target_length - ch_len\n",
    "                proc = np.pad(ch_data, (0, pad_width), mode='edge')\n",
    "            else:\n",
    "                proc = ch_data[:target_length]\n",
    "            processed.append(proc.astype(np.float32))\n",
    "        signal = np.vstack([p[None, :] for p in processed])\n",
    "    \n",
    "    return signal.astype(np.float32)\n",
    "\n",
    "def split_into_modalities(signal):\n",
    "    # If the signal is 1D, assume it represents a single modality (e.g., ECG).\n",
    "    if signal.ndim == 1:\n",
    "        return {\"ecg\": signal}\n",
    "    else:\n",
    "        # If multi-channel, split into ECG, GSR, and EEG as desired.\n",
    "        ecg = signal[0, :]\n",
    "        gsr = signal[1, :]\n",
    "        eeg = signal[2, :] \n",
    "        return {\"ecg\": ecg, \"gsr\": gsr, \"eeg\": eeg}\n",
    "\n",
    "def discretize_label(label):\n",
    "    \"\"\"\n",
    "    Convert a label [valence, arousal] into a descriptive class.\n",
    "    If the flattened label has 2 elements, use them directly.\n",
    "    If it has 3 or more, use the second and third elements.\n",
    "    \"\"\"\n",
    "    flat_label = np.array(label).flatten()  # Ensure label is 1D.\n",
    "    if flat_label.size == 2:\n",
    "        valence, arousal = flat_label\n",
    "    elif flat_label.size >= 3:\n",
    "        valence, arousal = flat_label[1], flat_label[2]\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    if valence < 0 and arousal < 0:\n",
    "        return \"Low valence, Low arousal\"\n",
    "    elif valence < 0 and arousal >= 0:\n",
    "        return \"Low valence, High arousal\"\n",
    "    elif valence >= 0 and arousal < 0:\n",
    "        return \"High valence, Low arousal\"\n",
    "    else:\n",
    "        return \"High valence, High arousal\"\n",
    "\n",
    "# --- Feature Extraction Functions ---\n",
    "def extract_features(signals, fs=128):\n",
    "    \"\"\"\n",
    "    Extract features for multiple signals (ECG, GSR, EEG) from a dictionary.\n",
    "    If advanced processing (e.g., HRV from ECG) fails, falls back to basic statistics.\n",
    "    \"\"\"\n",
    "    feat_list = []\n",
    "\n",
    "    # ---------- ECG Features ----------\n",
    "    if 'ecg' in signals:\n",
    "        ecg_signal = np.array(signals['ecg']).flatten()\n",
    "        if len(ecg_signal) <= 18:\n",
    "            ecg_feats = [0.0] * 10  # Not enough data for advanced features.\n",
    "        else:\n",
    "            try:\n",
    "                ecg_cleaned = nk.ecg_clean(ecg_signal, sampling_rate=fs)\n",
    "                _, rpeaks = nk.ecg_peaks(ecg_cleaned, sampling_rate=fs)\n",
    "                # Check if any R-peaks were detected\n",
    "                if len(rpeaks.get(\"ECG_R_Peaks\", [])) == 0:\n",
    "                    raise ValueError(\"No R-peaks detected.\")\n",
    "                hrv = nk.hrv(rpeaks, sampling_rate=fs, show=False)\n",
    "                feature_names = [\n",
    "                    \"RMSSD\", \"SDNN\", \"pNN50\", \"pNN20\",\n",
    "                    \"LF/HF\", \"HF\", \"LF\", \"VLF\", \"HRV_TI\", \"SDSD\"\n",
    "                ]\n",
    "                ecg_feats = []\n",
    "                for name in feature_names:\n",
    "                    if name in hrv.columns and not np.isnan(hrv[name].values[0]):\n",
    "                        ecg_feats.append(hrv[name].values[0])\n",
    "                    else:\n",
    "                        ecg_feats.append(0.0)\n",
    "            except Exception as e:\n",
    "                # Fallback: Compute basic statistics if advanced features fail.\n",
    "                basic_stats = [\n",
    "                    np.mean(ecg_signal),\n",
    "                    np.std(ecg_signal),\n",
    "                    np.min(ecg_signal),\n",
    "                    np.max(ecg_signal),\n",
    "                    np.median(ecg_signal)\n",
    "                ]\n",
    "                # Pad to reach length 10.\n",
    "                ecg_feats = basic_stats + [0.0] * (10 - len(basic_stats))\n",
    "        feat_list.append(np.array(ecg_feats))\n",
    "\n",
    "    # ---------- GSR Features ----------\n",
    "    if 'gsr' in signals:\n",
    "        gsr_signal = np.array(signals['gsr']).flatten()\n",
    "        if len(gsr_signal) > 2:\n",
    "            try:\n",
    "                eda_cleaned = nk.eda_clean(gsr_signal, sampling_rate=fs)\n",
    "                eda_peaks, _ = nk.eda_peaks(eda_cleaned, sampling_rate=fs)\n",
    "                num_scr_peaks = eda_peaks.get(\"SCR_Peaks\", np.array([0])).sum()\n",
    "            except Exception:\n",
    "                num_scr_peaks = 0.0\n",
    "            gsr_feats = [\n",
    "                np.mean(gsr_signal),\n",
    "                np.std(gsr_signal),\n",
    "                np.min(gsr_signal),\n",
    "                np.max(gsr_signal),\n",
    "                kurtosis(gsr_signal),\n",
    "                skew(gsr_signal),\n",
    "                num_scr_peaks\n",
    "            ]\n",
    "        else:\n",
    "            gsr_feats = [0.0] * 7\n",
    "        feat_list.append(np.array(gsr_feats))\n",
    "\n",
    "    # ---------- EEG Features ----------\n",
    "    if 'eeg' in signals:\n",
    "        eeg_data = np.array(signals['eeg'])\n",
    "        if eeg_data.ndim == 1:\n",
    "            eeg_data = eeg_data[None, :]  # Ensure 2D shape.\n",
    "        all_channels_feats = []\n",
    "        for ch in range(eeg_data.shape[0]):\n",
    "            channel_signal = eeg_data[ch, :]\n",
    "            if len(channel_signal) < 2:\n",
    "                ch_feats = [0.0] * 6\n",
    "            else:\n",
    "                activity = np.var(channel_signal)\n",
    "                mobility = np.std(np.diff(channel_signal)) / (np.std(channel_signal) + 1e-8)\n",
    "                diff_signal = np.diff(channel_signal)\n",
    "                complexity = (np.std(np.diff(diff_signal)) / (np.std(diff_signal) + 1e-8)) / (mobility + 1e-8)\n",
    "                freqs, psd = welch(channel_signal, fs=fs, nperseg=min(256, len(channel_signal)))\n",
    "                def bandpower(f, pxx, fmin, fmax):\n",
    "                    idx = np.logical_and(f >= fmin, f <= fmax)\n",
    "                    # Use trapezoid integration as recommended.\n",
    "                    return np.trapezoid(pxx[idx], x=f[idx])\n",
    "                alpha = bandpower(freqs, psd, 8, 14)\n",
    "                beta  = bandpower(freqs, psd, 14, 30)\n",
    "                gamma = bandpower(freqs, psd, 30, 50)\n",
    "                ch_feats = [activity, mobility, complexity, alpha, beta, gamma]\n",
    "            all_channels_feats.append(ch_feats)\n",
    "        # Average across channels.\n",
    "        eeg_feats = np.mean(all_channels_feats, axis=0)\n",
    "        feat_list.append(eeg_feats)\n",
    "\n",
    "    # ---------- Combine all features ----------\n",
    "    if len(feat_list) == 0:\n",
    "        return np.zeros(10)\n",
    "    return np.concatenate(feat_list)\n",
    "\n",
    "def build_dataset(joined_data, labels_array, target_length=None):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    n_trials = joined_data.shape[1]\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        trial_data = joined_data[0, i]\n",
    "        signal = process_trial_signal(trial_data, target_length)\n",
    "        if signal.size == 0 or signal.shape[0] == 0:\n",
    "            print(f\"Warning: Trial {i} has an empty signal. Skipping trial.\")\n",
    "            continue\n",
    "\n",
    "        signals_dict = split_into_modalities(signal)\n",
    "        feats = extract_features(signals_dict, fs=128)\n",
    "        \n",
    "        lbl = np.array(labels_array[0, i]).squeeze()\n",
    "        if lbl.size < 3:\n",
    "            print(f\"Warning: Trial {i} does not have enough label data. Skipping trial.\")\n",
    "            continue\n",
    "        selected_label = lbl[1:3]  # use only the second and third columns\n",
    "        discrete_label = discretize_label(selected_label)\n",
    "\n",
    "        X_list.append(feats)\n",
    "        y_list.append(discrete_label)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        return None, None\n",
    "\n",
    "    X_array = np.vstack(X_list)\n",
    "    y_array = np.array(y_list)\n",
    "    return X_array, y_array\n",
    "\n",
    "def build_patient_data(joined_data, label_array):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    n_trials = joined_data.shape[1]\n",
    "    for i in range(n_trials):\n",
    "        trial_data = joined_data[0, i]\n",
    "        trial_data = np.array(trial_data, dtype=float).squeeze()\n",
    "        features = extract_features(trial_data)\n",
    "        \n",
    "        lbl = np.array(label_array[0, i]).squeeze()\n",
    "        if lbl.size < 3:\n",
    "            print(f\"Warning: Trial {i} does not have enough label data. Skipping trial.\")\n",
    "            continue\n",
    "        # Select only the second and third columns (i.e. indices 1 and 2)\n",
    "        selected_label = lbl[1:3]\n",
    "        discrete_label = discretize_label(selected_label)\n",
    "\n",
    "        \n",
    "        X_list.append(features)\n",
    "        y_list.append(discrete_label)\n",
    "    if len(X_list) == 0:\n",
    "        return None, None\n",
    "    return np.vstack(X_list), np.array(y_list)\n",
    "\n",
    "def load_all_patients_data(num_patients=40):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for patient in range(1, num_patients+1):\n",
    "        print(f\"Loading patient {patient}\")\n",
    "        data = load_patient_preprocessed_data(patient)\n",
    "        joined_data = data['joined_data']\n",
    "        labels_array = data['labels_ext_annotation']\n",
    "        X_patient, y_patient = build_patient_data(joined_data, labels_array)\n",
    "        if X_patient is not None and y_patient is not None:\n",
    "            X_list.append(X_patient)\n",
    "            y_list.append(y_patient)\n",
    "    if len(X_list) == 0:\n",
    "        raise ValueError(\"No patient data loaded.\")\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.concatenate(y_list)\n",
    "    return X_all, y_all\n",
    "\n",
    "# Load raw signals for CNN/LSTM/GRU\n",
    "def load_all_patients_raw_signal(num_patients=40, target_length=None):\n",
    "    X_list, y_list = [], []\n",
    "    for patient in range(1, num_patients + 1):\n",
    "        data = load_patient_preprocessed_data(patient)\n",
    "        joined_data = data['joined_data']\n",
    "        labels_array = data['labels_ext_annotation']\n",
    "        \n",
    "        X_patient, y_patient = build_dataset(joined_data, labels_array, target_length=target_length)\n",
    "        \n",
    "        if X_patient is not None:\n",
    "            X_list.append(X_patient)\n",
    "            y_list.append(y_patient)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No data loaded!\")\n",
    "\n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.concatenate(y_list)\n",
    "\n",
    "    return X_all, y_all\n",
    "\n",
    "def pad_trials(trials, pad_mode='constant', constant_values=0):\n",
    "    \"\"\"\n",
    "    Given a list of 2D arrays (each with shape (channels, time)), pad them so that all have the same shape.\n",
    "    Both channel and time dimensions are padded using constant values.\n",
    "    \"\"\"\n",
    "    # Determine maximum dimensions among all trials.\n",
    "    max_channels = max(trial.shape[0] for trial in trials)\n",
    "    max_time = max(trial.shape[1] for trial in trials)\n",
    "    \n",
    "    padded_trials = []\n",
    "    for trial in trials:\n",
    "        ch, t = trial.shape\n",
    "        # Pad channels if needed.\n",
    "        if ch < max_channels:\n",
    "            trial = np.pad(trial, ((0, max_channels - ch), (0, 0)), mode=pad_mode, constant_values=constant_values)\n",
    "        # Pad time dimension if needed.\n",
    "        if t < max_time:\n",
    "            trial = np.pad(trial, ((0, 0), (0, max_time - t)), mode=pad_mode, constant_values=constant_values)\n",
    "        elif t > max_time:\n",
    "            trial = trial[:, :max_time]\n",
    "        padded_trials.append(trial)\n",
    "    return np.stack(padded_trials, axis=0)\n",
    "\n",
    "def load_all_patients_raw_signal_deep_chunked(num_patients=40, target_length=None):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    for patient in range(1, num_patients+1):\n",
    "        print(f\"Processing patient {patient}...\")\n",
    "        data = load_patient_preprocessed_data(patient)\n",
    "        joined_data = data['joined_data']\n",
    "        labels_array = data['labels_ext_annotation']\n",
    "        n_trials = joined_data.shape[1]\n",
    "        for i in range(n_trials):\n",
    "            # Process label first.\n",
    "            lbl = np.array(labels_array[0, i]).squeeze()\n",
    "            if lbl.size == 0:\n",
    "                print(f\"Warning: Patient {patient} Trial {i} has empty label. Skipping trial.\")\n",
    "                continue\n",
    "            if lbl.ndim == 2:\n",
    "                lbl_processed = np.mean(lbl, axis=0)\n",
    "            elif lbl.ndim == 1:\n",
    "                lbl_processed = lbl\n",
    "            else:\n",
    "                lbl_processed = lbl.flatten()[0]\n",
    "            discrete_label = discretize_label(lbl_processed)\n",
    "            \n",
    "            trial_data = joined_data[0, i]\n",
    "            # Process trial signal to a 2D array with full length.\n",
    "            signal = process_trial_signal(trial_data, target_length).astype(np.float32)\n",
    "            all_X.append(signal)\n",
    "            all_y.append(discrete_label)\n",
    "        \n",
    "        del data, joined_data, labels_array\n",
    "        gc.collect()\n",
    "    \n",
    "    if len(all_X) == 0:\n",
    "        raise ValueError(\"No patient data loaded.\")\n",
    "    \n",
    "    if target_length is None:\n",
    "        X_all = pad_trials(all_X, pad_mode='constant', constant_values=0)\n",
    "    else:\n",
    "        X_all = np.stack(all_X, axis=0)\n",
    "    \n",
    "    y_all = np.array(all_y)\n",
    "    return X_all, y_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Trial 0 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 1 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 2 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 3 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 4 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 5 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 6 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 7 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 8 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 9 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 10 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 11 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 12 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 13 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 14 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 15 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 16 has an empty signal. Skipping trial.\n",
      "Warning: Trial 17 has an empty signal. Skipping trial.\n",
      "Warning: Trial 18 has an empty signal. Skipping trial.\n",
      "Warning: Trial 19 has an empty signal. Skipping trial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Trial 0 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 1 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 2 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 3 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 4 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 5 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 6 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 7 does not have enough label data. Skipping trial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Trial 8 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 9 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 10 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 11 does not have enough label data. Skipping trial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Trial 12 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 13 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 14 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 15 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 16 has an empty signal. Skipping trial.\n",
      "Warning: Trial 17 has an empty signal. Skipping trial.\n",
      "Warning: Trial 18 has an empty signal. Skipping trial.\n",
      "Warning: Trial 19 has an empty signal. Skipping trial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Trial 0 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 1 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 2 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 3 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 4 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 5 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 6 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 7 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 8 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 9 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 10 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 11 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 12 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 13 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 14 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 15 does not have enough label data. Skipping trial.\n",
      "Warning: Trial 16 has an empty signal. Skipping trial.\n",
      "Warning: Trial 17 has an empty signal. Skipping trial.\n",
      "Warning: Trial 18 has an empty signal. Skipping trial.\n",
      "Warning: Trial 19 has an empty signal. Skipping trial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:69: NeuroKitWarning: There are 5 missing data points in your signal. Filling missing values by using the forward filling method.\n",
      "  warn(\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\neurokit2\\eda\\eda_clean.py:94: FutureWarning: DataFrame.pad/Series.pad is deprecated. Use DataFrame.ffill/Series.ffill instead\n",
      "  eda_signal = pd.DataFrame.pad(pd.Series(eda_signal))\n"
     ]
    }
   ],
   "source": [
    "# Load raw signals\n",
    "X_signal, y_signal_desc = load_all_patients_raw_signal(num_patients=40, target_length=None)\n",
    "\n",
    "# Option: Use global normalization instead of per-sample normalization\n",
    "scaler_global = StandardScaler().fit(X_signal)\n",
    "X_signal_norm = scaler_global.transform(X_signal)\n",
    "\n",
    "# Continue with label encoding and train/test split as before\n",
    "unique_labels = np.unique(y_signal_desc)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int_signal = np.array([label_to_int[label] for label in y_signal_desc])\n",
    "y_cat_signal = to_categorical(y_int_signal)\n",
    "\n",
    "X_train, X_test, y_train, y_test, y_int_train, y_int_test = train_test_split(\n",
    "    X_signal_norm, y_cat_signal, y_int_signal,\n",
    "    test_size=0.2, random_state=42, stratify=y_int_signal\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Statistical Feature Extraction + ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating classifiers with 5-fold cross-validation:\n",
      "Logistic Regression: Mean Balanced Accuracy = 0.345\n",
      "SVM: Mean Balanced Accuracy = 0.521\n",
      "KNN: Mean Balanced Accuracy = 0.736\n",
      "Decision Tree: Mean Balanced Accuracy = 0.724\n",
      "Random Forest: Mean Balanced Accuracy = 0.786\n",
      "Gradient Boosting: Mean Balanced Accuracy = 0.712\n",
      "Extra Trees: Mean Balanced Accuracy = 0.813\n",
      "\n",
      "Best classifier based on cross-validation: Extra Trees\n",
      "\n",
      "Final Extra Trees Accuracy on Test Set: 0.480\n",
      "Confusion Matrix:\n",
      "[[ 2  4  1  9]\n",
      " [ 1  3  0 16]\n",
      " [ 0  0  1  2]\n",
      " [20 17  7 65]]\n"
     ]
    }
   ],
   "source": [
    "# Use the features and labels from the \"Load and Prepare Data\" cell\n",
    "X_stat = X_signal       # Already computed features from load_all_patients_raw_signal\n",
    "y_stat = y_signal_desc  # Corresponding labels\n",
    "\n",
    "# Optionally encode labels if they are not already integers\n",
    "unique_labels = np.unique(y_stat)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_int_stat = np.array([label_to_int[label] for label in y_stat])\n",
    "\n",
    "# Split the statistical features dataset into training and testing sets\n",
    "X_train_stat, X_test_stat, y_train_stat, y_test_stat, y_int_train, y_int_test = train_test_split(\n",
    "    X_stat, y_stat, y_int_stat,\n",
    "    test_size=0.2, random_state=42, stratify=y_int_stat\n",
    ")\n",
    "\n",
    "# --- Preprocessing for Statistical Features ---\n",
    "# Imputation\n",
    "imputer = SimpleImputer(strategy='mean').fit(X_train_stat)\n",
    "X_train_stat_imputed = imputer.transform(X_train_stat)\n",
    "X_test_stat_imputed = imputer.transform(X_test_stat)\n",
    "\n",
    "# Global normalization\n",
    "scaler_global = StandardScaler().fit(X_train_stat_imputed)\n",
    "X_train_global = scaler_global.transform(X_train_stat_imputed)\n",
    "X_test_global = scaler_global.transform(X_test_stat_imputed)\n",
    "\n",
    "# Apply PCA to reduce dimensionality while preserving 95% of variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_global)\n",
    "X_test_pca = pca.transform(X_test_global)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train_pca, y_int_train)\n",
    "\n",
    "# --- Evaluate Multiple ML Classifiers ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    \"SVM\": SVC(probability=True, class_weight='balanced'),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced'),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, class_weight='balanced')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "print(\"\\nEvaluating classifiers with 5-fold cross-validation:\")\n",
    "for clf_name, clf in classifiers.items():\n",
    "    try:\n",
    "        cv_scores = cross_val_score(clf, X_train_bal, y_train_bal, cv=5, scoring='balanced_accuracy')\n",
    "        results[clf_name] = np.mean(cv_scores)\n",
    "        print(f\"{clf_name}: Mean Balanced Accuracy = {np.mean(cv_scores):.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{clf_name} encountered an error during cross-validation: {e}\")\n",
    "\n",
    "if results:\n",
    "    best_clf_name = max(results, key=results.get)\n",
    "    print(\"\\nBest classifier based on cross-validation:\", best_clf_name)\n",
    "    \n",
    "    best_clf = classifiers[best_clf_name]\n",
    "    best_clf.fit(X_train_bal, y_train_bal)\n",
    "    predictions = best_clf.predict(X_test_pca)\n",
    "    acc = accuracy_score(y_int_test, predictions)\n",
    "    print(f\"\\nFinal {best_clf_name} Accuracy on Test Set: {acc:.3f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_int_test, predictions))\n",
    "else:\n",
    "    print(\"No classifier could be evaluated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

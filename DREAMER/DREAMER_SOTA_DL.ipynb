{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b69e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.linear_model import SGDClassifier # Not used in the final classical list\n",
    "# from sklearn.neural_network import MLPClassifier # Not used\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis # Not used\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import signal\n",
    "from scipy.signal import spectrogram, welch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import neurokit2 as nk\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc # For garbage collection\n",
    "\n",
    "# Deep Learning and SOTA Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, ReLU, MaxPooling2D, AveragePooling2D,\n",
    "                                     Flatten, Dense, Dropout, Input, Add, Activation, DepthwiseConv2D,\n",
    "                                     SpatialDropout2D, ELU, SeparableConv2D, GlobalAveragePooling2D, Resizing)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# KerasTuner for Hyperparameter Optimization\n",
    "# Install with: pip install keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Pre-trained model\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d153a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to the dataset\n",
    "path = \"C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\DREAMER.mat\" # Ensure this path is correct\n",
    "raw = sio.loadmat(path)\n",
    "\n",
    "# Parameters for CNN Spectrograms\n",
    "NPERSEG_CNN = 64  # nperseg for spectrogram generation\n",
    "NOVERLAP_CNN = NPERSEG_CNN // 2 # noverlap for spectrogram generation\n",
    "\n",
    "# Parameters for EEGNet\n",
    "EEGNET_SAMPLING_RATE = 128 # Hz, specific to DREAMER EEG\n",
    "EEGNET_CHANNELS = 14\n",
    "EEGNET_SAMPLES_PER_SUBJECT = 128 # Corresponds to 1 second of EEG data for EEGNet input\n",
    "\n",
    "# EfficientNetB0 parameters\n",
    "EFFNET_IMG_SIZE = 32 # Minimum typical size for EfficientNet, resize spectrograms to this\n",
    "EFFNET_CHANNELS = 3 # EfficientNet expects 3 channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ca1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_extract_ECG(raw_data, model_type='RNN', sampling_rate=256, fixed_length=None,\n",
    "                     nperseg_spec=None, noverlap_spec=None):\n",
    "    extracted_data_ts = []\n",
    "    extracted_data_spec = []\n",
    "    n_participants = 23\n",
    "    n_videos = 18\n",
    "\n",
    "    for participant in range(n_participants):\n",
    "        for video in range(n_videos):\n",
    "            basl_left = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                [\"baseline\"][0, 0][video, 0][:, 0]\n",
    "            stim_left = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                [\"stimuli\"][0, 0][video, 0][:, 0]\n",
    "            basl_right = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                 [\"baseline\"][0, 0][video, 0][:, 1]\n",
    "            stim_right = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                 [\"stimuli\"][0, 0][video, 0][:, 1]\n",
    "\n",
    "            try:\n",
    "                signals_b_l, _ = nk.ecg_process(basl_left, sampling_rate=sampling_rate)\n",
    "                signals_s_l, _ = nk.ecg_process(stim_left, sampling_rate=sampling_rate)\n",
    "                signals_b_r, _ = nk.ecg_process(basl_right, sampling_rate=sampling_rate)\n",
    "                signals_s_r, _ = nk.ecg_process(stim_right, sampling_rate=sampling_rate)\n",
    "\n",
    "                ecg_clean_left = signals_s_l[\"ECG_Clean\"].values - np.mean(signals_b_l[\"ECG_Clean\"].values)\n",
    "                ecg_clean_right = signals_s_r[\"ECG_Clean\"].values - np.mean(signals_b_r[\"ECG_Clean\"].values)\n",
    "            except Exception as e:\n",
    "                # print(f\"Neurokit processing error for P{participant+1} V{video+1} ECG: {e}. Using zeros.\")\n",
    "                ecg_clean_left = np.zeros(fixed_length if fixed_length else sampling_rate) # fallback\n",
    "                ecg_clean_right = np.zeros(fixed_length if fixed_length else sampling_rate)\n",
    "\n",
    "\n",
    "            sample_time_series = np.stack([ecg_clean_left, ecg_clean_right], axis=-1)\n",
    "\n",
    "            if fixed_length is not None:\n",
    "                T = sample_time_series.shape[0]\n",
    "                if T > fixed_length:\n",
    "                    sample_time_series = sample_time_series[:fixed_length, :]\n",
    "                elif T < fixed_length:\n",
    "                    pad_width = fixed_length - T\n",
    "                    sample_time_series = np.pad(sample_time_series, ((0, pad_width), (0, 0)), mode='constant')\n",
    "\n",
    "            if model_type.upper() == 'RNN':\n",
    "                extracted_data_ts.append(sample_time_series.flatten())\n",
    "            elif model_type.upper() == 'CNN':\n",
    "                spec_channels = []\n",
    "                for ch_idx in range(sample_time_series.shape[1]):\n",
    "                    signal_ch = sample_time_series[:, ch_idx]\n",
    "                    if np.std(signal_ch) < 1e-9:\n",
    "                        n_freq_bins = nperseg_spec // 2 + 1\n",
    "                        n_time_bins = (fixed_length - noverlap_spec) // (nperseg_spec - noverlap_spec)\n",
    "                        Sxx = np.zeros((n_freq_bins, n_time_bins))\n",
    "                    else:\n",
    "                        _, _, Sxx = spectrogram(signal_ch, fs=sampling_rate, nperseg=nperseg_spec, noverlap=noverlap_spec)\n",
    "                    spec_channels.append(np.log1p(Sxx))\n",
    "                sample_spec = np.stack(spec_channels, axis=-1)\n",
    "                extracted_data_spec.append(sample_spec)\n",
    "\n",
    "    if model_type.upper() == 'RNN':\n",
    "        return pd.DataFrame(extracted_data_ts)\n",
    "    elif model_type.upper() == 'CNN':\n",
    "        return np.array(extracted_data_spec)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be either 'RNN' or 'CNN'\")\n",
    "\n",
    "def feat_extract_EEG(raw_data, model_type='RNN_FLAT', sampling_rate=128, fixed_length=None, # EEG sampling rate is 128Hz in DREAMER\n",
    "                     nperseg_spec=None, noverlap_spec=None):\n",
    "    \"\"\"\n",
    "    Extract EEG data.\n",
    "    model_type:\n",
    "      'RNN_FLAT': Flattens time series for classical ML. (fixed_length = EEGNET_SAMPLES_PER_SUBJECT)\n",
    "      'CNN_SPECTROGRAM': Spectrograms for CNNs. (fixed_length = fixed_length_cnn)\n",
    "      'EEGNET_INPUT': Shaped for EEGNet (N, C, T, 1) or (N, T, C) then reshaped. (fixed_length = EEGNET_SAMPLES_PER_SUBJECT)\n",
    "    \"\"\"\n",
    "    extracted_data_rnn_flat = []\n",
    "    extracted_data_cnn_spec = []\n",
    "    extracted_data_eegnet = [] # List of (fixed_length, n_channels)\n",
    "\n",
    "    n_participants = 23\n",
    "    n_videos = 18\n",
    "    n_channels = 14\n",
    "\n",
    "    for participant in range(n_participants):\n",
    "        for video in range(n_videos):\n",
    "            channels_data_single_trial = [] # For one trial, (fixed_length, n_channels)\n",
    "            for i in range(n_channels):\n",
    "                basl = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0]\\\n",
    "                                [\"baseline\"][0, 0][video, 0][:, i]\n",
    "                stim = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0]\\\n",
    "                                [\"stimuli\"][0, 0][video, 0][:, i]\n",
    "                corrected_signal = stim - np.mean(basl) # Simple baseline correction\n",
    "                channels_data_single_trial.append(corrected_signal)\n",
    "\n",
    "            # Before padding, stack to (timesteps_original, n_channels)\n",
    "            sample_time_series_unpadded = np.stack(channels_data_single_trial, axis=-1)\n",
    "\n",
    "            # Pad/truncate to fixed_length\n",
    "            current_fixed_length = fixed_length # Use the passed fixed_length\n",
    "            T_orig = sample_time_series_unpadded.shape[0]\n",
    "            \n",
    "            if T_orig > current_fixed_length:\n",
    "                sample_time_series = sample_time_series_unpadded[:current_fixed_length, :]\n",
    "            elif T_orig < current_fixed_length:\n",
    "                pad_width_time = current_fixed_length - T_orig\n",
    "                sample_time_series = np.pad(sample_time_series_unpadded, ((0, pad_width_time), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                sample_time_series = sample_time_series_unpadded # No padding/truncation needed\n",
    "\n",
    "            # --- Process based on model_type ---\n",
    "            if model_type.upper() == 'RNN_FLAT':\n",
    "                extracted_data_rnn_flat.append(sample_time_series.flatten())\n",
    "\n",
    "            elif model_type.upper() == 'CNN_SPECTROGRAM':\n",
    "                spec_channels = []\n",
    "                for ch_idx in range(sample_time_series.shape[1]): # Iterate over 14 channels\n",
    "                    signal_ch = sample_time_series[:, ch_idx]\n",
    "                    if np.std(signal_ch) < 1e-9:\n",
    "                        n_freq_bins = nperseg_spec // 2 + 1\n",
    "                        n_time_bins = (current_fixed_length - noverlap_spec) // (nperseg_spec - noverlap_spec)\n",
    "                        Sxx = np.zeros((n_freq_bins, n_time_bins))\n",
    "                    else:\n",
    "                        _, _, Sxx = spectrogram(signal_ch, fs=sampling_rate, nperseg=nperseg_spec, noverlap=noverlap_spec)\n",
    "                    spec_channels.append(np.log1p(Sxx))\n",
    "                sample_spec = np.stack(spec_channels, axis=-1) # (n_freq, n_time, 14)\n",
    "                extracted_data_cnn_spec.append(sample_spec)\n",
    "\n",
    "            elif model_type.upper() == 'EEGNET_INPUT':\n",
    "                # Expected shape (fixed_length, n_channels) for now, will be reshaped later\n",
    "                extracted_data_eegnet.append(sample_time_series)\n",
    "\n",
    "\n",
    "    if model_type.upper() == 'RNN_FLAT':\n",
    "        return pd.DataFrame(extracted_data_rnn_flat)\n",
    "    elif model_type.upper() == 'CNN_SPECTROGRAM':\n",
    "        return np.array(extracted_data_cnn_spec) # (n_samples, n_freq, n_time, 14)\n",
    "    elif model_type.upper() == 'EEGNET_INPUT':\n",
    "        # Return as (n_samples, fixed_length, n_channels)\n",
    "        # Reshape to (n_samples, n_channels, fixed_length, 1) or (n_samples, 1, n_channels, fixed_length) later\n",
    "        return np.array(extracted_data_eegnet)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'RNN_FLAT', 'CNN_SPECTROGRAM', or 'EEGNET_INPUT'\")\n",
    "\n",
    "\n",
    "def participant_affective(raw_data):\n",
    "    # (Identical to your original function)\n",
    "    a = np.zeros((23, 18, 9), dtype=object)\n",
    "    for participant in range(0, 23):\n",
    "        for video in range(0, 18):\n",
    "            a[participant, video, 0] = (raw_data[\"DREAMER\"][0, 0][\"Data\"]\n",
    "                                        [0, participant][\"Age\"][0][0][0])\n",
    "            a[participant, video, 1] = (raw_data[\"DREAMER\"][0, 0][\"Data\"]\n",
    "                                        [0, participant][\"Gender\"][0][0][0])\n",
    "            a[participant, video, 2] = int(participant+1)\n",
    "            a[participant, video, 3] = int(video+1)\n",
    "            a[participant, video, 4] = [\"Searching for Bobby Fischer\", \"D.O.A.\", \"The Hangover\", \"The Ring\", \"300\", \"National Lampoon\\'s VanWilder\", \"Wall-E\", \"Crash\", \"My Girl\", \"The Fly\", \"Pride and Prejudice\", \"Modern Times\", \"Remember the Titans\", \"Gentlemans Agreement\", \"Psycho\", \"The Bourne Identitiy\", \"The Shawshank Redemption\", \"The Departed\"][video]\n",
    "            a[participant, video, 5] = [\"calmness\", \"surprise\", \"amusement\", \"fear\", \"excitement\", \"disgust\", \"happiness\", \"anger\", \"sadness\", \"disgust\", \"calmness\", \"amusement\", \"happiness\", \"anger\", \"fear\", \"excitement\", \"sadness\", \"surprise\"][video]\n",
    "            a[participant, video, 6] = int(raw_data[\"DREAMER\"][0, 0][\"Data\"] [0, participant][\"ScoreValence\"] [0, 0][video, 0])\n",
    "            a[participant, video, 7] = int(raw_data[\"DREAMER\"][0, 0][\"Data\"] [0, participant][\"ScoreArousal\"] [0, 0][video, 0])\n",
    "            a[participant, video, 8] = int(raw_data[\"DREAMER\"][0, 0][\"Data\"] [0, participant][\"ScoreDominance\"] [0, 0][video, 0])\n",
    "    b = pd.DataFrame(a.reshape((23*18, a.shape[2])), columns=[\"age\", \"gender\", \"participant\", \"video\", \"video_name\", \"target_emotion\", \"valence\", \"arousal\", \"dominance\"])\n",
    "    for col in [\"age\", \"participant\", \"video\", \"valence\", \"arousal\", \"dominance\"]: b[col] = b[col].astype(int)\n",
    "    b[\"gender\"] = b[\"gender\"].astype(str)\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c719cf7",
   "metadata": {},
   "source": [
    "## Data Augmentation: SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c00ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecAugment(tf.keras.layers.Layer):\n",
    "    \"\"\"Spectrogram augmentation layer performing frequency and time masking.\n",
    "       Assumes channels_last format (batch, freq, time, channels).\n",
    "    \"\"\"\n",
    "    def __init__(self, freq_mask_param, time_mask_param, num_freq_masks, num_time_masks, name=\"spec_augment\", **kwargs):\n",
    "        super(SpecAugment, self).__init__(name=name, **kwargs)\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "        self.time_mask_param = time_mask_param\n",
    "        self.num_freq_masks = num_freq_masks\n",
    "        self.num_time_masks = num_time_masks\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if not training:\n",
    "            return inputs\n",
    "\n",
    "        augmented_inputs = inputs\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, num_freq_bins, num_time_frames, num_channels = input_shape[0], input_shape[1], input_shape[2], input_shape[3]\n",
    "        num_freq_bins_float = tf.cast(num_freq_bins, tf.float32)\n",
    "        num_time_frames_float = tf.cast(num_time_frames, tf.float32)\n",
    "\n",
    "\n",
    "        for _ in range(self.num_freq_masks):\n",
    "            f = tf.random.uniform([], minval=0, maxval=self.freq_mask_param, dtype=tf.int32)\n",
    "            f0 = tf.random.uniform([], minval=0, maxval=num_freq_bins - f, dtype=tf.int32)\n",
    "            mask = tf.concat([tf.ones((batch_size, f0, num_time_frames, num_channels)),\n",
    "                              tf.zeros((batch_size, f, num_time_frames, num_channels)),\n",
    "                              tf.ones((batch_size, num_freq_bins - f0 - f, num_time_frames, num_channels))], axis=1)\n",
    "            augmented_inputs = augmented_inputs * mask\n",
    "        \n",
    "        for _ in range(self.num_time_masks):\n",
    "            t = tf.random.uniform([], minval=0, maxval=self.time_mask_param, dtype=tf.int32)\n",
    "            t0 = tf.random.uniform([], minval=0, maxval=num_time_frames - t, dtype=tf.int32)\n",
    "            mask = tf.concat([tf.ones((batch_size, num_freq_bins, t0, num_channels)),\n",
    "                              tf.zeros((batch_size, num_freq_bins, t, num_channels)),\n",
    "                              tf.ones((batch_size, num_freq_bins, num_time_frames - t0 - t, num_channels))], axis=2)\n",
    "            augmented_inputs = augmented_inputs * mask\n",
    "            \n",
    "        return augmented_inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"freq_mask_param\": self.freq_mask_param,\n",
    "            \"time_mask_param\": self.time_mask_param,\n",
    "            \"num_freq_masks\": self.num_freq_masks,\n",
    "            \"num_time_masks\": self.num_time_masks,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c61e41",
   "metadata": {},
   "source": [
    "## Part 1: Classical ML Classifiers (using RNN-style flattened features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d29f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting RNN-style features for classical ML...\n",
      "Shape of X_rnn for classical ML: (138, 2304)\n",
      "\n",
      "Running classical ML models...\n",
      "Training Nearest Neighbors...\n",
      "Nearest Neighbors: Mean Acc = 0.5950 +/- 0.0759\n",
      "Training Linear SVM...\n",
      "Linear SVM: Mean Acc = 0.6517 +/- 0.0186\n",
      "Training RBF SVM...\n",
      "RBF SVM: Mean Acc = 0.6667 +/- 0.0000\n",
      "Training Gaussian Process...\n",
      "Gaussian Process: Mean Acc = 0.6600 +/- 0.0133\n",
      "Training Decision Tree...\n",
      "Decision Tree: Mean Acc = 0.5383 +/- 0.0869\n",
      "Training Random Forest...\n",
      "Random Forest: Mean Acc = 0.6217 +/- 0.0557\n",
      "Training AdaBoost...\n",
      "AdaBoost: Mean Acc = 0.5583 +/- 0.0756\n",
      "Training Naive Bayes...\n",
      "Naive Bayes: Mean Acc = 0.4833 +/- 0.1109\n",
      "\n",
      "Classical ML Results:\n",
      "                 name  mean_score  std_score  mean_runtime\n",
      "0  Nearest Neighbors    0.595000   0.075939      0.069536\n",
      "1         Linear SVM    0.651667   0.018559      0.004673\n",
      "2            RBF SVM    0.666667   0.000000      0.003163\n",
      "3   Gaussian Process    0.660000   0.013333      0.003397\n",
      "4      Decision Tree    0.538333   0.086859      0.002258\n",
      "5      Random Forest    0.621667   0.055678      0.005249\n",
      "6           AdaBoost    0.558333   0.075645      0.007886\n",
      "7        Naive Bayes    0.483333   0.110930      0.002226\n"
     ]
    }
   ],
   "source": [
    "fixed_length_eeg_rnn = EEGNET_SAMPLES_PER_SUBJECT # 128 samples for EEG (1s)\n",
    "fixed_length_ecg_rnn = 256  # 1 second of ECG data at 256 Hz for consistency with previous setup\n",
    "\n",
    "print(\"Extracting RNN-style features for classical ML...\")\n",
    "df_EEG_rnn = feat_extract_EEG(raw, model_type='RNN_FLAT', sampling_rate=EEGNET_SAMPLING_RATE, fixed_length=fixed_length_eeg_rnn)\n",
    "df_ECG_rnn = feat_extract_ECG(raw, model_type='RNN', sampling_rate=256, fixed_length=fixed_length_ecg_rnn) # Using original ECG feat extract\n",
    "df_features_rnn = pd.concat([df_EEG_rnn, df_ECG_rnn], axis=1)\n",
    "df_features_rnn.columns = [f\"feat_{i}\" for i in range(df_features_rnn.shape[1])]\n",
    "\n",
    "df_participant_affective = participant_affective(raw)\n",
    "df_rnn = pd.concat([df_features_rnn, df_participant_affective.reset_index(drop=True)], axis=1) # reset_index if needed\n",
    "\n",
    "data_rnn = df_rnn.loc[(df_rnn['target_emotion'] == 'anger') |\n",
    "                      (df_rnn['target_emotion'] == 'fear') |\n",
    "                      (df_rnn['target_emotion'] == 'calmness')].copy()\n",
    "\n",
    "data_rnn['stress_bin'] = data_rnn['target_emotion'].map({'anger': 1, 'fear': 1, 'calmness': 0})\n",
    "\n",
    "X_rnn = np.array(data_rnn.iloc[:, 0:df_features_rnn.shape[1]])\n",
    "y_rnn = np.array(data_rnn['stress_bin'])\n",
    "groups_rnn = np.array(data_rnn['participant'])\n",
    "\n",
    "print(f\"Shape of X_rnn for classical ML: {X_rnn.shape}\")\n",
    "\n",
    "def run_clf_cv(clf, X, y, groups, n_splits=10):\n",
    "    cv = GroupKFold(n_splits=n_splits)\n",
    "    scores_list, runtimes_list = [], []\n",
    "    if np.isnan(X).any(): print(\"Warning: NaNs in X for classical. Imputer should handle.\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        clf.fit(X_train, y_train)\n",
    "        start_time = time.time()\n",
    "        score = clf.score(X_test, y_test)\n",
    "        runtime = time.time() - start_time\n",
    "        scores_list.append(score); runtimes_list.append(runtime)\n",
    "    return scores_list, runtimes_list\n",
    "\n",
    "results_classical = []\n",
    "names_classical = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\", \n",
    "                   \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Naive Bayes\"]\n",
    "classifiers_classical = [\n",
    "    KNeighborsClassifier(3), SVC(kernel=\"linear\", C=0.025, probability=True), SVC(gamma=2, C=1, probability=True),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)), DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=100, max_features='sqrt'), AdaBoostClassifier(), GaussianNB()]\n",
    "\n",
    "print(\"\\nRunning classical ML models...\")\n",
    "for name, classifier_model in zip(names_classical, classifiers_classical):\n",
    "    pipeline = make_pipeline(SimpleImputer(strategy='mean'), MinMaxScaler(), classifier_model)\n",
    "    print(f\"Training {name}...\")\n",
    "    try:\n",
    "        # Reduce n_splits for faster initial testing if needed\n",
    "        scores, runtimes = run_clf_cv(pipeline, X_rnn, y_rnn, groups_rnn, n_splits=5) \n",
    "        results_classical.append([name, np.mean(scores), np.std(scores), np.mean(runtimes)])\n",
    "        print(f\"{name}: Mean Acc = {np.mean(scores):.4f} +/- {np.std(scores):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not run {name}. Error: {e}\")\n",
    "        results_classical.append([name, np.nan, np.nan, np.nan])\n",
    "results_classical_df = pd.DataFrame(results_classical, columns=['name', 'mean_score', 'std_score', 'mean_runtime'])\n",
    "print(\"\\nClassical ML Results:\\n\", results_classical_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9bc7a9",
   "metadata": {},
   "source": [
    "## Part 2: CNN / Advanced DL Classifiers (Spectrogram & Time-Series Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7523a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting CNN-style spectrogram features...\n",
      "Shape of combined X_cnn_spectrograms: (414, 33, 7, 16)\n"
     ]
    }
   ],
   "source": [
    "# --- Data Prep for CNNs (Spectrograms) ---\n",
    "fixed_length_cnn = 256 # Num samples for spectrogram input signal (2s for EEG@128Hz, 1s for ECG@256Hz)\n",
    "print(\"\\nExtracting CNN-style spectrogram features...\")\n",
    "data_EEG_cnn_spec = feat_extract_EEG(raw, model_type='CNN_SPECTROGRAM', sampling_rate=EEGNET_SAMPLING_RATE, fixed_length=fixed_length_cnn,\n",
    "                                nperseg_spec=NPERSEG_CNN, noverlap_spec=NOVERLAP_CNN)\n",
    "data_ECG_cnn_spec = feat_extract_ECG(raw, model_type='CNN', sampling_rate=256, fixed_length=fixed_length_cnn,\n",
    "                                nperseg_spec=NPERSEG_CNN, noverlap_spec=NOVERLAP_CNN)\n",
    "\n",
    "X_cnn_spectrograms = np.concatenate((data_EEG_cnn_spec, data_ECG_cnn_spec), axis=-1)\n",
    "print(f\"Shape of combined X_cnn_spectrograms: {X_cnn_spectrograms.shape}\") # (414, 33, 7, 16)\n",
    "\n",
    "# Align with targets (already done for data_rnn, can reuse indices)\n",
    "df_cnn_targets = df_participant_affective.copy()\n",
    "data_cnn_filtered_df = df_cnn_targets.loc[(df_cnn_targets['target_emotion'] == 'anger') |\n",
    "                                          (df_cnn_targets['target_emotion'] == 'fear') |\n",
    "                                          (df_cnn_targets['target_emotion'] == 'calmness')].copy()\n",
    "idx_filter = data_cnn_filtered_df.index\n",
    "X_cnn_spec_filtered = X_cnn_spectrograms[idx_filter]\n",
    "y_cnn_labels = data_cnn_filtered_df['target_emotion'].map({'anger': 1, 'fear': 1, 'calmness': 0}).values\n",
    "groups_cnn_labels = data_cnn_filtered_df['participant'].values\n",
    "\n",
    "if np.isnan(X_cnn_spec_filtered).any():\n",
    "    print(\"Warning: NaNs found in X_cnn_spec_filtered. Replacing with 0.\")\n",
    "    X_cnn_spec_filtered = np.nan_to_num(X_cnn_spec_filtered, nan=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88b9c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definitions ---\n",
    "\n",
    "def create_simple_cnn_model(input_shape, spec_augment_params=None):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    if spec_augment_params:\n",
    "        x = SpecAugment(**spec_augment_params)(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x); x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x) # (None, 16, 3, 32) for (33,7) input\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x); x = ReLU()(x)\n",
    "    x = MaxPooling2D((2, 2))(x) # (None, 8, 1, 64)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    # Compile outside or pass optimizer, loss\n",
    "    return model\n",
    "\n",
    "def resnet_block_mod(input_tensor, hp, stage_idx, block_idx): # Modified for KerasTuner\n",
    "    filters = hp.Int(f's{stage_idx}_b{block_idx}_filters', 32, 128, step=32)\n",
    "    kernel_size = hp.Choice(f's{stage_idx}_b{block_idx}_kernel', [3, 5])\n",
    "    strides = 1\n",
    "    use_batchnorm = hp.Boolean(f's{stage_idx}_b{block_idx}_bn')\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(kernel_size,kernel_size), strides=strides, padding='same')(input_tensor)\n",
    "    if use_batchnorm: x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=(kernel_size,kernel_size), padding='same')(x)\n",
    "    if use_batchnorm: x = BatchNormalization()(x)\n",
    "\n",
    "    if strides > 1 or input_tensor.shape[-1] != filters: # Basic shortcut handling\n",
    "        shortcut = Conv2D(filters, kernel_size=(1,1), strides=strides, padding='same')(input_tensor)\n",
    "        if use_batchnorm: shortcut = BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_tensor\n",
    "    x = Add()([x, shortcut]); x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_for_tuner(hp, input_shape, spec_augment_params=None): # For KerasTuner\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    if spec_augment_params and hp.Boolean(\"spec_augment\"):\n",
    "         x = SpecAugment(freq_mask_param=hp.Int('SA_freq_param', 1, 10), # Example HP for SA\n",
    "                         time_mask_param=hp.Int('SA_time_param', 1, 3),\n",
    "                         num_freq_masks=hp.Int('SA_n_freq', 1, 2),\n",
    "                         num_time_masks=hp.Int('SA_n_time', 1, 2))(x)\n",
    "\n",
    "\n",
    "    initial_filters = hp.Int('initial_filters', 32, 64, step=32)\n",
    "    x = Conv2D(initial_filters, (3,3), padding='same')(x)\n",
    "    if hp.Boolean(\"initial_bn\"): x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    num_stages = hp.Int('num_stages', 1, 2) # Simpler ResNet\n",
    "    for s_idx in range(num_stages):\n",
    "        num_blocks_in_stage = hp.Int(f's{s_idx}_num_blocks', 1, 2)\n",
    "        for b_idx in range(num_blocks_in_stage):\n",
    "            x = resnet_block_mod(x, hp, s_idx, b_idx)\n",
    "        if s_idx < num_stages -1 and x.shape[1] > 1 and x.shape[2] > 1 : # Downsample if not last stage and possible\n",
    "             if hp.Boolean(f\"s{s_idx}_downsample\"):\n",
    "                x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=hp.Int('dense_units', 32, 128, step=32), activation='relu')(x)\n",
    "    x = Dropout(hp.Float('dropout_dense', 0.2, 0.5, step=0.1))(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 5e-4, 1e-4])),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_adapted_efficientnet(input_shape, num_classes=1, spec_augment_params=None):\n",
    "    inputs = Input(shape=input_shape)  # e.g. (33,7,16)\n",
    "    x = inputs\n",
    "\n",
    "    # If channels ≠ 3, first collapse your 16 channels into 1, then convert to RGB\n",
    "    if input_shape[-1] != EFFNET_CHANNELS:\n",
    "        # 1) Mean across last axis → shape (H,W,1)\n",
    "        x = Lambda(lambda t: tf.reduce_mean(t, axis=-1, keepdims=True),\n",
    "                   name='collapse_channels')(x)\n",
    "        # 2) Convert grayscale→RGB (now (H,W,3))\n",
    "        x = Lambda(lambda t: tf.image.grayscale_to_rgb(t),\n",
    "                   name='to_rgb')(x)\n",
    "\n",
    "    # 3) Resize spatial dims to EfficientNet’s minimum\n",
    "    x = Resizing(EFFNET_IMG_SIZE, EFFNET_IMG_SIZE, name='resize_eff')(\n",
    "        x\n",
    "    )\n",
    "\n",
    "    # 4) (Optional) SpecAugment, after resizing but before feeding into EffNet\n",
    "    if spec_augment_params:\n",
    "        # clamp mask sizes so they’re meaningful on resized input\n",
    "        sa_params = spec_augment_params.copy()\n",
    "        sa_params['freq_mask_param'] = min(sa_params['freq_mask_param'], EFFNET_IMG_SIZE//4)\n",
    "        sa_params['time_mask_param'] = min(sa_params['time_mask_param'], EFFNET_IMG_SIZE//4)\n",
    "        x = SpecAugment(**sa_params)(x)\n",
    "\n",
    "    # 5) Load pre‐trained EfficientNetB0, starting from this tensor `x`\n",
    "    base = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=x,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    # 6) Attach your own classification head\n",
    "    preds = Dense(\n",
    "        num_classes,\n",
    "        activation='sigmoid' if num_classes==1 else 'softmax',\n",
    "        name='effnet_preds'\n",
    "    )(base.output)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=preds, name='AdaptedEfficientNetB0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "993dfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EEGNet Model ---\n",
    "# (Adapted from official EEGNet Keras implementation, simplified)\n",
    "def EEGNet(nb_classes, Chans=64, Samples=128, dropoutRate=0.5, kernLength=64, F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D or Dropout')\n",
    "\n",
    "    input1 = Input(shape=(Chans, Samples, 1)) # channels_first like format\n",
    "\n",
    "    block1 = Conv2D(F1, (1, kernLength), padding='same', input_shape=(Chans, Samples, 1), use_bias=False)(input1)\n",
    "    block1 = BatchNormalization(axis=1)(block1) # Normalizing over channels\n",
    "    block1 = DepthwiseConv2D((Chans, 1), use_bias=False, depth_multiplier=D, depthwise_constraint=max_norm(1.))(block1)\n",
    "    block1 = BatchNormalization(axis=1)(block1)\n",
    "    block1 = Activation('elu')(block1)\n",
    "    block1 = AveragePooling2D((1, 4))(block1)\n",
    "    block1 = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2 = SeparableConv2D(F2, (1, 16), use_bias=False, padding='same')(block1)\n",
    "    block2 = BatchNormalization(axis=1)(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = AveragePooling2D((1, 8))(block2)\n",
    "    block2 = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten = Flatten(name='flatten')(block2)\n",
    "    dense = Dense(nb_classes, name='dense', kernel_constraint=max_norm(norm_rate))(flatten)\n",
    "    softmax = Activation('sigmoid' if nb_classes == 1 else 'softmax', name='softmax')(dense) # Sigmoid for binary\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b4893",
   "metadata": {},
   "source": [
    "### KerasTuner Setup (Example for one fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4759fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KerasTuner Example ---\n",
    "# Best to run this separately or for a single fold due to time constraints.\n",
    "# We'll define it but not run it in the main CV loop for all models to save time here.\n",
    "def run_kerastuner_example(X_train_fold, y_train_fold, X_val_fold, y_val_fold, input_shape):\n",
    "    print(\"\\n--- Running KerasTuner Example ---\")\n",
    "    # Define SpecAugment parameters to be potentially tuned or fixed\n",
    "    spec_augment_params_for_tuner = {\n",
    "        'freq_mask_param': 5, # Max size of freq mask (fixed for this example)\n",
    "        'time_mask_param': 2, # Max size of time mask (fixed for this example)\n",
    "        'num_freq_masks': 1,\n",
    "        'num_time_masks': 1\n",
    "    }\n",
    "    \n",
    "    tuner = kt.Hyperband(\n",
    "        lambda hp: build_resnet_for_tuner(hp, input_shape, spec_augment_params_for_tuner), # Pass fixed SA params\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=10, # For demo, keep low. Real tuning: 30-50+\n",
    "        factor=3,\n",
    "        directory='kerastuner_dir',\n",
    "        project_name='stress_resnet_tuning'\n",
    "    )\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    \n",
    "    print(\"Starting KerasTuner search...\")\n",
    "    tuner.search(X_train_fold, y_train_fold,\n",
    "                 epochs=15, # Max epochs per trial for tuner search\n",
    "                 validation_data=(X_val_fold, y_val_fold),\n",
    "                 callbacks=[stop_early],\n",
    "                 batch_size=16) # Tuner might override batch_size if defined in HP space\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print(f\"\\nBest HPs found: {best_hps.values}\")\n",
    "\n",
    "    # Build the model with the best HPs\n",
    "    # model = tuner.hypermodel.build(best_hps)\n",
    "    # history = model.fit(X_train_fold, y_train_fold, epochs=20, validation_data=(X_val_fold, y_val_fold)) # Retrain\n",
    "    # val_acc_per_epoch = history.history['val_accuracy']\n",
    "    # best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "    # print(f'Best epoch: {best_epoch}')\n",
    "    # Re-initialize the model and train for the optimal number of epochs on the full training data.\n",
    "    # For now, just printing HPs.\n",
    "    return best_hps\n",
    "\n",
    "# To run the tuner (example using first fold data for X_cnn_spec_filtered):\n",
    "# cv_temp = GroupKFold(n_splits=5)\n",
    "# train_idx_kt, val_idx_kt = next(cv_temp.split(X_cnn_spec_filtered, y_cnn_labels, groups_cnn_labels))\n",
    "# X_train_kt, X_val_kt = X_cnn_spec_filtered[train_idx_kt], X_cnn_spec_filtered[val_idx_kt]\n",
    "# y_train_kt, y_val_kt = y_cnn_labels[train_idx_kt], y_cnn_labels[val_idx_kt]\n",
    "# # best_hyperparameters = run_kerastuner_example(X_train_kt, y_train_kt, X_val_kt, y_val_kt, X_cnn_spec_filtered.shape[1:])\n",
    "# # print(\"To use best HPs, manually update model creation or load them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84954fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training and Evaluation Loop for DL Models ---\n",
    "def run_dl_model_cv(model_fn, X_data_list, y_data, groups_data, model_name,\n",
    "                    n_splits=5, epochs=25, batch_size=16, compile_kwargs=None, model_kwargs=None):\n",
    "    print(f\"\\n--- Evaluating: {model_name} ---\")\n",
    "    cv_dl = GroupKFold(n_splits=n_splits)\n",
    "    scores, runtimes = [], []\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "    X_for_split = X_data_list[0]\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_dl.split(X_for_split, y_data, groups_data)):\n",
    "        print(f\"{model_name} - Fold {fold+1}/{n_splits}...\")\n",
    "        X_train = [x_mod[train_idx] for x_mod in X_data_list]\n",
    "        X_test  = [x_mod[test_idx]  for x_mod in X_data_list]\n",
    "        y_train, y_test = y_data[train_idx], y_data[test_idx]\n",
    "\n",
    "        # clear any previous TF graph & free memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        # instantiate a fresh model\n",
    "        model = model_fn(**model_kwargs)\n",
    "\n",
    "        # compile: either clone your optimizer or fall back to a new Adam each fold\n",
    "        if compile_kwargs:\n",
    "            # shallow-copy so we don't mutate the user's dict\n",
    "            ck = compile_kwargs.copy()\n",
    "\n",
    "            if 'optimizer' in ck:\n",
    "                opt = ck.pop('optimizer')\n",
    "                # re-create a fresh optimizer instance from its config\n",
    "                ck['optimizer'] = type(opt).from_config(opt.get_config())\n",
    "\n",
    "            model.compile(**ck)\n",
    "        elif not model._is_compiled:\n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'],\n",
    "                run_eagerly=True\n",
    "            )\n",
    "\n",
    "        # fit + time it\n",
    "        start_time = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=0\n",
    "        )\n",
    "        runtime = time.time() - start_time\n",
    "\n",
    "        # evaluate\n",
    "        loss_val, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        scores.append(accuracy)\n",
    "        runtimes.append(runtime)\n",
    "\n",
    "        best_val_acc_fold = max(history.history.get('val_accuracy', [0]))\n",
    "        print(f\"Fold {fold+1}: Acc={accuracy:.4f}, Time={runtime:.2f}s. \"\n",
    "              f\"Best val_acc: {best_val_acc_fold:.4f}\")\n",
    "\n",
    "    # summarize\n",
    "    mean_acc = np.mean(scores) if scores else np.nan\n",
    "    std_acc  = np.std(scores)  if scores else np.nan\n",
    "    mean_rt  = np.mean(runtimes) if runtimes else np.nan\n",
    "\n",
    "    print(f\"{model_name} CV Results: Mean Acc = {mean_acc:.4f} \"\n",
    "          f\"+/- {std_acc:.4f}, Mean Runtime = {mean_rt:.2f}s\")\n",
    "\n",
    "    return [model_name, mean_acc, std_acc, mean_rt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b32eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating: SimpleCNN_SpecAug ---\n",
      "SimpleCNN_SpecAug - Fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(16, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(10, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(32, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.7083, Time=7.35s. Best val_acc: 0.7083\n",
      "SimpleCNN_SpecAug - Fold 2/3...\n",
      "Fold 2: Acc=0.6042, Time=7.09s. Best val_acc: 0.7083\n",
      "SimpleCNN_SpecAug - Fold 3/3...\n",
      "Fold 3: Acc=0.6905, Time=7.12s. Best val_acc: 0.7143\n",
      "SimpleCNN_SpecAug CV Results: Mean Acc = 0.6677 +/- 0.0455, Mean Runtime = 7.19s\n",
      "\n",
      "--- Evaluating: ResNetLike_SpecAug ---\n",
      "ResNetLike_SpecAug - Fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(16, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(10, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(32, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.6667, Time=12.80s. Best val_acc: 0.6875\n",
      "ResNetLike_SpecAug - Fold 2/3...\n",
      "Fold 2: Acc=0.6667, Time=12.80s. Best val_acc: 0.7083\n",
      "ResNetLike_SpecAug - Fold 3/3...\n",
      "Fold 3: Acc=0.7381, Time=13.29s. Best val_acc: 0.7381\n",
      "ResNetLike_SpecAug CV Results: Mean Acc = 0.6905 +/- 0.0337, Mean Runtime = 12.96s\n",
      "\n",
      "--- Evaluating: AdaptedEfficientNetB0_SA ---\n",
      "AdaptedEfficientNetB0_SA - Fold 1/3...\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(16, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(10, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(32, 33, 7, 16))',)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.6667, Time=56.26s. Best val_acc: 0.6667\n",
      "AdaptedEfficientNetB0_SA - Fold 2/3...\n",
      "Fold 2: Acc=0.6667, Time=56.16s. Best val_acc: 0.6667\n",
      "AdaptedEfficientNetB0_SA - Fold 3/3...\n",
      "Fold 3: Acc=0.6667, Time=58.98s. Best val_acc: 0.6905\n",
      "AdaptedEfficientNetB0_SA CV Results: Mean Acc = 0.6667 +/- 0.0000, Mean Runtime = 57.13s\n"
     ]
    }
   ],
   "source": [
    "# --- Run DL Models ---\n",
    "dl_results = []\n",
    "N_SPLITS_DL = 3     # e.g. 3 folds\n",
    "EPOCHS_DL   = 15    # e.g. 15 epochs for faster testing\n",
    "BATCH_SIZE_DL = 16\n",
    "\n",
    "\n",
    "def create_fixed_resnet_like_model(input_shape, spec_augment_params=None, num_blocks_list=[1,1], initial_filters=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    if spec_augment_params: x = SpecAugment(**spec_augment_params)(x)\n",
    "    \n",
    "    x = Conv2D(initial_filters, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x); x = ReLU()(x)\n",
    "\n",
    "    current_filters = initial_filters\n",
    "    for i, num_blocks in enumerate(num_blocks_list):\n",
    "        for _ in range(num_blocks):\n",
    "            # Simplified ResNet block (no HP tuning here)\n",
    "            y = Conv2D(current_filters, (3,3), padding='same')(x)\n",
    "            y = BatchNormalization()(y); y = ReLU()(y)\n",
    "            y = Conv2D(current_filters, (3,3), padding='same')(y)\n",
    "            y = BatchNormalization()(y)\n",
    "            if x.shape[-1] != current_filters: # Adjust shortcut\n",
    "                x_shortcut = Conv2D(current_filters, (1,1), padding='same')(x)\n",
    "            else:\n",
    "                x_shortcut = x\n",
    "            x = Add()([x_shortcut, y]); x = ReLU()(x)\n",
    "        if i < len(num_blocks_list) - 1 and x.shape[1] > 1 and x.shape[2] > 1:\n",
    "            current_filters *= 2 # Increase filters for next stage\n",
    "            # Downsample for next stage (example, could be strided conv in block)\n",
    "            x_ident = x # store for potential shortcut across pooling if needed\n",
    "            x = MaxPooling2D((2,2))(x)\n",
    "            # if a shortcut needs to cross pooling, it must also be pooled/projected.\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x) # Reduced dense units\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    # model.compile(...) done by run_dl_model_cv if needed\n",
    "    return model\n",
    "\n",
    "spec_augment_config = {\n",
    "    'freq_mask_param': 5,\n",
    "    'time_mask_param': 2,\n",
    "    'num_freq_masks': 1,\n",
    "    'num_time_masks': 1\n",
    "}\n",
    "\n",
    "# shared compile settings\n",
    "compile_kwargs = {\n",
    "    'optimizer': Adam(learning_rate=1e-3),\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'metrics': ['accuracy'],\n",
    "    'run_eagerly': True\n",
    "}\n",
    "\n",
    "# 1. Simple CNN + SpecAugment\n",
    "dl_results.append(\n",
    "    run_dl_model_cv(\n",
    "        model_fn=create_simple_cnn_model,\n",
    "        X_data_list=[X_cnn_spec_filtered],\n",
    "        y_data=y_cnn_labels,\n",
    "        groups_data=groups_cnn_labels,\n",
    "        model_name=\"SimpleCNN_SpecAug\",\n",
    "        n_splits=N_SPLITS_DL,\n",
    "        epochs=EPOCHS_DL,\n",
    "        batch_size=BATCH_SIZE_DL,\n",
    "        compile_kwargs=compile_kwargs,\n",
    "        model_kwargs={\n",
    "            'input_shape': X_cnn_spec_filtered.shape[1:],\n",
    "            'spec_augment_params': spec_augment_config\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. ResNet-like + SpecAugment\n",
    "dl_results.append(\n",
    "    run_dl_model_cv(\n",
    "        model_fn=create_fixed_resnet_like_model,\n",
    "        X_data_list=[X_cnn_spec_filtered],\n",
    "        y_data=y_cnn_labels,\n",
    "        groups_data=groups_cnn_labels,\n",
    "        model_name=\"ResNetLike_SpecAug\",\n",
    "        n_splits=N_SPLITS_DL,\n",
    "        epochs=EPOCHS_DL,\n",
    "        batch_size=BATCH_SIZE_DL,\n",
    "        compile_kwargs=compile_kwargs,\n",
    "        model_kwargs={\n",
    "            'input_shape': X_cnn_spec_filtered.shape[1:],\n",
    "            'spec_augment_params': spec_augment_config,\n",
    "            'initial_filters': 32,\n",
    "            'num_blocks_list': [1, 1]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Adapted EfficientNetB0 + SpecAugment (with a smaller LR)\n",
    "dl_results.append(\n",
    "    run_dl_model_cv(\n",
    "        model_fn=create_adapted_efficientnet,\n",
    "        X_data_list=[X_cnn_spec_filtered],\n",
    "        y_data=y_cnn_labels,\n",
    "        groups_data=groups_cnn_labels,\n",
    "        model_name=\"AdaptedEfficientNetB0_SA\",\n",
    "        n_splits=N_SPLITS_DL,\n",
    "        epochs=EPOCHS_DL,\n",
    "        batch_size=BATCH_SIZE_DL,\n",
    "        compile_kwargs={\n",
    "            'optimizer': Adam(learning_rate=1e-4),\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'metrics': ['accuracy'],\n",
    "            'run_eagerly': True\n",
    "        },\n",
    "        model_kwargs={\n",
    "            'input_shape': X_cnn_spec_filtered.shape[1:],\n",
    "            'num_classes': 1,\n",
    "            'spec_augment_params': spec_augment_config\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c8da9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting EEG data for EEGNet...\n",
      "Shape of X_eegnet_reshaped: (138, 14, 128, 1)\n",
      "\n",
      "--- Evaluating: EEGNet ---\n",
      "EEGNet - Fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(16, 14, 128, 1))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(10, 14, 128, 1))',)\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=('Tensor(shape=(32, 14, 128, 1))',)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.6667, Time=14.91s. Best val_acc: 0.6667\n",
      "EEGNet - Fold 2/3...\n",
      "Fold 2: Acc=0.6667, Time=14.77s. Best val_acc: 0.7292\n",
      "EEGNet - Fold 3/3...\n",
      "Fold 3: Acc=0.6667, Time=13.82s. Best val_acc: 0.6667\n",
      "EEGNet CV Results: Mean Acc = 0.6667 +/- 0.0000, Mean Runtime = 14.50s\n"
     ]
    }
   ],
   "source": [
    "# --- Data Prep and Evaluation for EEGNet ---\n",
    "print(\"\\nExtracting EEG data for EEGNet...\")\n",
    "# EEGNet typically uses (Batch, Channels, Samples, 1) or (Batch, 1, Channels, Samples)\n",
    "# Our feat_extract_EEG with EEGNET_INPUT gives (Batch, Samples, Channels)\n",
    "X_eegnet_raw = feat_extract_EEG(raw, model_type='EEGNET_INPUT', sampling_rate=EEGNET_SAMPLING_RATE, fixed_length=EEGNET_SAMPLES_PER_SUBJECT)\n",
    "\n",
    "# Filter based on selected emotions (same indices as for CNNs)\n",
    "X_eegnet_filtered = X_eegnet_raw[idx_filter] # idx_filter from CNN data prep\n",
    "\n",
    "# Reshape for EEGNet: (Batch, Channels, Samples, 1) - Keras default for Conv2D is channels_last, but EEGNet paper implies specific convs\n",
    "# The EEGNet implementation used here has axis=1 for BN, implying channels_first-like operations\n",
    "# So we need (Batch, Chans, Samples, 1)\n",
    "X_eegnet_reshaped = X_eegnet_filtered.reshape(X_eegnet_filtered.shape[0], EEGNET_CHANNELS, EEGNET_SAMPLES_PER_SUBJECT, 1)\n",
    "# Transpose if feat_extract_EEG gave (Batch, Samples, Channels) -> (Batch, Channels, Samples) then expand_dims\n",
    "# X_eegnet_reshaped = np.transpose(X_eegnet_filtered, (0, 2, 1))[:, :, :, np.newaxis]\n",
    "\n",
    "\n",
    "print(f\"Shape of X_eegnet_reshaped: {X_eegnet_reshaped.shape}\") # Should be (num_filtered_samples, 14, 128, 1)\n",
    "# y_eegnet_labels and groups_eegnet_labels are same as y_cnn_labels, groups_cnn_labels\n",
    "\n",
    "if np.isnan(X_eegnet_reshaped).any():\n",
    "    print(\"Warning: NaNs found in X_eegnet_reshaped. Replacing with 0.\")\n",
    "    X_eegnet_reshaped = np.nan_to_num(X_eegnet_reshaped, nan=0.0)\n",
    "\n",
    "\n",
    "# 4. EEGNet\n",
    "# EEGNet model expects specific input shape (Chans, Samples, 1) for the model definition provided\n",
    "eegnet_input_shape = (EEGNET_CHANNELS, EEGNET_SAMPLES_PER_SUBJECT, 1)\n",
    "\n",
    "dl_results.append(\n",
    "    run_dl_model_cv(\n",
    "        model_fn=EEGNet,\n",
    "        X_data_list=[ X_eegnet_reshaped ],      # wrap in list!\n",
    "        y_data=y_cnn_labels,\n",
    "        groups_data=groups_cnn_labels,\n",
    "        model_name=\"EEGNet\",\n",
    "        n_splits=N_SPLITS_DL,\n",
    "        epochs=EPOCHS_DL + 10,                 # if you want more epochs\n",
    "        batch_size=BATCH_SIZE_DL,\n",
    "        compile_kwargs={\n",
    "            'optimizer': Adam(learning_rate=1e-3),\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'metrics': ['accuracy'],\n",
    "            'run_eagerly': True\n",
    "        },\n",
    "        model_kwargs={\n",
    "            'nb_classes': 1,\n",
    "            'Chans': EEGNET_CHANNELS,\n",
    "            'Samples': EEGNET_SAMPLES_PER_SUBJECT,\n",
    "            'dropoutRate': 0.5\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ce94578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep Learning Models CV Results:\n",
      "                       name  mean_score  std_score  mean_runtime\n",
      "0         SimpleCNN_SpecAug    0.667659   0.045484      7.187518\n",
      "1        ResNetLike_SpecAug    0.690476   0.033672     12.963567\n",
      "2  AdaptedEfficientNetB0_SA    0.666667   0.000000     57.133949\n",
      "3                    EEGNet    0.666667   0.000000     14.502123\n",
      "\n",
      "--- Script Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Consolidate and Save Results ---\n",
    "results_dl_df = pd.DataFrame(dl_results, columns=['name', 'mean_score', 'std_score', 'mean_runtime'])\n",
    "print(\"\\nDeep Learning Models CV Results:\")\n",
    "print(results_dl_df)\n",
    "results_dl_df.to_csv('results_advanced_dl.csv', index=False)\n",
    "\n",
    "print(\"\\n--- Script Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

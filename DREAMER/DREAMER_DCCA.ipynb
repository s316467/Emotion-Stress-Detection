{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3780b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import scipy.io as sio\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc # For garbage collection\n",
    "\n",
    "# Deep Learning Imports for DCCA\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras.layers import Layer # Import base Layer class\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, BatchNormalization, ReLU,\n",
    "                                     MaxPooling1D, GlobalAveragePooling1D, Dense,\n",
    "                                     Dropout, Concatenate)\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6ad031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to the dataset\n",
    "path = \"C:\\\\Users\\\\ferri\\\\Downloads\\\\PoliTO\\\\Tesi\\\\DSs\\\\Emotion-Stress\\\\DREAMER.mat\" # Ensure this path is correct\n",
    "raw = sio.loadmat(path)\n",
    "\n",
    "# Parameters for DCCA data\n",
    "EEG_SAMPLING_RATE = 128 # Hz, specific to DREAMER EEG\n",
    "EEG_CHANNELS = 14\n",
    "EEG_SAMPLES_PER_TRIAL = 128 # Corresponds to 1 second of EEG data (128 Hz * 1s)\n",
    "\n",
    "ECG_SAMPLING_RATE = 256 # Hz for DREAMER ECG\n",
    "ECG_SAMPLES_PER_TRIAL = 256 # Corresponds to 1 second of ECG data (256 Hz * 1s)\n",
    "ECG_CHANNELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27192b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_extract_ECG_for_DCCA(raw_data, sampling_rate=ECG_SAMPLING_RATE, fixed_length=ECG_SAMPLES_PER_TRIAL):\n",
    "    \"\"\"Extracts ECG time-series data for DCCA.\"\"\"\n",
    "    extracted_data_ts = []\n",
    "    n_participants = 23\n",
    "    n_videos = 18\n",
    "\n",
    "    for participant in range(n_participants):\n",
    "        for video in range(n_videos):\n",
    "            basl_left = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                     [\"baseline\"][0, 0][video, 0][:, 0]\n",
    "            stim_left = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                     [\"stimuli\"][0, 0][video, 0][:, 0]\n",
    "            basl_right = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                      [\"baseline\"][0, 0][video, 0][:, 1]\n",
    "            stim_right = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"ECG\"][0, 0]\\\n",
    "                                      [\"stimuli\"][0, 0][video, 0][:, 1]\n",
    "\n",
    "            try:\n",
    "                signals_b_l, _ = nk.ecg_process(basl_left, sampling_rate=sampling_rate)\n",
    "                signals_s_l, _ = nk.ecg_process(stim_left, sampling_rate=sampling_rate)\n",
    "                signals_b_r, _ = nk.ecg_process(basl_right, sampling_rate=sampling_rate)\n",
    "                signals_s_r, _ = nk.ecg_process(stim_right, sampling_rate=sampling_rate)\n",
    "\n",
    "                ecg_clean_left = signals_s_l[\"ECG_Clean\"].values - np.mean(signals_b_l[\"ECG_Clean\"].values)\n",
    "                ecg_clean_right = signals_s_r[\"ECG_Clean\"].values - np.mean(signals_b_r[\"ECG_Clean\"].values)\n",
    "            except Exception as e:\n",
    "                # print(f\"Neurokit processing error for P{participant+1} V{video+1} ECG: {e}. Using zeros.\")\n",
    "                ecg_clean_left = np.zeros(fixed_length if fixed_length else sampling_rate) # fallback\n",
    "                ecg_clean_right = np.zeros(fixed_length if fixed_length else sampling_rate)\n",
    "\n",
    "            sample_time_series = np.stack([ecg_clean_left, ecg_clean_right], axis=-1)\n",
    "\n",
    "            if fixed_length is not None:\n",
    "                T = sample_time_series.shape[0]\n",
    "                if T > fixed_length:\n",
    "                    sample_time_series = sample_time_series[:fixed_length, :]\n",
    "                elif T < fixed_length:\n",
    "                    pad_width = fixed_length - T\n",
    "                    sample_time_series = np.pad(sample_time_series, ((0, pad_width), (0, 0)), mode='constant')\n",
    "            \n",
    "            extracted_data_ts.append(sample_time_series)\n",
    "            \n",
    "    return np.array(extracted_data_ts)\n",
    "\n",
    "def feat_extract_EEG_for_DCCA(raw_data, sampling_rate=EEG_SAMPLING_RATE, fixed_length=EEG_SAMPLES_PER_TRIAL):\n",
    "    \"\"\"Extracts EEG time-series data for DCCA (shape: n_samples, fixed_length, n_channels).\"\"\"\n",
    "    extracted_data_eeg_ts = []\n",
    "    n_participants = 23\n",
    "    n_videos = 18\n",
    "    n_channels = EEG_CHANNELS\n",
    "\n",
    "    for participant in range(n_participants):\n",
    "        for video in range(n_videos):\n",
    "            channels_data_single_trial = [] \n",
    "            for i in range(n_channels):\n",
    "                basl = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0]\\\n",
    "                                     [\"baseline\"][0, 0][video, 0][:, i]\n",
    "                stim = raw_data[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0]\\\n",
    "                                     [\"stimuli\"][0, 0][video, 0][:, i]\n",
    "                corrected_signal = stim - np.mean(basl) \n",
    "                channels_data_single_trial.append(corrected_signal)\n",
    "\n",
    "            sample_time_series_unpadded = np.stack(channels_data_single_trial, axis=-1)\n",
    "\n",
    "            current_fixed_length = fixed_length\n",
    "            T_orig = sample_time_series_unpadded.shape[0]\n",
    "            \n",
    "            if T_orig > current_fixed_length:\n",
    "                sample_time_series = sample_time_series_unpadded[:current_fixed_length, :]\n",
    "            elif T_orig < current_fixed_length:\n",
    "                pad_width_time = current_fixed_length - T_orig\n",
    "                sample_time_series = np.pad(sample_time_series_unpadded, ((0, pad_width_time), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                sample_time_series = sample_time_series_unpadded\n",
    "            \n",
    "            extracted_data_eeg_ts.append(sample_time_series)\n",
    "\n",
    "    return np.array(extracted_data_eeg_ts) \n",
    "\n",
    "\n",
    "def participant_affective(raw_data):\n",
    "    a = np.zeros((23, 18, 9), dtype=object)\n",
    "    for participant in range(0, 23):\n",
    "        for video in range(0, 18):\n",
    "            a[participant, video, 0] = (raw_data[\"DREAMER\"][0, 0][\"Data\"]\n",
    "                                        [0, participant][\"Age\"][0][0][0])\n",
    "            a[participant, video, 1] = (raw_data[\"DREAMER\"][0, 0][\"Data\"]\n",
    "                                        [0, participant][\"Gender\"][0][0][0])\n",
    "            a[participant, video, 2] = int(participant+1)\n",
    "            a[participant, video, 3] = int(video+1)\n",
    "            a[participant, video, 4] = [\"Searching for Bobby Fischer\", \"D.O.A.\", \"The Hangover\", \"The Ring\", \"300\", \"National Lampoon\\'s VanWilder\", \"Wall-E\", \"Crash\", \"My Girl\", \"The Fly\", \"Pride and Prejudice\", \"Modern Times\", \"Remember the Titans\", \"Gentlemans Agreement\", \"Psycho\", \"The Bourne Identitiy\", \"The Shawshank Redemption\", \"The Departed\"][video]\n",
    "            a[participant, video, 5] = [\"calmness\", \"surprise\", \"amusement\", \"fear\", \"excitement\", \"disgust\", \"happiness\", \"anger\", \"sadness\", \"disgust\", \"calmness\", \"amusement\", \"happiness\", \"anger\", \"fear\", \"excitement\", \"sadness\", \"surprise\"][video]\n",
    "            a[participant, video, 6] = int(raw_data[\"DREAMER\"][0, 0][\"Data\"] [0, participant][\"ScoreValence\"] [0, 0][video, 0])\n",
    "            a[participant, video, 7] = int(raw_data[\"DREAMER\"][0, 0][\"Data\"] [0, participant][\"ScoreArousal\"] [0, 0][video, 0])\n",
    "            a[participant, video, 8] = int(raw_data[\"DREAMER\"][0, 0][\"Data\"] [0, participant][\"ScoreDominance\"] [0, 0][video, 0])\n",
    "    b = pd.DataFrame(a.reshape((23*18, a.shape[2])), columns=[\"age\", \"gender\", \"participant\", \"video\", \"video_name\", \"target_emotion\", \"valence\", \"arousal\", \"dominance\"])\n",
    "    for col in [\"age\", \"participant\", \"video\", \"valence\", \"arousal\", \"dominance\"]: b[col] = b[col].astype(int)\n",
    "    b[\"gender\"] = b[\"gender\"].astype(str)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ce406",
   "metadata": {},
   "source": [
    "## DCCA Fusion Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626866d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data for DCCA Fusion Model...\n",
      "Shape of X_eeg_for_dcca: (138, 128, 14)\n",
      "Shape of X_ecg_for_dcca: (138, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# --- Get Labels and Groups ---\n",
    "df_participant_affective = participant_affective(raw)\n",
    "data_filtered_df = df_participant_affective.loc[\n",
    "    (df_participant_affective['target_emotion'] == 'anger') |\n",
    "    (df_participant_affective['target_emotion'] == 'fear') |\n",
    "    (df_participant_affective['target_emotion'] == 'calmness')\n",
    "].copy()\n",
    "\n",
    "idx_filter = data_filtered_df.index\n",
    "y_labels = data_filtered_df['target_emotion'].map({'anger': 1, 'fear': 1, 'calmness': 0}).values\n",
    "groups_labels = data_filtered_df['participant'].values\n",
    "\n",
    "# --- Data Prep for DCCA Fusion Model ---\n",
    "print(\"\\nExtracting data for DCCA Fusion Model...\")\n",
    "\n",
    "# EEG Data for DCCA\n",
    "X_eeg_unfiltered = feat_extract_EEG_for_DCCA(raw, fixed_length=EEG_SAMPLES_PER_TRIAL)\n",
    "X_eeg_for_dcca = X_eeg_unfiltered[idx_filter] \n",
    "if np.isnan(X_eeg_for_dcca).any():\n",
    "    print(\"Warning: NaNs found in X_eeg_for_dcca. Replacing with 0.\")\n",
    "    X_eeg_for_dcca = np.nan_to_num(X_eeg_for_dcca, nan=0.0)\n",
    "print(f\"Shape of X_eeg_for_dcca: {X_eeg_for_dcca.shape}\")\n",
    "\n",
    "# ECG Data for DCCA\n",
    "X_ecg_unfiltered = feat_extract_ECG_for_DCCA(raw, fixed_length=ECG_SAMPLES_PER_TRIAL)\n",
    "X_ecg_for_dcca = X_ecg_unfiltered[idx_filter] \n",
    "if np.isnan(X_ecg_for_dcca).any():\n",
    "    print(\"Warning: NaNs found in X_ecg_for_dcca. Replacing with 0.\")\n",
    "    X_ecg_for_dcca = np.nan_to_num(X_ecg_for_dcca, nan=0.0)\n",
    "print(f\"Shape of X_ecg_for_dcca: {X_ecg_for_dcca.shape}\")\n",
    "\n",
    "X_dcca_inputs = [X_eeg_for_dcca, X_ecg_for_dcca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f922aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DCCA Loss Layer Definition ---\n",
    "class DccaLossLayer(Layer):\n",
    "    def __init__(self, dcca_weight=0.5, epsilon=1e-9, name=\"dcca_loss_layer\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.dcca_weight = dcca_weight\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def call(self, inputs):\n",
    "        o1, o2 = inputs\n",
    "\n",
    "        N = tf.cast(tf.shape(o1)[0], tf.float32)\n",
    "\n",
    "        def compute_loss():\n",
    "            o1_centered = o1 - tf.reduce_mean(o1, axis=0, keepdims=True)\n",
    "            o2_centered = o2 - tf.reduce_mean(o2, axis=0, keepdims=True)\n",
    "            denominator = (N - 1.0) + self.epsilon # Ensure N-1.0 for sample covariance\n",
    "            cross_cov = tf.matmul(o1_centered, o2_centered, transpose_a=True) / denominator\n",
    "            singular_values = tf.linalg.svd(cross_cov, compute_uv=False)\n",
    "            loss = -tf.reduce_sum(singular_values)\n",
    "            return loss\n",
    "\n",
    "        raw_loss = tf.cond(tf.greater(N, 1.0), # Use tf.greater for explicit boolean tensor\n",
    "                           true_fn=compute_loss,\n",
    "                           false_fn=lambda: tf.constant(0.0, dtype=tf.float32))\n",
    "        \n",
    "        weighted_loss = self.dcca_weight * raw_loss\n",
    "        self.add_loss(weighted_loss)\n",
    "        \n",
    "        # Return one of the inputs, making it behave like an identity layer for data flow.\n",
    "        # This avoids Keras treating a scalar output specially in a way that might cause issues.\n",
    "        return o1 # Or inputs (the list [o1, o2]), or any other valid tensor from inputs.\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # If returning o1, the output shape is the shape of o1.\n",
    "        # input_shape is a list of two shapes: [shape_o1, shape_o2]\n",
    "        return input_shape[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"dcca_weight\": self.dcca_weight,\n",
    "            \"epsilon\": self.epsilon,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# --- DCCA Model Definition ---\n",
    "def create_dcca_fusion_model(input_shape_eeg, input_shape_ecg, projection_dim=32, num_classes=1, dcca_weight=0.5):\n",
    "    input_eeg = Input(shape=input_shape_eeg, name='eeg_input')\n",
    "    input_ecg = Input(shape=input_shape_ecg, name='ecg_input')\n",
    "\n",
    "    x_eeg = Conv1D(filters=16, kernel_size=7, padding='same', activation='relu')(input_eeg)\n",
    "    x_eeg = BatchNormalization()(x_eeg); x_eeg = MaxPooling1D(pool_size=2)(x_eeg)\n",
    "    x_eeg = Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(x_eeg)\n",
    "    x_eeg = BatchNormalization()(x_eeg); x_eeg = MaxPooling1D(pool_size=2)(x_eeg)\n",
    "    eeg_pooled_features = GlobalAveragePooling1D(name='eeg_pooled_features')(x_eeg)\n",
    "\n",
    "    x_ecg = Conv1D(filters=16, kernel_size=7, padding='same', activation='relu')(input_ecg)\n",
    "    x_ecg = BatchNormalization()(x_ecg); x_ecg = MaxPooling1D(pool_size=2)(x_ecg)\n",
    "    x_ecg = Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(x_ecg)\n",
    "    x_ecg = BatchNormalization()(x_ecg); x_ecg = MaxPooling1D(pool_size=2)(x_ecg)\n",
    "    ecg_pooled_features = GlobalAveragePooling1D(name='ecg_pooled_features')(x_ecg)\n",
    "\n",
    "    eeg_projected = Dense(projection_dim, activation=None, name='eeg_projection')(eeg_pooled_features)\n",
    "    ecg_projected = Dense(projection_dim, activation=None, name='ecg_projection')(ecg_pooled_features)\n",
    "\n",
    "    # DccaLossLayer adds loss as a side effect. Its direct output is now eeg_projected (or o1).\n",
    "    # This output is not used further in this specific branch, which is fine.\n",
    "    _ = DccaLossLayer(dcca_weight=dcca_weight, name='dcca_loss_calculator')([eeg_projected, ecg_projected])\n",
    "\n",
    "    combined_features = Concatenate()([eeg_pooled_features, ecg_pooled_features])\n",
    "    x_clf = Dense(64, activation='relu')(combined_features)\n",
    "    x_clf = Dropout(0.5)(x_clf)\n",
    "    output_classification = Dense(num_classes, activation='sigmoid' if num_classes == 1 else 'softmax', name='classification_output')(x_clf)\n",
    "\n",
    "    model = Model(inputs=[input_eeg, input_ecg], outputs=output_classification)\n",
    "    return model\n",
    "\n",
    "# --- Training and Evaluation Loop for DL Models ---\n",
    "def run_dl_model_cv(model_fn, X_data_list, y_data, groups_data, model_name,\n",
    "                    n_splits=5, epochs=25, batch_size=16, compile_kwargs=None, model_kwargs=None):\n",
    "    print(f\"\\n--- Evaluating: {model_name} ---\")\n",
    "    cv_dl = GroupKFold(n_splits=n_splits)\n",
    "    scores, runtimes = [], []\n",
    "\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "    X_for_split = X_data_list[0]\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_dl.split(X_for_split, y_data, groups_data)):\n",
    "        print(f\"{model_name} - Fold {fold+1}/{n_splits}...\")\n",
    "        X_train = [x_mod[train_idx] for x_mod in X_data_list]\n",
    "        X_test  = [x_mod[test_idx]  for x_mod in X_data_list]\n",
    "        y_train, y_test = y_data[train_idx], y_data[test_idx]\n",
    "\n",
    "        # clear any previous TF graph & free memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "        # instantiate a fresh model\n",
    "        model = model_fn(**model_kwargs)\n",
    "\n",
    "        # compile: either clone your optimizer or fall back to a new Adam each fold\n",
    "        if compile_kwargs:\n",
    "            # shallow-copy so we don't mutate the user's dict\n",
    "            ck = compile_kwargs.copy()\n",
    "\n",
    "            if 'optimizer' in ck:\n",
    "                opt = ck.pop('optimizer')\n",
    "                # re-create a fresh optimizer instance from its config\n",
    "                ck['optimizer'] = type(opt).from_config(opt.get_config())\n",
    "\n",
    "            model.compile(**ck)\n",
    "        elif not model._is_compiled:\n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'],\n",
    "                run_eagerly=True\n",
    "            )\n",
    "\n",
    "        # fit + time it\n",
    "        start_time = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=0\n",
    "        )\n",
    "        runtime = time.time() - start_time\n",
    "\n",
    "        # evaluate\n",
    "        loss_val, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        scores.append(accuracy)\n",
    "        runtimes.append(runtime)\n",
    "\n",
    "        best_val_acc_fold = max(history.history.get('val_accuracy', [0]))\n",
    "        print(f\"Fold {fold+1}: Acc={accuracy:.4f}, Time={runtime:.2f}s. \"\n",
    "              f\"Best val_acc: {best_val_acc_fold:.4f}\")\n",
    "\n",
    "    # summarize\n",
    "    mean_acc = np.mean(scores) if scores else np.nan\n",
    "    std_acc  = np.std(scores)  if scores else np.nan\n",
    "    mean_rt  = np.mean(runtimes) if runtimes else np.nan\n",
    "\n",
    "    print(f\"{model_name} CV Results: Mean Acc = {mean_acc:.4f} \"\n",
    "          f\"+/- {std_acc:.4f}, Mean Runtime = {mean_rt:.2f}s\")\n",
    "\n",
    "    return [model_name, mean_acc, std_acc, mean_rt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4435bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating: DCCA_Fusion_EEG_ECG ---\n",
      "DCCA_Fusion_EEG_ECG - Fold 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.6250, Time=16.78s. Best val_acc: 0.6667\n",
      "DCCA_Fusion_EEG_ECG - Fold 2/3...\n",
      "Fold 2: Acc=0.6458, Time=16.55s. Best val_acc: 0.7083\n",
      "DCCA_Fusion_EEG_ECG - Fold 3/3...\n",
      "Fold 3: Acc=0.5238, Time=17.34s. Best val_acc: 0.6905\n",
      "DCCA_Fusion_EEG_ECG CV Results: Mean Acc = 0.5982 +/- 0.0533, Mean Runtime = 16.89s\n"
     ]
    }
   ],
   "source": [
    "# --- Run DCCA Fusion Model ---\n",
    "dl_results = []\n",
    "N_SPLITS_DL = 3\n",
    "EPOCHS_DL = 25\n",
    "BATCH_SIZE_DL = 16\n",
    "\n",
    "dcca_model_kwargs = {\n",
    "    'input_shape_eeg': (EEG_SAMPLES_PER_TRIAL, EEG_CHANNELS),\n",
    "    'input_shape_ecg': (ECG_SAMPLES_PER_TRIAL, ECG_CHANNELS),\n",
    "    'projection_dim': 32,\n",
    "    'num_classes': 1,\n",
    "    'dcca_weight': 0.3\n",
    "}\n",
    "\n",
    "compile_kwargs = {\n",
    "    'optimizer': Adam(learning_rate=1e-3),\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'metrics': ['accuracy'],\n",
    "    'run_eagerly': True\n",
    "}\n",
    "\n",
    "dl_results.append(run_dl_model_cv(\n",
    "    create_dcca_fusion_model,\n",
    "    X_dcca_inputs,\n",
    "    y_labels,\n",
    "    groups_labels,\n",
    "    \"DCCA_Fusion_EEG_ECG\",\n",
    "    n_splits=N_SPLITS_DL,\n",
    "    epochs=EPOCHS_DL,\n",
    "    batch_size=BATCH_SIZE_DL,\n",
    "    model_kwargs=dcca_model_kwargs,\n",
    "    compile_kwargs=compile_kwargs\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a84f9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DCCA Fusion Model CV Results:\n",
      "                  name  mean_score  std_score  mean_runtime\n",
      "0  DCCA_Fusion_EEG_ECG    0.598214   0.053295     16.891401\n",
      "\n",
      "--- Script Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Consolidate and Save Results ---\n",
    "results_dcca_df = pd.DataFrame(dl_results, columns=['name', 'mean_score', 'std_score', 'mean_runtime'])\n",
    "print(\"\\nDCCA Fusion Model CV Results:\")\n",
    "print(results_dcca_df)\n",
    "\n",
    "results_dcca_df.to_csv('dcca_fusion_model_results.csv', index=False)\n",
    "\n",
    "print(\"\\n--- Script Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
